{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOMATED HPCL , BPCL & NAYARA REPORTS:\n",
    "\n",
    "## Advantages Of This Project:\n",
    "\n",
    "### 1. Time & Money Saving : \n",
    "#### Reduced Team & Team efforts for building daily operating reports & send mails to respective state heads ( Before - 2x60 Hrs ) <> ( Now - 20 mins ).\n",
    "### 2. Accuracy : \n",
    "#### Produces 100% accurate data i.e Reduced human errors in data hence getting data ready for Machine Learning Algorithms.\n",
    "### 3. Analysis : \n",
    "#### Provides on time as well as Gap Analysis of weak days.\n",
    "### 4. Error Tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate():\n",
    "    \n",
    "    \n",
    "    # Importing Neccessary Libraries...\n",
    "\n",
    "    import warnings \n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    import pandas as pd , numpy as np , datetime, os\n",
    "    import smtplib\n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from email.mime.base import MIMEBase\n",
    "    from email import encoders\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pylab import imread\n",
    "    from distutils.dir_util import copy_tree\n",
    "\n",
    "    # Taking Input From User...\n",
    "\n",
    "    variable = input('\\033[1m' +'Enter Your System Name : ')\n",
    "    slash = input('\\033[1m' + 'Enter \\ : ')\n",
    "\n",
    "    # Good Morning Message...\n",
    "\n",
    "    image = imread(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Script\\goodmorning.jpg')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Datetime Manipulation \n",
    "\n",
    "    TD = datetime.datetime.now().strftime('%d-%m-%Y')\n",
    "    YD = datetime.date.today()-datetime.timedelta(1)\n",
    "    YD = YD.strftime('%d-%m-%Y')\n",
    "\n",
    "    # Initiliazing State Office\n",
    "\n",
    "    incrementer_lst = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO'\n",
    "                       ,'KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "\n",
    "    #incrementer_lst = ['NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO'\n",
    "    #                   ,'KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "\n",
    "    incrementer = 0\n",
    "    Pan_India_HPCL = pd.DataFrame()\n",
    "\n",
    "    # Connecting Files To One Drive\n",
    "\n",
    "    print('\\033[0m' + 'Wait In Process...')\n",
    "\n",
    "    URL1 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'  # Pan India HPCL Input\n",
    "    URL2 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input NANO History'             # NANO History Input\n",
    "    URL3 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files'              # Fixed Location Input\n",
    "    URL4 = URL3           # Fixed State Office Mail Details Input\n",
    "    URL5 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Prods ( 1 & 2 )'          # Production 1 BPCL Input\n",
    "    URL6 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Prods ( 1 & 2 )'          # Production 2 BPCL Input\n",
    "    URL7 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input HOS'              # HOS File Input\n",
    "    URL8 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL' + slash + TD    # HPCL State Wise Destination Output\n",
    "    URL9 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL' + slash + TD    # BPCL State Wise Destination Output\n",
    "    URL10 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL' # Pan India BPCL Input\n",
    "    URL11 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'  # Pan India HPCL Output\n",
    "    URL12 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL' # Pan India BPCL Output\n",
    "    URL13 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'   # HPCL Pan Output\n",
    "    URL14 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Daily Remarks Updation\\HPCL'   # Daily Remarks Updation HPCL\n",
    "    URL15 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL'   # BPCL Pan Output\n",
    "    URL16 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Daily Remarks Updation\\BPCL'   # Daily Remarks Updation BPCL\n",
    "    URL17 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL'   # State wise BPCL for remarks\n",
    "    URL18 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL'   # State wise HPCl for remarks\n",
    "    URL19 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL'\n",
    "    URL20 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL' # NAyara cols\n",
    "\n",
    "    URL21 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files\\Nayara Columns.xlsx'\n",
    "    URL22 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\Pan_India'        # Pan_India_nayara\n",
    "    URL23 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\State_files_Output' + slash + TD   #  Output State Wise Nayara\n",
    "    URL24 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\State_files_Input' # Input State wise nayara\n",
    "\n",
    "\n",
    "\n",
    "    # Auto Generation Today's Date Folders... \n",
    "\n",
    "    #os.mkdir(URL8)   \n",
    "    #os.mkdir(URL9)\n",
    "    #os.mkdir(URL23)\n",
    "\n",
    "\n",
    "    # Copy Of Yesterday HPCL & BPCL Pan India... \n",
    "\n",
    "    Y_df = pd.read_excel(URL1 + '\\Backup But Without Update' + '\\HPCL_' + 'Pan_India_Report_'+ YD +'.xlsx')   # Pan_India_HPCL Yesterday\n",
    "    Y_Pan_India = pd.read_excel(URL10 + '\\Backup But Without Update' + '\\BPCL_Pan_India_Report_' + YD + '.xlsx')  # Pan_India_BPCL Yesterday\n",
    "\n",
    "    # Importing Required Columns Name to Overfit Format Of Files...\n",
    "\n",
    "    cols_hpcl = pd.read_excel(URL3 + '\\HPCL Columns.xlsx').columns.tolist()\n",
    "    cols_bpcl = pd.read_excel(URL3 + '\\BPCL Columns.xlsx').columns.tolist()\n",
    "    cols_nayara = pd.read_excel(URL21,'NAYARA DETAILS').columns.tolist()\n",
    "\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"Updating Yesterday's PAN INDIA Reports...\")\n",
    "\n",
    "    # HPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "\n",
    "    states_for_pan = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO','KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "    i = 0\n",
    "    Pan_India_HPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_HPCL = pd.read_excel(URL19 + slash + YD + slash + 'HPCL_' + states_for_pan[i] + '_' + YD + '.xlsx', 'Data')\n",
    "        extract_State_HPCL.columns = cols_hpcl\n",
    "        Pan_India_HPCL = pd.concat([Pan_India_HPCL,extract_State_HPCL])\n",
    "        i +=1\n",
    "    Pan_India_HPCL.to_excel(URL11 +'\\HPCL_Pan_India_Report_' + YD + '.xlsx',index = False)\n",
    "    print('\\033[0m' + 'SUCCESSFULLY File Saved As : ' + 'HPCL_Pan_India_Report_' + YD)\n",
    "\n",
    "    # BPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "\n",
    "    i = 0\n",
    "    Pan_India_BPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_BPCL = pd.read_excel(URL20 + slash + YD + slash + 'BPCL_' + states_for_pan[i] + '_' + YD + '.xlsx', 'Data')\n",
    "        extract_State_BPCL.columns = cols_bpcl\n",
    "        State_BPCL = extract_State_BPCL.drop('Sr no',axis = 1)\n",
    "        Pan_India_BPCL = pd.concat([Pan_India_BPCL,State_BPCL])\n",
    "        i +=1\n",
    "    Pan_India_BPCL['Sr no'] = list(range(1,len(Pan_India_BPCL)+1))\n",
    "    Pan_India_BPCL = Pan_India_BPCL.reset_index().drop('index',axis=1)\n",
    "    Pan_India_BPCL = Pan_India_BPCL[extract_State_BPCL.columns.tolist()]\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\BPCL_Pan_India_Report_' + YD + '.xlsx',index = False)\n",
    "    print('SUCCESSFULLY File Saved As : ' + 'BPCL_Pan_India_Report_' + YD)\n",
    "    print('\\033[1m' + '\\033[92m' + \"SUCCESSFULLY Updated Yesterday's PAN INDIA Reports\")\n",
    "\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'Building PAN INDIA NAYARA Reports...')\n",
    "\n",
    "    # NAYARA (Building PAN INDIA NAYARA Reports...)\n",
    "\n",
    "    f_N = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO'\n",
    "                  ,'KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "\n",
    "    i_N = 0\n",
    "    nayara = pd.DataFrame()\n",
    "\n",
    "\n",
    "    while i_N < len(f_N):\n",
    "        extract_nayara = pd.read_excel(URL24 + slash + f_N[i_N] + '.xlsx', 'NAYARA DETAILS')\n",
    "        extract_nayara.columns = cols_nayara\n",
    "        nayara = pd.concat([nayara,extract_nayara])\n",
    "        i_N += 1\n",
    "\n",
    "    nayara = nayara.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "    nayara = nayara.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "    nayara = nayara.drop_duplicates(subset = 'CMS Code')\n",
    "    nayara = nayara.reset_index().drop('index',axis=1)\n",
    "    nayara['Sr No.'] = list(range(1,len(nayara)+1))\n",
    "\n",
    "    # SUMMARY Pan_India_NAYARA\n",
    "\n",
    "    s = nayara[['Zone', 'State','Division','CMS Code','I & C Status', 'HOTO Done','HOTO - Uploaded','O&M Call Status (Open/Closed)'\n",
    "                ,'Spare Requirement','Delivery Status']]\n",
    "    s.loc[s['I & C Status'] == 'COMPLETED', ['I & C Status']] = 'I/C Completed'\n",
    "    s.loc[s['I & C Status'] == 'PENDING' , ['I & C Status']] = 'I/C Pending'\n",
    "\n",
    "    s.loc[s['HOTO Done'] == 'N',['HOTO Done']] = 'HOTO Pending'\n",
    "    s.loc[s['HOTO - Uploaded'] == 'Y' , ['HOTO - Uploaded']] = 'HOTO Uploaded'\n",
    "    s.loc[s['O&M Call Status (Open/Closed)'] == 'OPEN',['O&M Call Status (Open/Closed)']] = 'O&M Open calls'\n",
    "\n",
    "    s.loc[(s['I & C Status'] != 'I/C Completed') & (s['I & C Status'] != 'I/C Pending') , ['I & C Status']] = np.nan\n",
    "    s.loc[s['HOTO Done'] != 'HOTO Pending' ,['HOTO Done']] = np.nan\n",
    "    s.loc[s['HOTO - Uploaded'] != 'HOTO Uploaded' , ['HOTO - Uploaded']] = np.nan\n",
    "    s.loc[s['O&M Call Status (Open/Closed)'] != 'O&M Open calls' , ['O&M Call Status (Open/Closed)']] = np.nan\n",
    "\n",
    "\n",
    "    s1 = pd.get_dummies(s['I & C Status'])\n",
    "    s2 = pd.get_dummies(s['HOTO - Uploaded'])\n",
    "\n",
    "    if len(s.loc[s['HOTO - Uploaded'].isnull(),['HOTO - Uploaded']]) == len(s):\n",
    "        s2['HOTO - Uploaded'] = 0\n",
    "\n",
    "    s3 = pd.get_dummies(s['HOTO Done'])\n",
    "\n",
    "    if len(s.loc[s['HOTO Done'].isnull(),['HOTO Done']]) == len(s):\n",
    "        s3['HOTO Pending'] = 0\n",
    "\n",
    "    s4 = pd.get_dummies(s['O&M Call Status (Open/Closed)'])\n",
    "    ro = s[['CMS Code']]\n",
    "    ro['CMS Code'] = 1\n",
    "    ro.columns = ['Total RO']\n",
    "\n",
    "    Summary = pd.concat([s[['Zone','State','Division']],ro,s1,s2,s3,s4],axis=1)\n",
    "\n",
    "    Summary = Summary.groupby(['Zone','State','Division']).sum()\n",
    "    Summary = Summary.T\n",
    "    Summary['GRAND TOTAL'] = Summary.sum(axis=1)\n",
    "    Summary = Summary.T\n",
    "    Summary['HOTO Pending'] = Summary['Total RO'] - Summary['HOTO Uploaded']\n",
    "    Summary_NAYARA = Summary.astype(int)\n",
    "    Summary_NAYARA = Summary_NAYARA.replace(0,' ')\n",
    "\n",
    "    # HOTO PIVOT Pan_India_NAYARA\n",
    "\n",
    "    tHP = nayara[['HOTO Remarks']]\n",
    "    tHP.columns = ['Count Of Remarks']\n",
    "    HP = pd.concat([nayara[['HOTO Dependency','HOTO Remarks']],tHP],axis=1)\n",
    "    HP = HP.dropna()\n",
    "    HP = HP.groupby(['HOTO Dependency','HOTO Remarks']).count()\n",
    "    HP = HP.replace(0,' ')\n",
    "\n",
    "    # O & M PIVOT Pan_India_NAYARA\n",
    "\n",
    "    tOM = nayara[['O & M Remarks']]\n",
    "    tOM.columns = ['Count Of Remarks']\n",
    "    OM = pd.concat([nayara[['O & M Dependency','O & M Remarks']],tOM],axis=1)\n",
    "    OM = OM.dropna()\n",
    "    OM = OM.groupby(['O & M Dependency','O & M Remarks']).count()\n",
    "    OM = OM.replace(0,' ')\n",
    "\n",
    "    ## SPARE PIVOT\n",
    "\n",
    "    p=nayara[['State','BOS CARD', 'FCC CARD', '5 VOLT SMPS', 'INTERFACE CARD',\n",
    "           'FCC with Accessory', 'DOOR LOCK RFID', 'Barrier board', 'Glands',\n",
    "           '12 SMPS', 'Total ATG probe', '2M', '2.25 M', '2.50 M', '2.75 M',\n",
    "           '3 M', 'HSD Density Float Kit', 'MS Density Float Kit',\n",
    "           'PRODUCT FLOAT KIT', 'WATER FLOAT KIT', 'RFID TAG', 'RFID READER',\n",
    "           'Neck Ribbon', 'Slave', 'MASTER', 'COMM Cable (M)', 'Epoxy KIT',\n",
    "           'MONITOR', 'KEYBOARD', 'MOUSE', 'USB HUB', 'MONITOR POWER CABLE',\n",
    "           'VGA CABLE', 'MCB', 'SPD', 'ROUTER', 'ROUTER ADOPTER', 'PATCH CORD (M)']]\n",
    "    Pivot = p.groupby('State').sum().T\n",
    "    Pivot['GRAND TOTAL'] = Pivot.sum(axis=1)\n",
    "    Pivot = Pivot.astype(int).replace(0,' ')\n",
    "\n",
    "    # EXPORTING FILES  Pan_India_NAYARA\n",
    "\n",
    "    Destination_URL_NAYARA = URL22 + slash + 'Pan_India_NAYARA_' + TD + '.xlsx'\n",
    "\n",
    "    writer5 = pd.ExcelWriter(Destination_URL_NAYARA , engine = 'xlsxwriter')\n",
    "    Summary_NAYARA.to_excel(writer5 , sheet_name = 'NAYARA SUMMARY')\n",
    "    HP.to_excel(writer5 , sheet_name = 'HOTO PIVOT')\n",
    "    OM.to_excel(writer5 , sheet_name = 'O&M PIVOT')\n",
    "    Pivot.to_excel(writer5,sheet_name = 'SPARE PIVOT')\n",
    "    nayara.to_excel(writer5 , sheet_name = 'NAYARA DETAILS' , index = False)\n",
    "    writer5.save()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESSFULLY Built & Exported PAN_INDIA_NAYARA Report')\n",
    "\n",
    "\n",
    "\n",
    "    # Looping................\n",
    "\n",
    "    while incrementer < len(incrementer_lst):\n",
    "\n",
    "        print('\\033[1m' + '\\033[92m' + 'Building ' + incrementer_lst[incrementer] + ' HPCL , BPCL & NAYARA' + ' Reports...')\n",
    "\n",
    "        a = incrementer_lst[incrementer]\n",
    "\n",
    "\n",
    "        #....................................................HPCL.................................................................#\n",
    "\n",
    "\n",
    "        # Extracting Required Data_HPCL HPCL\n",
    "\n",
    "        df = pd.read_excel(URL1 + '\\HPCL_' + 'Pan_India_Report_'+ YD +'.xlsx')   # Pan_India_HPCl\n",
    "        ref = pd.read_excel(URL2 + '\\HPCL_' + 'NANO_HISTORY_' + TD + '.xlsx')  # Nano History last date\n",
    "        location = pd.read_excel(URL3 + '\\Zone_State_Region' + '.xlsx' , 'HPCL')   # Fixed location\n",
    "\n",
    "        # Cleaning ALL Above Data_HPCL\n",
    "\n",
    "        df = df.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "        location = location.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        location = location.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "\n",
    "        # Should be changed according to file\n",
    "\n",
    "        #df = df.drop(['Connectivity Status','Connectivity Vendor'],axis=1)\n",
    "\n",
    "        # Cleaning NANO History\n",
    "\n",
    "        NANO_HISTORY = ref.iloc[11:,:].dropna(how='all',axis=1)\n",
    "        NANO_HISTORY.columns = list(NANO_HISTORY.iloc[0])\n",
    "        NANO_HISTORY = NANO_HISTORY.rename(columns = {'Pumps Configured':'Today Pumps Configured' , 'Tanks Configured':'Tanks Configured Today'})\n",
    "\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop(columns='index').iloc[1:len(NANO_HISTORY)-1].reset_index().drop('index',axis=1)\n",
    "        NANO_HISTORY['Region'] = NANO_HISTORY['Region'].str.upper()\n",
    "        NANO_HISTORY = location[['Region','State','State Office']].merge(NANO_HISTORY , how = 'right' , on = ['Region'])\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop('index',axis=1)\n",
    "        df = df.drop_duplicates(subset='ROCode')\n",
    "        NANO_HISTORY = NANO_HISTORY.drop_duplicates(subset='ROCode')\n",
    "\n",
    "        # .......\n",
    "\n",
    "        df['Reason'] = df['Reason'].str.upper()\n",
    "        df['Remarks'] = df['Remarks'].str.upper()\n",
    "        df['Dependency'] = df['Dependency'].str.upper()\n",
    "        df['Region'] = df['Region'].str.upper()\n",
    "        df['State Office'] = df['State Office'].str.upper()\n",
    "\n",
    "        HPCL = df       # Making A Copy Of Yesterday's Pan_India_HPCL\n",
    "\n",
    "        df['Yesterday Tanks Configured'] = df['Tanks Configured Today']\n",
    "        df['Yesterday Pumps Configured'] = df['Today Pumps Configured']\n",
    "        lstnano = list(set(NANO_HISTORY.columns.tolist()) & set(df.columns.tolist()))\n",
    "        lstnano.remove('ROCode')\n",
    "        df1 = df.drop(lstnano,axis=1)\n",
    "        Data_HPCL = df1.reset_index().drop('index',axis=1)\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop('index',axis=1)\n",
    "        Data_HPCL = Data_HPCL.merge(NANO_HISTORY, how = 'outer' , on = ['ROCode'])\n",
    "        Data_HPCL = Data_HPCL.reset_index().drop('index',axis=1)\n",
    "        Data_HPCL = Data_HPCL[df.columns.tolist()]\n",
    "\n",
    "        Data_HPCL.loc[Data_HPCL['Status'] == 'Fully Communicated' , ['Reason','Remarks','Dependency']] = np.nan\n",
    "        Data_HPCL.loc[Data_HPCL['Status'] == 'Temporary Close' , ['Reason','Remarks','Dependency']] = np.nan\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Reason'].isnull()) , ['Reason']] = 'TBF'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Reason'].isnull()) , ['Reason']] = 'TBF'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Remarks'].isnull()) , ['Remarks']] ='TO BE FOUND'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Remarks'].isnull()) , ['Remarks']] ='TO BE FOUND'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Dependency'].isnull()) , ['Dependency']] = 'AGS'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Dependency'].isnull()) , ['Dependency']] = 'AGS'\n",
    "\n",
    "        Data_HPCL['Difference'] = Data_HPCL['Today Pumps Configured'].sub(Data_HPCL['Yesterday Pumps Configured'] , axis = 0)\n",
    "        Data_HPCL['Difference.1'] = Data_HPCL['Tanks Configured Today'].sub(Data_HPCL['Yesterday Tanks Configured'] , axis = 0)\n",
    "\n",
    "        Data_HPCL = Data_HPCL.astype(int , errors = 'ignore')\n",
    "        Data_HPCL = Data_HPCL.drop_duplicates()\n",
    "        Data_HPCL = location[['Region','State']].merge(Data_HPCL , how = 'right' , on = ['Region'])\n",
    "        HPCL_2 = Data_HPCL.drop('State',axis=1)  # Copy of pan india\n",
    "\n",
    "        # Summary\n",
    "\n",
    "        ds1 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Dependency'] , values = 'Remarks' , aggfunc = len ,fill_value=0)#,margins =True)\n",
    "        ds2 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Reason'] , values = 'Remarks' , aggfunc = len ,fill_value=0)\n",
    "        ds2 = ds2[ds2.columns.tolist()]\n",
    "        ds3 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Status'] , values = 'Remarks' , aggfunc = len ,fill_value=0)\n",
    "        ds3['Total'] = ds3['Fully Communicated'] + ds3['Not Communicated'] + ds3['Partially Communicated']\n",
    "        ds3['NANO %'] = (ds3['Fully Communicated']/ ds3[\"Total\"])*100\n",
    "        Summary = pd.concat([ds3[['NANO %']],ds2,ds1],keys=[' ','Reason for NANO Absence','Issue Classification'],axis=1)\n",
    "\n",
    "        Summary = Summary.T[a].T  # Filtering State wise\n",
    "\n",
    "        ts = Summary[['Reason for NANO Absence','Issue Classification']]\n",
    "        ts = ts.T\n",
    "        ts['Grand Total'] = ts.sum(axis = 1)\n",
    "        ts = ts.fillna(0)\n",
    "        ts = ts.T.astype(int)\n",
    "        tn = Summary[[' ']]\n",
    "        tn = tn.T\n",
    "        tn['Grand Total'] = tn.mean(axis=1)\n",
    "        tn = tn.T\n",
    "        tn = tn.round(2)\n",
    "        Summary = pd.concat([tn,ts],axis=1)\n",
    "        Summary = Summary.replace(0,' ')\n",
    "\n",
    "\n",
    "        # Building Main Data & Pivot_Tables\n",
    "\n",
    "        # 1\n",
    "        a1 = Data_HPCL[['State Office','Remarks']]\n",
    "        a2 = pd.get_dummies(Data_HPCL['Dependency'])\n",
    "        #a2.columns = ['AGS','DEALER','HPCL']\n",
    "        Data_HPCL_t = pd.concat([a1,a2],axis=1)\n",
    "        Data_HPCL_m = Data_HPCL_t[Data_HPCL_t['State Office'] == a]\n",
    "        Data_HPCLp1 = Data_HPCL_m.set_index('Remarks')\n",
    "        Pivot_1 = Data_HPCLp1.groupby('Remarks').sum()\n",
    "\n",
    "        Pivot_1.loc['Grand Total'] = Pivot_1.sum()  # for column \n",
    "        Pivot_1['Grand Total'] = Pivot_1.sum(axis=1) # for row\n",
    "        Pivot_1 = Pivot_1.replace(0 ,' ')\n",
    "        P_t1 = Pivot_1.iloc[:,0:3]\n",
    "        P_t2 = Pivot_1[['Grand Total']]\n",
    "        Pivot_1 = pd.concat([P_t1,P_t2] , keys = ['Dependency' , ' '] , axis = 1)\n",
    "\n",
    "\n",
    "        # 2\n",
    "        Data_HPCL = Data_HPCL[Data_HPCL['State Office'] == a]   # Breaking State Office wise\n",
    "        ttdf = Data_HPCL[Data_HPCL.columns.tolist()[31:]]\n",
    "        tdf = pd.concat([Data_HPCL.Region,ttdf],axis=1)\n",
    "        Pivot_2 = tdf.groupby('Region').count().T\n",
    "        Pivot_2['Grand Total'] = Pivot_2.sum(axis=1) # for row\n",
    "        Pivot_2 = Pivot_2.replace(0,np.nan)\n",
    "        Pivot_2 = Pivot_2.dropna(how = 'all',axis=0)\n",
    "        Pivot_2 = Pivot_2.fillna(0)\n",
    "        Pivot_2 = Pivot_2.astype(int)\n",
    "        Pivot_2 = Pivot_2.replace(0 , ' ')\n",
    "\n",
    "        # Finalizing Data\n",
    "\n",
    "        Data_HPCL = Data_HPCL.drop('State',axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #...................................................BPCL...........................................................#\n",
    "\n",
    "        #Extracting Required Data BPCL\n",
    "\n",
    "        prod1 = pd.read_excel(URL5 + '\\Prod1 ' + TD + '.xlsx')    # Production 1\n",
    "        prod2 = pd.read_excel(URL6 + '\\Prod2 ' + TD + '.xlsx')  # Production 2  \n",
    "        Pan_India = pd.read_excel(URL10 + '\\BPCL_Pan_India_Report_' + YD + '.xlsx')\n",
    "        location = pd.read_excel(URL3 + '\\Zone_State_Region' + '.xlsx','BPCL')      # Fixed location\n",
    "        HOS = pd.read_excel(URL7 + '\\BPCL_HOS_' + TD + '.xlsx')   # HOS Onboarding\n",
    "\n",
    "        # CLeaning ALL Above\n",
    "\n",
    "        Pan_India = Pan_India.drop_duplicates(subset = 'CC')\n",
    "\n",
    "        Pan_India = Pan_India.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        Pan_India = Pan_India.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        location = location.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        location = location.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "\n",
    "        # MAking a copy of Yesterday's Pan_India_BPCL\n",
    "\n",
    "        BPCL = Pan_India\n",
    "\n",
    "\n",
    "        # Building Pan_India_Data\n",
    "\n",
    "        HOS_lst = HOS.iloc[1,:].tolist()\n",
    "        HOS.columns = [HOS_lst]\n",
    "        HOS = HOS.iloc[2:,:]\n",
    "\n",
    "        Final_HOS = HOS[['RO SAPCC','Status']]\n",
    "        Final_HOS.columns = ['CC','Status']\n",
    "        Final_HOS = Final_HOS.drop_duplicates(subset = ['CC'])\n",
    "\n",
    "        Pan_lst = Pan_India.columns.tolist()\n",
    "        Pan_India['CC'] = Pan_India['CC'].astype(int)\n",
    "        Final_HOS['CC'] = Final_HOS['CC'].astype(int)\n",
    "\n",
    "        Final_HOS1 = Final_HOS[['CC']]\n",
    "        Final_HOS1['Onboarded- YES/NO'] = 'YES'\n",
    "\n",
    "        Final_HOS2 = Final_HOS\n",
    "        Final_HOS2['Onboarding Reflecting On Server'] = np.nan\n",
    "        Final_HOS2.loc[Final_HOS2['Status'] == 'Completed' , ['Onboarding Reflecting On Server']] = 'YES'\n",
    "        Final_HOS2.loc[Final_HOS2['Status'] == 'Initiated' , ['Onboarding Reflecting On Server']] = 'NO'\n",
    "        Final_HOS2 = Final_HOS2.drop('Status',axis=1)\n",
    "\n",
    "        prod1.columns = prod1.iloc[1,:]\n",
    "        prod2.columns = prod2.iloc[1,:]\n",
    "        prod1 = prod1.iloc[2:,:]\n",
    "        prod2 = prod2.iloc[2:,:]\n",
    "        prod1 = prod1.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        prod2 = prod2.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        prod1 = prod1.drop_duplicates(subset='RO SAP CC',keep='first')\n",
    "        prod2 = prod2.drop_duplicates(subset='RO SAP CC',keep='first')\n",
    "        Final_Prod = pd.DataFrame(list(set(list(set(list(prod1['RO SAP CC']) + list(prod2['RO SAP CC']))))))\n",
    "        Final_Prod.columns = ['CC']\n",
    "        Final_Prod['CC'] = Final_Prod['CC'].astype(int)\n",
    "\n",
    "        Final_Prod['Today Auto RSP'] = 'YES'\n",
    "\n",
    "        Pan_India['Previous Day Auto RSP'] = Pan_India['Today Auto RSP']\n",
    "\n",
    "\n",
    "        Pan_India = Pan_India.drop(columns = ['Today Auto RSP','Onboarded- YES/NO','Onboarding Reflecting On Server','Sr no'])\n",
    "\n",
    "\n",
    "        Pan_India = Final_Prod.merge(Pan_India , how = 'outer' , on = ['CC'])\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "        Final_HOS3 = Final_HOS1.merge(Final_HOS2 , how = 'outer' , on =['CC'])\n",
    "        Final_HOS3 = Final_HOS3.reset_index().drop('index',axis=1)\n",
    "        Pan_India = Final_HOS3.merge(Pan_India , how = 'outer' , on = ['CC'])\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "\n",
    "\n",
    "        Pan_India.loc[Pan_India['Today Auto RSP'] == 'YES' , ['Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence','Dependency for Auto-RSP Absence','Reasons for sites not upgraded','Remarks for sites not upgraded','Dependency for Sites not upgraded','Description']] = np.nan\n",
    "\n",
    "        Pan_India.loc[Pan_India['Today Auto RSP'].isnull(),['Today Auto RSP']] = 'NO'\n",
    "        Pan_India.loc[Pan_India['Onboarding Reflecting On Server'].isnull(),['Onboarding Reflecting On Server']] = 'NO'\n",
    "        Pan_India.loc[Pan_India['Onboarded- YES/NO'].isnull(),['Onboarded- YES/NO']] = 'NO'\n",
    "\n",
    "\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Reasons for Auto-RSP Absence'].isnull()) , ['Reasons for Auto-RSP Absence']] = 'TBF'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Remarks for AUTO-RSP absence'].isnull()), ['Remarks for AUTO-RSP absence' ]] = 'TO BE FOUND'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Dependency for Auto-RSP Absence'].isnull()),['Dependency for Auto-RSP Absence']] = 'AGS'\n",
    "\n",
    "\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Reasons for sites not upgraded'].isnull()),['Reasons for sites not upgraded']] = 'TBF'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Remarks for sites not upgraded'].isnull()),['Remarks for sites not upgraded']] = 'TO BE FOUND'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Dependency for Sites not upgraded'].isnull()),['Dependency for Sites not upgraded']] = 'AGS'\n",
    "\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "        Pan_India['Sr no'] = np.nan\n",
    "        Pan_India['Sr no'] = list(range(1,len(Pan_India)+1))\n",
    "        Pan_India = Pan_India[Pan_lst]\n",
    "\n",
    "\n",
    "\n",
    "        # Pivot_1 (P1) (Auto-RSP)\n",
    "\n",
    "        India = Pan_India.drop('Region', axis = 1)\n",
    "        India['Dependency for Sites not upgraded'] = India['Dependency for Sites not upgraded'].replace('BPCl','BPCL')\n",
    "        India = India.rename(columns = {'Territory':'Region'})\n",
    "        India['Region'] = India['Region'].str.upper()\n",
    "        India = India.merge(location[['State Office','Region']] , on = ['Region'])\n",
    "        India = India.drop_duplicates()\n",
    "        P1 = pd.get_dummies(India['Dependency for Auto-RSP Absence'])\n",
    "        #P1.columns = ['AGS','BPCL','DEALER']\n",
    "        P1 = pd.concat([P1,India[['State Office','Remarks for AUTO-RSP absence']]],axis = 1)\n",
    "        P1 = P1.loc[(P1['State Office'] == a) & (P1['Remarks for AUTO-RSP absence'] == P1['Remarks for AUTO-RSP absence']),['Remarks for AUTO-RSP absence','AGS','BPCL','DEALER','TBF']]\n",
    "        P1 = pd.concat([P1.groupby('Remarks for AUTO-RSP absence').sum()] , keys = ['Dependency for Auto-RSP Absence'] , axis = 1)\n",
    "        P1.loc['Grand Total'] = P1.sum()  # for column \n",
    "        P1['Grand Total'] = P1.sum(axis=1) # for row\n",
    "        P1 = P1.astype(int)\n",
    "        P1.replace(0, ' ', inplace = True)\n",
    "\n",
    "        # Pivot_2 (P2) ()\n",
    "\n",
    "        P2 = pd.get_dummies(India['Dependency for Sites not upgraded'])\n",
    "        #P2.columns = ['AGS','BPCL']\n",
    "        P2 = pd.concat([P2,India[['State Office','Remarks for sites not upgraded']]],axis = 1)\n",
    "        P2 = P2.loc[(P2['State Office'] == a) & (P2['Remarks for sites not upgraded'] == P2['Remarks for sites not upgraded']),['Remarks for sites not upgraded','AGS','BPCL']]\n",
    "        P2 = pd.concat([P2.groupby('Remarks for sites not upgraded').sum()] , keys = ['Dependency for Sites not upgraded'] , axis = 1)\n",
    "        P2.loc['Grand Total'] = P2.sum()  # for column \n",
    "        P2['Grand Total'] = P2.sum(axis=1) # for row\n",
    "        P2 = P2.astype(int)\n",
    "        P2.replace(0, ' ', inplace = True)\n",
    "\n",
    "        # Summary (S) \n",
    "\n",
    "        T_India = India[India['State Office'] == a]\n",
    "\n",
    "\n",
    "                                      # Changing names #\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'TBF' , ['Reasons for sites not upgraded']] ='TBF-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'RAP' , ['Reasons for sites not upgraded']] ='RAP-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'FVP' , ['Reasons for sites not upgraded']] ='FVP-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'II' , ['Reasons for sites not upgraded']] ='II-U'\n",
    "\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'AGS' , ['Dependency for Sites not upgraded']] ='AGS-U'\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'BPCL' , ['Dependency for Sites not upgraded']] ='BPCL-U'\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'DEALER' , ['Dependency for Sites not upgraded']] ='DEALER-U'\n",
    "\n",
    "\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'TBF' , ['Reasons for Auto-RSP Absence']] ='TBF-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'RAP' , ['Reasons for Auto-RSP Absence']] ='RAP-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'FVP' , ['Reasons for Auto-RSP Absence']] ='FVP-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'II' , ['Reasons for Auto-RSP Absence']] ='II-A'\n",
    "\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'AGS' , ['Dependency for Auto-RSP Absence']] ='AGS-A'\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'BPCL' , ['Dependency for Auto-RSP Absence']] ='BPCL-A'\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'DEALER' , ['Dependency for Auto-RSP Absence']] ='DEALER-A'\n",
    "\n",
    "\n",
    "\n",
    "        S1 = T_India.loc[India['Upgraded-Yes/No'] == 'YES' , ['Region','Upgraded-Yes/No']].groupby('Region').count()\n",
    "        S2 = T_India.loc[India['Onboarded- YES/NO'] == 'YES' , ['Region','Onboarded- YES/NO']].groupby('Region').count()\n",
    "        S3 = pd.DataFrame(T_India['Region'].value_counts())\n",
    "        S4 = T_India.loc[T_India['Onboarding Reflecting On Server'] == 'YES' , ['Region','Onboarding Reflecting On Server']].groupby('Region').count()\n",
    "        S5 = T_India.loc[T_India['Today Auto RSP'] == 'YES' , ['Region','Today Auto RSP']].groupby('Region').count()\n",
    "\n",
    "        S5['Auto RSP %'] = (S5['Today Auto RSP']/S1['Upgraded-Yes/No'])*100\n",
    "\n",
    "        S5 = S5.round(2)\n",
    "        S6 = pd.get_dummies(T_India['Reasons for sites not upgraded']).groupby(T_India['Region']).sum()\n",
    "        S7 = pd.get_dummies(T_India['Dependency for Sites not upgraded']).groupby(T_India['Region']).sum()\n",
    "        S8 = pd.get_dummies(T_India['Reasons for Auto-RSP Absence']).groupby(T_India['Region']).sum()\n",
    "        S9 = pd.get_dummies(T_India['Dependency for Auto-RSP Absence']).groupby(T_India['Region']).sum()\n",
    "\n",
    "        S = S1.join(S2).join(S3).join(S4).join(S5).join(S6).join(S7).join(S8).join(S9).fillna(0).astype(int)\n",
    "\n",
    "        s0 = S[['Upgraded-Yes/No','Onboarded- YES/NO','Region','Onboarding Reflecting On Server','Today Auto RSP','Auto RSP %']]\n",
    "        s0.columns = ['UPGRADED','ONBOARDED','GRAND TOTAL','ONBOARDING REFLECTING ON SERVER','AUTO RSP','AUTO RSP %']\n",
    "        s1 = S[S6.columns.tolist()]\n",
    "        s2 = S[S7.columns.tolist()]\n",
    "        s3 = S[S8.columns.tolist()]\n",
    "        s4 = S[S9.columns.tolist()]\n",
    "\n",
    "        Summary_b = pd.concat([s0.reset_index().drop('Region',axis=1),s1.reset_index().drop('Region',axis=1),s2.reset_index().drop('Region',axis=1),s3.reset_index().drop('Region',axis=1),s4.reset_index().drop('Region',axis=1)] , keys = [' ','Reasons for sites not upgraded','ISSUE CLASSIFICATION','Reasons for Auto-RSP Absence','ISSUE CLASSIFICATION_1'],axis=1)\n",
    "        Summary_b['Zone'] = a\n",
    "        Summary_b['Region'] = s0.reset_index()['Region']\n",
    "        Summary_b = Summary_b.groupby(['Zone','Region']).first()\n",
    "        Summary_b = Summary_b.T\n",
    "        Summary_b['Grand Total'] = Summary_b.sum(axis = 1) # for row\n",
    "        Summary_b = Summary_b.T\n",
    "        Summary_b = Summary_b.astype(int)\n",
    "\n",
    "        if len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) > 0:\n",
    "            Summary_b.iloc[-1,5] = sum(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) / len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1])\n",
    "        elif len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) == 0:\n",
    "            Summary_b.iloc[-1,5] = 0\n",
    "\n",
    "        Summary_b = Summary_b.astype(int)\n",
    "        Summary_b = Summary_b.replace(0,' ')\n",
    "\n",
    "        # Building State_Office_Wise_Data\n",
    "\n",
    "        Pan_India = Pan_India.merge(location[['State','State Office']] , how = 'left' , on = ['State'])\n",
    "\n",
    "\n",
    "        BPCL_2 = Pan_India    # Copy of pan india\n",
    "        BPCL_2 = BPCL_2.drop('State Office',axis=1)\n",
    "        BPCL_2 = BPCL_2.drop_duplicates(subset='CC')\n",
    "        BPCL_2['Sr no'] = list(range(1,len(BPCL_2['Sr no'])+1))\n",
    "\n",
    "        Pan_India = Pan_India[Pan_India['State Office'] == a]\n",
    "        Pan_India = Pan_India.drop('State Office',axis=1)\n",
    "        Pan_India = Pan_India.drop_duplicates(subset='CC')\n",
    "        Pan_India['Sr no'] = list(range(1,len(Pan_India['Sr no'])+1))\n",
    "\n",
    "        # Building Pivot 3\n",
    "\n",
    "        p3 = Pan_India\n",
    "\n",
    "        p3 =p3[['Territory','FCC(WIRED)', 'INTERFACE CARD', 'FCC(WIRELESS)', 'SLAVE',\n",
    "               'MONILITH SLAVE', 'MASTER', 'SMPS(5V)', 'SMPS(12V)', 'SLAVE SMPS',\n",
    "               'MONITOR', 'KEYBOARD', 'MOUSE', 'OTHERS']]\n",
    "\n",
    "        p3 = p3.replace(np.nan , 0)\n",
    "        p3 = p3.groupby('Territory').sum().T\n",
    "        p3.loc['GRAND TOTAL'] = p3.sum()\n",
    "        p3 = p3.astype(int)\n",
    "        p3 = p3.replace(0 , np.nan)\n",
    "        p3 = pd.concat([p3],keys = ['REGION'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        #.............................................NAYARA REPORTS...................................................#\n",
    "\n",
    "\n",
    "\n",
    "        nayara = pd.read_excel(URL24 + slash + a + '.xlsx', 'NAYARA DETAILS')\n",
    "        nayara.columns = cols_nayara\n",
    "\n",
    "        nayara = nayara.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "        nayara = nayara.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        nayara = nayara.drop_duplicates(subset = 'CMS Code')\n",
    "        nayara = nayara.reset_index().drop('index',axis=1)\n",
    "        nayara['Sr No.'] = list(range(1,len(nayara)+1))\n",
    "\n",
    "\n",
    "        # SUMMARY nayara state wise\n",
    "\n",
    "        s = nayara[['Zone', 'State','Division','CMS Code','I & C Status', 'HOTO Done','HOTO - Uploaded','O&M Call Status (Open/Closed)'\n",
    "                    ,'Spare Requirement','Delivery Status']]\n",
    "        s.loc[s['I & C Status'] == 'COMPLETED', ['I & C Status']] = 'I/C Completed'\n",
    "        s.loc[s['I & C Status'] == 'PENDING' , ['I & C Status']] = 'I/C Pending'\n",
    "\n",
    "        s.loc[s['HOTO Done'] == 'N',['HOTO Done']] = 'HOTO Pending'\n",
    "\n",
    "        s.loc[s['HOTO - Uploaded'] == 'Y' , ['HOTO - Uploaded']] = 'HOTO Uploaded'\n",
    "        s.loc[s['O&M Call Status (Open/Closed)'] == 'OPEN',['O&M Call Status (Open/Closed)']] = 'O&M Open calls'\n",
    "\n",
    "        s.loc[(s['I & C Status'] != 'I/C Completed') & (s['I & C Status'] != 'I/C Pending') , ['I & C Status']] = np.nan\n",
    "        s.loc[s['HOTO Done'] != 'HOTO Pending' ,['HOTO Done']] = np.nan\n",
    "        s.loc[s['HOTO - Uploaded'] != 'HOTO Uploaded' , ['HOTO - Uploaded']] = np.nan\n",
    "        s.loc[s['O&M Call Status (Open/Closed)'] != 'O&M Open calls' , ['O&M Call Status (Open/Closed)']] = np.nan\n",
    "\n",
    "\n",
    "        s1 = pd.get_dummies(s['I & C Status'])\n",
    "        s2 = pd.get_dummies(s['HOTO - Uploaded'])\n",
    "\n",
    "        if len(s.loc[s['HOTO - Uploaded'].isnull(),['HOTO - Uploaded']]) == len(s):\n",
    "            s2['HOTO Uploaded'] = 0\n",
    "\n",
    "        s3 = pd.get_dummies(s['HOTO Done'])\n",
    "\n",
    "        if len(s.loc[s['HOTO Done'].isnull(),['HOTO Done']]) == len(s):\n",
    "            s3['HOTO Pending'] = 0\n",
    "\n",
    "        s4 = pd.get_dummies(s['O&M Call Status (Open/Closed)'])\n",
    "        ro = s[['CMS Code']]\n",
    "        ro['CMS Code'] = 1\n",
    "        ro.columns = ['Total RO']\n",
    "\n",
    "        Summary_N = pd.concat([s[['Zone','State','Division']],ro,s1,s2,s3,s4],axis=1)\n",
    "\n",
    "        Summary_N = Summary_N.groupby(['Zone','State','Division']).sum()\n",
    "        Summary_N = Summary_N.T\n",
    "        Summary_N['GRAND TOTAL'] = Summary_N.sum(axis=1)\n",
    "        Summary_N = Summary_N.T\n",
    "        Summary_N['HOTO Pending'] = Summary_N['Total RO'] - Summary_N['HOTO Uploaded']\n",
    "        Summary_State_NAYARA = Summary_N.astype(int)\n",
    "        Summary1_State_NAYARA = Summary_State_NAYARA   # For Mails\n",
    "        Summary1_State_NAYARA = Summary1_State_NAYARA.replace(0,' ')\n",
    "\n",
    "\n",
    "\n",
    "        # HOTO PIVOT Nayara State wise\n",
    "        tHP = nayara[['HOTO Remarks']]\n",
    "        tHP.columns = ['Count Of Remarks']\n",
    "        HP = pd.concat([nayara[['HOTO Dependency','HOTO Remarks']],tHP],axis=1)\n",
    "        HP = HP.dropna()\n",
    "        HP = HP.groupby(['HOTO Dependency','HOTO Remarks']).count()\n",
    "        HP = HP.replace(0,' ')\n",
    "\n",
    "\n",
    "        # O & M PIVOT Nayara State Wise\n",
    "\n",
    "\n",
    "        tOM = nayara[['O & M Remarks']]\n",
    "        tOM.columns = ['Count Of Remarks']\n",
    "        OM = pd.concat([nayara[['O & M Dependency','O & M Remarks']],tOM],axis=1)\n",
    "        OM = OM.dropna()\n",
    "        OM = OM.groupby(['O & M Dependency','O & M Remarks']).count()\n",
    "        OM = OM.replace(0,' ')\n",
    "\n",
    "        # SPARE PIVOT NAyara State Wise\n",
    "\n",
    "        p=nayara[['State','BOS CARD', 'FCC CARD', '5 VOLT SMPS', 'INTERFACE CARD',\n",
    "               'FCC with Accessory', 'DOOR LOCK RFID', 'Barrier board', 'Glands',\n",
    "               '12 SMPS', 'Total ATG probe', '2M', '2.25 M', '2.50 M', '2.75 M',\n",
    "               '3 M', 'HSD Density Float Kit', 'MS Density Float Kit',\n",
    "               'PRODUCT FLOAT KIT', 'WATER FLOAT KIT', 'RFID TAG', 'RFID READER',\n",
    "               'Neck Ribbon', 'Slave', 'MASTER', 'COMM Cable (M)', 'Epoxy KIT',\n",
    "               'MONITOR', 'KEYBOARD', 'MOUSE', 'USB HUB', 'MONITOR POWER CABLE',\n",
    "               'VGA CABLE', 'MCB', 'SPD', 'ROUTER', 'ROUTER ADOPTER', 'PATCH CORD (M)']]\n",
    "        Pivot = p.groupby('State').sum().T\n",
    "        Pivot['GRAND TOTAL'] = Pivot.sum(axis=1)\n",
    "        Pivot = Pivot.astype(int).replace(0,' ')\n",
    "\n",
    "\n",
    "        # Maintaining Files\n",
    "\n",
    "        if len(HP) == 0:\n",
    "            HP = HP.reset_index()\n",
    "\n",
    "        if len(OM) == 0:\n",
    "            OM = OM.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "        print('\\033[0m' + 'Files Made Succesfully')\n",
    "        print('\\033[0m' + 'Styling & Exporting Files Please Wait...')\n",
    "\n",
    "        # Styling Getting the content to be centered \n",
    "\n",
    "        Data_HPCL_s = Data_HPCL.style.set_properties(**{'text-align':'center'})\n",
    "        Summary_s = Summary.style.set_properties(**{'text-align':'center'})\n",
    "        Pivot_1_s = Pivot_1.style.set_properties(**{'text-align':'center'})\n",
    "        Pivot_2_s = Pivot_2.style.set_properties(**{'text-align':'center'})\n",
    "        #UPDATED_PAN_HPCL_REMARKS_s = UPDATED_PAN_HPCL_REMARKS.style.set_properties(**{'text-align':'center'})\n",
    "\n",
    "        Final_Statewise_India_s = Pan_India.style.set_properties(**{'text-align':'center'})\n",
    "        P1_s = P1.style.set_properties(**{'text-align':'center'})\n",
    "        P2_s = P2.style.set_properties(**{'text-align':'center'})\n",
    "        P3_s = p3.style.set_properties(**{'text-align':'center'})\n",
    "        Summary_b_s = Summary_b.style.set_properties(**{'text-align':'center'})\n",
    "        #UPDATED_PAN_BPCL_REMARKS_s = UPDATED_PAN_BPCL_REMARKS.style.set_properties(**{'text-align':'center'})\n",
    "\n",
    "\n",
    "        # Exporting Neccessary Files  (HPCL)\n",
    "\n",
    "        Destination_URL = URL8 + '\\HPCL_' + a + '_' + TD +'.xlsx'\n",
    "\n",
    "        writer1 = pd.ExcelWriter(Destination_URL , engine = 'xlsxwriter')\n",
    "        #UPDATED_PAN_HPCL_REMARKS_s.to_excel(writer1 , sheet_name = 'UPDATED REMARKS HPCL',index=False)\n",
    "        Summary_s.to_excel(writer1 , sheet_name = 'Summary')\n",
    "        Pivot_1_s.to_excel(writer1 , sheet_name = 'Pivot_Remarks')\n",
    "        Pivot_2_s.to_excel(writer1 , sheet_name = 'Pivot_Spares')\n",
    "        Data_HPCL_s.to_excel(writer1 , sheet_name = 'Data' , index = False)\n",
    "        writer1.save()\n",
    "\n",
    "\n",
    "        # Exporting Neccessary Files  (BPCL)\n",
    "\n",
    "        Destination_URL_B = URL9 + '\\BPCL_' + a + '_' + TD +'.xlsx'\n",
    "\n",
    "        writer2 = pd.ExcelWriter(Destination_URL_B , engine = 'xlsxwriter')\n",
    "        #UPDATED_PAN_BPCL_REMARKS_s.to_excel(writer2 , sheet_name = 'UPDATED REMARKS BPCL',index=False)\n",
    "        Summary_b_s.to_excel(writer2 , sheet_name = 'Summary')\n",
    "        P1_s.to_excel(writer2 , sheet_name = 'Issue Analysis Auto RSP')\n",
    "        P2_s.to_excel(writer2 , sheet_name = 'Issue Analysis Pending Upgrades')\n",
    "        P3_s.to_excel(writer2 , sheet_name = 'Spare Required')\n",
    "        Final_Statewise_India_s.to_excel(writer2 , sheet_name = 'Data' , index = False)\n",
    "        writer2.save()\n",
    "\n",
    "        # EXPORTING FILES NAYARA STATE WISE\n",
    "\n",
    "        Destination_URL_STATE_NAYARA = URL23 + slash + 'NAYARA_' + a + '_' + TD + '.xlsx'\n",
    "\n",
    "        writer6 = pd.ExcelWriter(Destination_URL_STATE_NAYARA , engine = 'xlsxwriter')\n",
    "        Summary_State_NAYARA.to_excel(writer6 , sheet_name = 'NAYARA SUMMARY')\n",
    "        HP.to_excel(writer6 , sheet_name = 'HOTO PIVOT')\n",
    "        OM.to_excel(writer6 , sheet_name = 'O&M PIVOT')\n",
    "        Pivot.to_excel(writer6,sheet_name = 'SPARE PIVOT')\n",
    "        nayara.to_excel(writer6 , sheet_name = 'NAYARA DETAILS' , index = False)\n",
    "        writer6.save()\n",
    "\n",
    "\n",
    "        print('\\033[0m' + 'All Files Saved Succesfully')\n",
    "\n",
    "\n",
    "        # Extracting State_Head Information & Team\n",
    "\n",
    "        SOG = pd.read_excel(URL4 + '\\StatesOffice_Gmail.xlsx')\n",
    "        SOG = SOG.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        State_Head_Name = SOG.loc[SOG['State Office'] == a , ['State Head']].iloc[0,0]\n",
    "        State_Head_Email = SOG.loc[SOG['State Office'] == a , ['Email ID']].iloc[0,0]\n",
    "        Monitoring_Team = SOG.loc[SOG['State Office'] == a , ['BCC 3']].iloc[0,0]\n",
    "        cc1 = SOG.loc[SOG['State Office'] == a , ['CC 1']].iloc[0,0]\n",
    "        cc2 = SOG.loc[SOG['State Office'] == a , ['CC 2']].iloc[0,0]\n",
    "\n",
    "        # Gmail Sender Final\n",
    "\n",
    "        print('\\033[0m' + 'Getting Access to Gmail Server Please Wait...')\n",
    "\n",
    "        email_user = 'monitoring-team@agsindia.com'      # Monitoring Team Mail ID\n",
    "        email_password = '*****'                  # Monitoring Team Password\n",
    "\n",
    "        # Automatic\n",
    "        email_send = State_Head_Email  \n",
    "\n",
    "        cc = [cc1,cc2]  \n",
    "        bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com',Monitoring_Team]                                 \n",
    "\n",
    "\n",
    "        subject = a + ' Operational Updates'\n",
    "\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = email_user\n",
    "        msg['To'] = email_send\n",
    "        msg['Subject'] = subject\n",
    "        msg['Cc'] = \", \".join(cc)\n",
    "\n",
    "        # Creating HTML Bodies Based on team\n",
    "\n",
    "        manroop = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "               <br>NAYARA Summary:<br>\n",
    "               {6}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>Regards,\n",
    "               <br>Manroop Jhajharia,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 8239300577\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html()\n",
    "                   ,Summary1_State_NAYARA.to_html() )\n",
    "\n",
    "        jaspal = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "               <br>NAYARA Summary:<br>\n",
    "               {6}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Jaspal Singh,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 7986017094\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html(),\n",
    "                  Summary1_State_NAYARA.to_html())\n",
    "\n",
    "\n",
    "        suhas = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "               <br>NAYARA Summary:<br>\n",
    "               {6}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Suhas Dhande,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 9403831912\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html()\n",
    "                  ,Summary1_State_NAYARA.to_html())\n",
    "\n",
    "\n",
    "        bipul_1 = \"\"\"\\              \n",
    "        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Bipul Kumar,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 7903636882\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html() )\n",
    "\n",
    "\n",
    "        bipul_2 = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "               <br>NAYARA Summary:<br>\n",
    "               {6}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Bipul Kumar,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 7903636882\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html()\n",
    "                  ,Summary1_State_NAYARA.to_html())\n",
    "\n",
    "\n",
    "        abhijit= \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HCPL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "               <br>NAYARA Summary:<br>\n",
    "               {6}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Abhijit Maity,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 9563626404\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html() \n",
    "                  ,Summary1_State_NAYARA.to_html())\n",
    "\n",
    "\n",
    "        gufran = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "               <br>NAYARA Summary:<br>\n",
    "               {6}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Mohd Gufran Khan,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 7703016246\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html() \n",
    "                  ,Summary1_State_NAYARA.to_html())\n",
    "\n",
    "\n",
    "        varun = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "               <br>NAYARA Summary:<br>\n",
    "               {6}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Varun Kumar,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 8146140803\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html()\n",
    "                  ,Summary1_State_NAYARA.to_html())\n",
    "\n",
    "\n",
    "        Deepali = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Deepali Shirsat,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html() )\n",
    "\n",
    "\n",
    "        manoj = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated operational details for your state(s) below:<br>\n",
    "\n",
    "               <br>HPCL Summary:<br>\n",
    "               {0}\n",
    "               <br>Issue Analysis:<br>\n",
    "               {1}\n",
    "               <br>Spares:<br>\n",
    "               {2}\n",
    "               <br>BPCL Summary:<br>\n",
    "               {3}\n",
    "               <br>Issue Analysis : Auto RSP<br>\n",
    "               {4}\n",
    "               <br>Issue Analysis : Pending Upgrades<br>\n",
    "               {5}\n",
    "               <br>NAYARA Summary:<br>\n",
    "               {6}\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>\n",
    "               <br>Regards,\n",
    "               <br>Varun Kumar,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd\n",
    "               <br>(M):+91 - 8146140803\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(Summary.to_html(), Pivot_1.to_html() ,Pivot_2.to_html(), Summary_b.to_html(), P1.to_html(),P2.to_html()\n",
    "                  ,Summary1_State_NAYARA.to_html())\n",
    "\n",
    "\n",
    "\n",
    "        if a == 'DSO' or a == 'RSO' or a == 'GSO':\n",
    "            msg.attach(MIMEText(manroop,'html'))\n",
    "        elif a == 'KASO':\n",
    "            msg.attach(MIMEText(jaspal,'html'))\n",
    "        elif a == 'TAPSO':\n",
    "            msg.attach(MIMEText(suhas,'html'))\n",
    "        elif a == 'TNSO':\n",
    "            msg.attach(MIMEText(bipul_1,'html'))\n",
    "        elif a == 'MPSO' or a == 'BSO' or a == 'CHSO':\n",
    "            msg.attach(MIMEText(bipul_2,'html'))\n",
    "        elif a == 'WBSO' or a == 'ODSO' or a == 'NESO' or a == 'JSO':\n",
    "            msg.attach(MIMEText(abhijit,'html'))\n",
    "        elif a == 'UPSO I' or a == 'UPSO II':\n",
    "            msg.attach(MIMEText(gufran,'html'))\n",
    "        elif a == 'PBSO I' or a == 'PBSO II':\n",
    "            msg.attach(MIMEText(varun,'html'))\n",
    "        elif a == 'KESO':\n",
    "            msg.attach(MIMEText(Deepali,'html'))\n",
    "        elif a == 'MSO' or a == 'ROM':\n",
    "            msg.attach(MIMEText(manoj,'html'))\n",
    "        elif a == 'MHSO':\n",
    "            msg.attach(MIMEText(manoj,'html'))\n",
    "\n",
    "\n",
    "        if a == 'TNSO' or a == 'KESO':\n",
    "            files = [Destination_URL , Destination_URL_B]    #\n",
    "\n",
    "            for a_file in files:\n",
    "                attachment  = open(a_file,'rb')   #\n",
    "                file_name = os.path.basename(a_file)\n",
    "                part = MIMEBase('application','octet-stream')\n",
    "                part.set_payload((attachment).read())\n",
    "                encoders.encode_base64(part)    #\n",
    "                part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "                msg.attach(part)\n",
    "\n",
    "            text = msg.as_string()\n",
    "            #try:\n",
    "            server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "            server.starttls()\n",
    "            server.login(email_user,email_password)\n",
    "\n",
    "\n",
    "            server.sendmail(email_user,[email_send] + cc + bcc,text)\n",
    "            server.quit()\n",
    "\n",
    "        else:\n",
    "            files = [Destination_URL , Destination_URL_B , Destination_URL_STATE_NAYARA]    #\n",
    "\n",
    "            for a_file in files:\n",
    "                attachment  = open(a_file,'rb')   #\n",
    "                file_name = os.path.basename(a_file)\n",
    "                part = MIMEBase('application','octet-stream')\n",
    "                part.set_payload((attachment).read())\n",
    "                encoders.encode_base64(part)    #\n",
    "                part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "                msg.attach(part)\n",
    "\n",
    "            text = msg.as_string()\n",
    "            #try:\n",
    "            server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "            server.starttls()\n",
    "            server.login(email_user,email_password)\n",
    "\n",
    "\n",
    "            server.sendmail(email_user,[email_send] + cc + bcc,text)\n",
    "            server.quit()\n",
    "\n",
    "\n",
    "        print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + a + '\\033[0m' + ' Report To ' + '\\033[1m' + '\\033[92m' + SOG.loc[SOG['State Office'] == a , ['State Head']].iloc[0,0])\n",
    "\n",
    "        incrementer += 1 \n",
    "\n",
    "        if incrementer < len(incrementer_lst):\n",
    "            print('\\033[0m' + 'Wait Next File, In Process...')\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'Extracting NEW SITES Records...')\n",
    "\n",
    "    # Getting New Sites Records\n",
    "\n",
    "    HPCL_2 = HPCL_2[HPCL_2['Region'].isnull()]\n",
    "    HPCL_2.to_excel(URL8 + slash + 'NEW_SITES_HPCL.xlsx')\n",
    "\n",
    "    BPCL_2 = BPCL_2[(BPCL_2['Region'].isnull()) | (BPCL_2['State'].isnull()) | (BPCL_2['Territory'].isnull())]\n",
    "    BPCL_2.to_excel(URL9 + slash + 'NEW_SITES_BPCL.xlsx')\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"STATE WISE OPERATION'S SUCCESSFUL\")\n",
    "\n",
    "    # Exporting PAN_INDIA HPCL & BPCL Reports\n",
    "\n",
    "    print('\\033[0m' + 'Exporting PAN_INDIA HPCL & BPCL Reports Wait...')\n",
    "\n",
    "    # HPCL\n",
    "    states_for_pan = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO','KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "    i = 0\n",
    "    Pan_India_HPCL =pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_HPCL = pd.read_excel(URL18 + slash + TD + slash +'HPCL_' + states_for_pan[i] + '_' + TD + '.xlsx', 'Data')\n",
    "        Pan_India_HPCL = pd.concat([Pan_India_HPCL,extract_State_HPCL])\n",
    "        i +=1\n",
    "    Pan_India_HPCL.to_excel(URL11 +'\\HPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "    Pan_India_HPCL.to_excel(URL11 + '\\Backup But Without Update' + '\\HPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "\n",
    "    print('\\033[0m' + 'SUCCESSFULLY File Saved As : ' + 'HPCL_Pan_India_Report_' + TD)\n",
    "\n",
    "    # BPCL\n",
    "    i = 0\n",
    "    Pan_India_BPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_BPCL = pd.read_excel(URL17 + slash + TD + slash +'BPCL_' + states_for_pan[i] + '_' + TD + '.xlsx', 'Data')\n",
    "        Pan_India_BPCL = pd.concat([Pan_India_BPCL,extract_State_BPCL])\n",
    "        i +=1\n",
    "\n",
    "    Pan_India_BPCL['Sr no'] = list(range(1,len(Pan_India_BPCL)+1))\n",
    "    Pan_India_BPCL = Pan_India_BPCL.reset_index().drop('index',axis=1)\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\BPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\Backup But Without Update' + '\\BPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "\n",
    "    print('SUCCESSFULLY File Saved As : ' + 'BPCL_Pan_India_Report_' + TD)\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"PAN_INDIA OPERATION'S SUCCESSFUL\")\n",
    "\n",
    "\n",
    "    #.............................................................................\n",
    "\n",
    "\n",
    "    HPCL = HPCL.rename({'State Office':'State'},axis=1)\n",
    "    Y_df = Y_df.rename({'State Office':'State'},axis=1)\n",
    "    BPCL = Pan_India\n",
    "\n",
    "    #......\n",
    "    print('\\033[0m' + 'Wait In Process...')\n",
    "    CH = HPCL.loc[(HPCL['Reason'] == 'TBF') | (HPCL['Remarks'] == 'TO BE FOUND') , ['State','ROCode','Dependency','Reason','Remarks']]\n",
    "    CB = BPCL.loc[(BPCL['Reasons for sites not upgraded'] == 'TBF') | (BPCL['Remarks for sites not upgraded'] == 'TO BE FOUND') | (BPCL['Reasons for Auto-RSP Absence'] == 'TBF') | (BPCL['Remarks for AUTO-RSP absence'] == 'TO BE FOUND'), ['State','CC','Reasons for sites not upgraded','Remarks for sites not upgraded','Dependency for Sites not upgraded','Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence','Dependency for Auto-RSP Absence']]\n",
    "\n",
    "    #......\n",
    "\n",
    "    hcr = pd.read_excel(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files\\Common Remarks For HPCL & BPCL.xlsx','HPCL')\n",
    "    bcr = pd.read_excel(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files\\Common Remarks For HPCL & BPCL.xlsx','BPCL')\n",
    "    hcr['Remarks for HPCL'] = hcr['Remarks for HPCL'].str.upper()  # Since Pan India HPCL Is In Upper\n",
    "    bcr['Remarks for BPCL'] = bcr['Remarks for BPCL'].str.upper()  # Since Pan India BPCL Is In Upper \n",
    "\n",
    "\n",
    "    ags_hcr = hcr.loc[hcr['Dependency'] == 'AGS']\n",
    "    dea_hcr = hcr.loc[hcr['Dependency'] == 'DEALER']\n",
    "    hpcl_hcr = hcr.loc[hcr['Dependency'] == 'HPCL']\n",
    "\n",
    "    ags_bcr = bcr.loc[bcr['Dependency'] == 'AGS']\n",
    "    dea_bcr = bcr.loc[bcr['Dependency'] == 'DEALER']\n",
    "    bpcl_bcr = bcr.loc[bcr['Dependency'] == 'BPCL']\n",
    "\n",
    "    # HPCL\n",
    "\n",
    "    HPCL['Remarks'] = HPCL['Remarks'].str.upper()\n",
    "\n",
    "    H1 = HPCL.loc[HPCL['Dependency'] == 'AGS' , CH.columns.tolist()]\n",
    "    H1_ags_chk = H1.loc[~(H1['Remarks'].isin(ags_hcr['Remarks for HPCL']))]\n",
    "\n",
    "    H2 = HPCL.loc[HPCL['Dependency'] == 'DEALER' , CH.columns.tolist()]\n",
    "    H2_dea_chk = H2.loc[~(H2['Remarks'].isin(dea_hcr['Remarks for HPCL']))]\n",
    "\n",
    "    H3 = HPCL.loc[HPCL['Dependency'] == 'HPCL' , CH.columns.tolist()]\n",
    "    H3_hpcl_chk = H3.loc[~(H3['Remarks'].isin(hpcl_hcr['Remarks for HPCL']))]\n",
    "\n",
    "    PAN_HPCL_CHK = pd.concat([H1_ags_chk,H2_dea_chk,H3_hpcl_chk])\n",
    "    PAN_HPCL_CHK = PAN_HPCL_CHK[PAN_HPCL_CHK['Remarks'] != 'TO BE FOUND']\n",
    "\n",
    "    # BPCL\n",
    "\n",
    "\n",
    "    B1 = BPCL.loc[BPCL['Dependency for Sites not upgraded'] == 'AGS' , ['State','CC','Dependency for Sites not upgraded','Reasons for sites not upgraded','Remarks for sites not upgraded']]\n",
    "    B1_ags_chk = B1.loc[~(B1['Remarks for sites not upgraded'].isin(ags_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    B2 = BPCL.loc[BPCL['Dependency for Sites not upgraded'] == 'DEALER' , ['State','CC','Dependency for Sites not upgraded','Reasons for sites not upgraded','Remarks for sites not upgraded']]\n",
    "    B2_dea_chk = B2.loc[~(B2['Remarks for sites not upgraded'].isin(dea_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    B3 = BPCL.loc[BPCL['Dependency for Sites not upgraded'] == 'BPCL' , ['State','CC','Dependency for Sites not upgraded','Reasons for sites not upgraded','Remarks for sites not upgraded']]\n",
    "    B3_bpcl_chk = B3.loc[~(B3['Remarks for sites not upgraded'].isin(bpcl_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    PAN_BPCL_CHK_1 = pd.concat([B1_ags_chk,B2_dea_chk,B3_bpcl_chk])\n",
    "    PAN_BPCL_CHK_1 = PAN_BPCL_CHK_1[PAN_BPCL_CHK_1['Remarks for sites not upgraded'] != 'TO BE FOUND']\n",
    "\n",
    "    B4 = BPCL.loc[BPCL['Dependency for Auto-RSP Absence'] == 'AGS' , ['State','CC','Dependency for Auto-RSP Absence','Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence']]\n",
    "    B4_ags_chk = B4.loc[~(B4['Remarks for AUTO-RSP absence'].isin(ags_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    B5 = BPCL.loc[BPCL['Dependency for Auto-RSP Absence'] == 'DEALER' , ['State','CC','Dependency for Auto-RSP Absence','Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence']]\n",
    "    B5_dea_chk = B5.loc[~(B5['Remarks for AUTO-RSP absence'].isin(dea_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    B6 = BPCL.loc[BPCL['Dependency for Auto-RSP Absence'] == 'BPCL' , ['State','CC','Dependency for Auto-RSP Absence','Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence']]\n",
    "    B6_bpcl_chk = B6.loc[~(B6['Remarks for AUTO-RSP absence'].isin(bpcl_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    PAN_BPCL_CHK_2 = pd.concat([B4_ags_chk,B5_dea_chk,B6_bpcl_chk])\n",
    "    PAN_BPCL_CHK_2 = PAN_BPCL_CHK_2[PAN_BPCL_CHK_2['Remarks for AUTO-RSP absence'] != 'TO BE FOUND']\n",
    "\n",
    "    # .....\n",
    "\n",
    "    sir1 = CH.groupby('State').count()[['ROCode']].rename({'ROCode':'Not Updated ( Previous Evening )'},axis=1)\n",
    "    sir2 = PAN_HPCL_CHK.groupby('State').count()[['ROCode']].rename({'ROCode':'Wrongly Updated'},axis=1)\n",
    "    sir3 = CB.groupby('State').count()[['CC']].rename({'CC':'Not Updated ( Previous Evening )'},axis=1)\n",
    "    sir4 = PAN_BPCL_CHK_1.groupby('State').count()[['CC']].rename({'CC':'Wrongly Updated for Sites'},axis=1)\n",
    "    sir5 = PAN_BPCL_CHK_2.groupby('State').count()[['CC']].rename({'CC':'Wrongly Updated for Auto-RSP'},axis=1)\n",
    "    sir = sir1.merge(sir2, how = 'outer' , on = ['State']).merge(sir3, how='outer', on = ['State']).merge(sir4, how = 'outer' , on = ['State']).merge(sir5, how = 'outer' , on = ['State'])\n",
    "    sir = sir.fillna(0)\n",
    "    sir = sir.astype(int)\n",
    "    tsir1 = sir.iloc[:,:2]\n",
    "    tsir2 = sir.iloc[:,2:]\n",
    "\n",
    "    tsir2 = tsir2.drop_duplicates(keep = False)\n",
    "    tsir1 = tsir1.drop_duplicates(keep = False)\n",
    "\n",
    "\n",
    "    y_tdf_hpcl = Y_df.loc[Y_df['Reason'] == 'TBF' , ['State','Reason']].groupby('State').count().rename({'Reason':\"TBFs ( Previous Day )\"},axis=1)\n",
    "    y_tdf_bpcl = Y_Pan_India.loc[Y_Pan_India['Reasons for sites not upgraded'] == 'TBF' ,\n",
    "                                 ['State','Reasons for sites not upgraded']].groupby('State').count().rename({'Reasons for sites not upgraded':\"TBFs ( Previous Day )\"},axis=1)\n",
    "\n",
    "    sir_hpcl = y_tdf_hpcl.merge(tsir1 , how = 'outer' , on = ['State'])\n",
    "    sir_bpcl = y_tdf_bpcl.merge(tsir2 , how = 'outer' , on = ['State'])\n",
    "\n",
    "    sir_hpcl = pd.concat([sir_hpcl],keys=[\"HPCL ERROR'S\"],axis=1)\n",
    "    sir_bpcl = pd.concat([sir_bpcl],keys=[\"BPCL ERROR'S\"],axis=1)\n",
    "\n",
    "    sir_hpcl.loc['GRAND TOTAL'] = sir_hpcl.sum().astype(int)\n",
    "\n",
    "    sir_bpcl.loc['GRAND TOTAL'] = sir_bpcl.sum().astype(int)\n",
    "\n",
    "    sir_hpcl = sir_hpcl.fillna(0)\n",
    "    sir_hpcl = sir_hpcl.replace(0,' ')\n",
    "\n",
    "    sir_bpcl = sir_bpcl.fillna(0)\n",
    "    sir_bpcl = sir_bpcl.replace(0,' ')\n",
    "\n",
    "\n",
    "    # Gmail\n",
    "\n",
    "    email_user = 'monitoring-team@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']    #\n",
    "    bcc = 'idrisikasim@gmail.com'\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = \", \".join(email_send)\n",
    "    msg['Subject'] = 'Work Review ' + YD\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated Pan India work review of HPCL & BPCL:<br>\n",
    "\n",
    "               <br>HPCL PAN INDIA WORK ERROR'S SUMMARY:<br>\n",
    "               {0}\n",
    "               <br>BPCL PAN INDIA WORK ERROR'S SUMMARY:<br>\n",
    "               {1}\n",
    "               <br>HPCL Not Updated ( Previous Evening ):<br>\n",
    "               {2}\n",
    "               <br>HPCL Wrongly Updated:<br>\n",
    "               {3}\n",
    "               <br>BPCL Not Updated ( Previous Evening ):<br>\n",
    "               {4}\n",
    "               <br>BPCL Wrongly Updated for Sites:<br>\n",
    "               {5}\n",
    "               <br>BPCL Wrongly Updated for Auto-RSP:<br>\n",
    "               {6}\n",
    "\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>Regards,\n",
    "               <br>Mohd Kasim & Shweta Kedar,\n",
    "               <br>Data Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>(M):+91 - 8291244397 / +91 - 7507714623\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(sir_hpcl.to_html(),sir_bpcl.to_html(), CH.to_html(), PAN_HPCL_CHK.to_html(), CB.to_html(), PAN_BPCL_CHK_1.to_html(), PAN_BPCL_CHK_2.to_html())\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [URL1 + '\\HPCL_Pan_India_Report_' + YD + '.xlsx' , URL10 + '\\BPCL_Pan_India_Report_' + YD + '.xlsx']\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,email_send + [bcc],text)\n",
    "    server.quit()\n",
    "\n",
    "\n",
    "    # Mail to AmSool Sir....HPCL\n",
    "\n",
    "    print('\\033[0m' + 'Sending HPCL PAN INDIA Report To Amar Sool...')\n",
    "\n",
    "    email_user = 'singh.jaspal@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = 'amar.sool@agsindia.com'    #\n",
    "    bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = email_send\n",
    "    msg['Subject'] = 'Operational Updates - HPCL'\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated Pan India work status of HPCL:<br>\n",
    "\n",
    "               <br>Regards,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [URL1 + '\\HPCL_Pan_India_Report_' + TD + '.xlsx']\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,[email_send] + bcc,text)\n",
    "    server.quit()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + 'HPCL PAN INDIA ' + '\\033[0m' + 'Report To ' + '\\033[1m' + '\\033[92m' + 'Amar Sool')\n",
    "\n",
    "\n",
    "    # Mail to Nitin Nikam Sir....BPCL\n",
    "\n",
    "    print('\\033[0m' +'Sending BPCL PAN INDIA Report To Nitin Nikam...')\n",
    "\n",
    "\n",
    "    email_user = 'abhijit.maity@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = 'nitin.nikam@agsindia.com'    #\n",
    "    bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = email_send\n",
    "    msg['Subject'] = 'Operational Updates - BPCL'\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated Pan India work status of BPCL:<br>\n",
    "\n",
    "               <br>Regards,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [URL12 + '\\BPCL_Pan_India_Report_' + TD + '.xlsx']\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,[email_send] + bcc,text)\n",
    "    server.quit()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + 'BPCL PAN INDIA ' + '\\033[0m' + 'Report To ' + '\\033[1m' + '\\033[92m' +'Nitin Nikam')\n",
    "\n",
    "\n",
    "\n",
    "    # Mail to Reshmi & Shah Jainam....NAYARA\n",
    "\n",
    "    print('\\033[0m' +'Sending NAYARA PAN INDIA Report To Reshmi...')\n",
    "\n",
    "\n",
    "    email_user = 'varun.kumar@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = 'reshmi.das@agsindia.com'    #\n",
    "\n",
    "    bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = email_send\n",
    "    msg['Subject'] = 'Operational Updates - NAYARA'\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Mam,\n",
    "\n",
    "               <br>Please find updated Pan India work status of NAYARA:<br>\n",
    "\n",
    "               <br>Regards,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [Destination_URL_NAYARA]\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,[email_send] + bcc,text)\n",
    "    server.quit()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + 'NAYARA PAN INDIA ' + '\\033[0m' + 'Report To ' + '\\033[1m' + '\\033[92m' +'Reshmi')\n",
    "\n",
    "\n",
    "\n",
    "    # Continuation.......\n",
    "\n",
    "    print('\\033[0m' +'Sending NAYARA PAN INDIA Report To Shah Jainam...')\n",
    "\n",
    "\n",
    "    email_user = 'varun.kumar@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = 'shah.jainam@agsindia.com'    #\n",
    "    bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = email_send\n",
    "    msg['Subject'] = 'Operational Updates - NAYARA'\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated Pan India work status of NAYARA:<br>\n",
    "\n",
    "               <br>Regards,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [Destination_URL_NAYARA]\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,[email_send] + bcc,text)\n",
    "    server.quit()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + 'NAYARA PAN INDIA ' + '\\033[0m' + 'Report To ' + '\\033[1m' + '\\033[92m' +'Shah Jainam')\n",
    "\n",
    "\n",
    "\n",
    "    print('Creating Backup...')\n",
    "\n",
    "    # copy subdirectory \n",
    "    os.mkdir(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\Backup\\HPCL & BPCL' + slash + TD)\n",
    "    fromDirectory = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL'\n",
    "    toDirectory = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\Backup\\HPCL & BPCL' + slash + TD\n",
    "\n",
    "    copy_tree(fromDirectory, toDirectory)\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESSFULLY Backup Created')\n",
    "\n",
    "    image = imread(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Script\\image-robot.jpg')\n",
    "    plt.imshow(image,print('\\033[1m' + 'ALL TASK COMPLETED'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def consolidate_exclude_state_heads():\n",
    "\n",
    "\n",
    "    # Importing Neccessary Libraries...\n",
    "\n",
    "    import warnings \n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    import pandas as pd , numpy as np , datetime, os\n",
    "    import smtplib\n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from email.mime.base import MIMEBase\n",
    "    from email import encoders\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pylab import imread\n",
    "    from distutils.dir_util import copy_tree\n",
    "\n",
    "    # Taking Input From User...\n",
    "\n",
    "    variable = input('\\033[1m' +'Enter Your System Name : ')\n",
    "    slash = input('\\033[1m' + 'Enter \\ : ')\n",
    "\n",
    "    # Good Morning Message...\n",
    "\n",
    "    image = imread(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Script\\goodmorning.jpg')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Datetime Manipulation \n",
    "\n",
    "    TD = datetime.datetime.now().strftime('%d-%m-%Y')\n",
    "    YD = datetime.date.today()-datetime.timedelta(1)\n",
    "    YD = YD.strftime('%d-%m-%Y')\n",
    "\n",
    "    # Initiliazing State Office\n",
    "\n",
    "    incrementer_lst = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO'\n",
    "                       ,'KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "\n",
    "    incrementer = 0\n",
    "    Pan_India_HPCL = pd.DataFrame()\n",
    "\n",
    "    # Connecting Files To One Drive\n",
    "\n",
    "    print('\\033[0m' + 'Wait In Process...')\n",
    "\n",
    "    URL1 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'  # Pan India HPCL Input\n",
    "    URL2 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input NANO History'             # NANO History Input\n",
    "    URL3 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files'              # Fixed Location Input\n",
    "    URL4 = URL3           # Fixed State Office Mail Details Input\n",
    "    URL5 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Prods ( 1 & 2 )'          # Production 1 BPCL Input\n",
    "    URL6 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Prods ( 1 & 2 )'          # Production 2 BPCL Input\n",
    "    URL7 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input HOS'              # HOS File Input\n",
    "    URL8 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL' + slash + TD    # HPCL State Wise Destination Output\n",
    "    URL9 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL' + slash + TD    # BPCL State Wise Destination Output\n",
    "    URL10 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL' # Pan India BPCL Input\n",
    "    URL11 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'  # Pan India HPCL Output\n",
    "    URL12 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL' # Pan India BPCL Output\n",
    "    URL13 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'   # HPCL Pan Output\n",
    "    URL14 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Daily Remarks Updation\\HPCL'   # Daily Remarks Updation HPCL\n",
    "    URL15 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL'   # BPCL Pan Output\n",
    "    URL16 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Daily Remarks Updation\\BPCL'   # Daily Remarks Updation BPCL\n",
    "    URL17 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL'   # State wise BPCL for remarks\n",
    "    URL18 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL'   # State wise HPCl for remarks\n",
    "    URL19 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL'\n",
    "    URL20 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL' # NAyara cols\n",
    "\n",
    "    URL21 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files\\Nayara Columns.xlsx'\n",
    "    URL22 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\Pan_India'        # Pan_India_nayara\n",
    "    URL23 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\State_files_Output' + slash + TD   #  Output State Wise Nayara\n",
    "    URL24 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\State_files_Input' # Input State wise nayara\n",
    "\n",
    "\n",
    "\n",
    "    # Auto Generation Today's Date Folders... \n",
    "\n",
    "    os.mkdir(URL8)   \n",
    "    os.mkdir(URL9)\n",
    "    os.mkdir(URL23)\n",
    "\n",
    "\n",
    "    # Copy Of Yesterday HPCL & BPCL Pan India... \n",
    "\n",
    "    Y_df = pd.read_excel(URL1 + '\\Backup But Without Update' + '\\HPCL_' + 'Pan_India_Report_'+ YD +'.xlsx')   # Pan_India_HPCL Yesterday\n",
    "    Y_Pan_India = pd.read_excel(URL10 + '\\Backup But Without Update' + '\\BPCL_Pan_India_Report_' + YD + '.xlsx')  # Pan_India_BPCL Yesterday\n",
    "\n",
    "    # Importing Required Columns Name to Overfit Format Of Files...\n",
    "\n",
    "    cols_hpcl = pd.read_excel(URL3 + '\\HPCL Columns.xlsx').columns.tolist()\n",
    "    cols_bpcl = pd.read_excel(URL3 + '\\BPCL Columns.xlsx').columns.tolist()\n",
    "    cols_nayara = pd.read_excel(URL21,'NAYARA DETAILS').columns.tolist()\n",
    "\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"Updating Yesterday's PAN INDIA Reports...\")\n",
    "\n",
    "    # HPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "\n",
    "    states_for_pan = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO','KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "    i = 0\n",
    "    Pan_India_HPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_HPCL = pd.read_excel(URL19 + slash + YD + slash + 'HPCL_' + states_for_pan[i] + '_' + YD + '.xlsx', 'Data')\n",
    "        extract_State_HPCL.columns = cols_hpcl\n",
    "        Pan_India_HPCL = pd.concat([Pan_India_HPCL,extract_State_HPCL])\n",
    "        i +=1\n",
    "    Pan_India_HPCL.to_excel(URL11 +'\\HPCL_Pan_India_Report_' + YD + '.xlsx',index = False)\n",
    "    print('\\033[0m' + 'SUCCESSFULLY File Saved As : ' + 'HPCL_Pan_India_Report_' + YD)\n",
    "\n",
    "    # BPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "\n",
    "    i = 0\n",
    "    Pan_India_BPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_BPCL = pd.read_excel(URL20 + slash + YD + slash + 'BPCL_' + states_for_pan[i] + '_' + YD + '.xlsx', 'Data')\n",
    "        extract_State_BPCL.columns = cols_bpcl\n",
    "        State_BPCL = extract_State_BPCL.drop('Sr no',axis = 1)\n",
    "        Pan_India_BPCL = pd.concat([Pan_India_BPCL,State_BPCL])\n",
    "        i +=1\n",
    "    Pan_India_BPCL['Sr no'] = list(range(1,len(Pan_India_BPCL)+1))\n",
    "    Pan_India_BPCL = Pan_India_BPCL.reset_index().drop('index',axis=1)\n",
    "    Pan_India_BPCL = Pan_India_BPCL[extract_State_BPCL.columns.tolist()]\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\BPCL_Pan_India_Report_' + YD + '.xlsx',index = False)\n",
    "    print('SUCCESSFULLY File Saved As : ' + 'BPCL_Pan_India_Report_' + YD)\n",
    "    print('\\033[1m' + '\\033[92m' + \"SUCCESSFULLY Updated Yesterday's PAN INDIA Reports\")\n",
    "\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'Building PAN INDIA NAYARA Reports...')\n",
    "\n",
    "    # NAYARA (Building PAN INDIA NAYARA Reports...)\n",
    "\n",
    "    f_N = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO'\n",
    "                  ,'KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "\n",
    "    i_N = 0\n",
    "    nayara = pd.DataFrame()\n",
    "\n",
    "\n",
    "    while i_N < len(f_N):\n",
    "        extract_nayara = pd.read_excel(URL24 + slash + f_N[i_N] + '.xlsx', 'NAYARA DETAILS')\n",
    "        extract_nayara.columns = cols_nayara\n",
    "        nayara = pd.concat([nayara,extract_nayara])\n",
    "        i_N += 1\n",
    "\n",
    "    nayara = nayara.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "    nayara = nayara.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "    nayara = nayara.drop_duplicates(subset = 'CMS Code')\n",
    "    nayara = nayara.reset_index().drop('index',axis=1)\n",
    "    nayara['Sr No.'] = list(range(1,len(nayara)+1))\n",
    "\n",
    "    # SUMMARY Pan_India_NAYARA\n",
    "\n",
    "    s = nayara[['Zone', 'State','Division','CMS Code','I & C Status', 'HOTO Done','HOTO - Uploaded','O&M Call Status (Open/Closed)'\n",
    "                ,'Spare Requirement','Delivery Status']]\n",
    "    s.loc[s['I & C Status'] == 'COMPLETED', ['I & C Status']] = 'I/C Completed'\n",
    "    s.loc[s['I & C Status'] == 'PENDING' , ['I & C Status']] = 'I/C Pending'\n",
    "\n",
    "    s.loc[s['HOTO Done'] == 'N',['HOTO Done']] = 'HOTO Pending'\n",
    "    s.loc[s['HOTO - Uploaded'] == 'Y' , ['HOTO - Uploaded']] = 'HOTO Uploaded'\n",
    "    s.loc[s['O&M Call Status (Open/Closed)'] == 'OPEN',['O&M Call Status (Open/Closed)']] = 'O&M Open calls'\n",
    "\n",
    "    s.loc[(s['I & C Status'] != 'I/C Completed') & (s['I & C Status'] != 'I/C Pending') , ['I & C Status']] = np.nan\n",
    "    s.loc[s['HOTO Done'] != 'HOTO Pending' ,['HOTO Done']] = np.nan\n",
    "    s.loc[s['HOTO - Uploaded'] != 'HOTO Uploaded' , ['HOTO - Uploaded']] = np.nan\n",
    "    s.loc[s['O&M Call Status (Open/Closed)'] != 'O&M Open calls' , ['O&M Call Status (Open/Closed)']] = np.nan\n",
    "\n",
    "\n",
    "    s1 = pd.get_dummies(s['I & C Status'])\n",
    "    s2 = pd.get_dummies(s['HOTO - Uploaded'])\n",
    "\n",
    "    if len(s.loc[s['HOTO - Uploaded'].isnull(),['HOTO - Uploaded']]) == len(s):\n",
    "        s2['HOTO - Uploaded'] = 0\n",
    "\n",
    "    s3 = pd.get_dummies(s['HOTO Done'])\n",
    "\n",
    "    if len(s.loc[s['HOTO Done'].isnull(),['HOTO Done']]) == len(s):\n",
    "        s3['HOTO Pending'] = 0\n",
    "\n",
    "    s4 = pd.get_dummies(s['O&M Call Status (Open/Closed)'])\n",
    "    ro = s[['CMS Code']]\n",
    "    ro['CMS Code'] = 1\n",
    "    ro.columns = ['Total RO']\n",
    "\n",
    "    Summary = pd.concat([s[['Zone','State','Division']],ro,s1,s2,s3,s4],axis=1)\n",
    "\n",
    "    Summary = Summary.groupby(['Zone','State','Division']).sum()\n",
    "    Summary = Summary.T\n",
    "    Summary['GRAND TOTAL'] = Summary.sum(axis=1)\n",
    "    Summary = Summary.T\n",
    "    Summary['HOTO Pending'] = Summary['Total RO'] - Summary['HOTO Uploaded']\n",
    "    Summary_NAYARA = Summary.astype(int)\n",
    "    Summary_NAYARA = Summary_NAYARA.replace(0,' ')\n",
    "\n",
    "    # HOTO PIVOT Pan_India_NAYARA\n",
    "\n",
    "    tHP = nayara[['HOTO Remarks']]\n",
    "    tHP.columns = ['Count Of Remarks']\n",
    "    HP = pd.concat([nayara[['HOTO Dependency','HOTO Remarks']],tHP],axis=1)\n",
    "    HP = HP.dropna()\n",
    "    HP = HP.groupby(['HOTO Dependency','HOTO Remarks']).count()\n",
    "    HP = HP.replace(0,' ')\n",
    "\n",
    "    # O & M PIVOT Pan_India_NAYARA\n",
    "\n",
    "    tOM = nayara[['O & M Remarks']]\n",
    "    tOM.columns = ['Count Of Remarks']\n",
    "    OM = pd.concat([nayara[['O & M Dependency','O & M Remarks']],tOM],axis=1)\n",
    "    OM = OM.dropna()\n",
    "    OM = OM.groupby(['O & M Dependency','O & M Remarks']).count()\n",
    "    OM = OM.replace(0,' ')\n",
    "\n",
    "    ## SPARE PIVOT\n",
    "\n",
    "    p=nayara[['State','BOS CARD', 'FCC CARD', '5 VOLT SMPS', 'INTERFACE CARD',\n",
    "           'FCC with Accessory', 'DOOR LOCK RFID', 'Barrier board', 'Glands',\n",
    "           '12 SMPS', 'Total ATG probe', '2M', '2.25 M', '2.50 M', '2.75 M',\n",
    "           '3 M', 'HSD Density Float Kit', 'MS Density Float Kit',\n",
    "           'PRODUCT FLOAT KIT', 'WATER FLOAT KIT', 'RFID TAG', 'RFID READER',\n",
    "           'Neck Ribbon', 'Slave', 'MASTER', 'COMM Cable (M)', 'Epoxy KIT',\n",
    "           'MONITOR', 'KEYBOARD', 'MOUSE', 'USB HUB', 'MONITOR POWER CABLE',\n",
    "           'VGA CABLE', 'MCB', 'SPD', 'ROUTER', 'ROUTER ADOPTER', 'PATCH CORD (M)']]\n",
    "    Pivot = p.groupby('State').sum().T\n",
    "    Pivot['GRAND TOTAL'] = Pivot.sum(axis=1)\n",
    "    Pivot = Pivot.astype(int).replace(0,' ')\n",
    "\n",
    "    # EXPORTING FILES  Pan_India_NAYARA\n",
    "\n",
    "    Destination_URL_NAYARA = URL22 + slash + 'Pan_India_NAYARA_' + TD + '.xlsx'\n",
    "\n",
    "    writer5 = pd.ExcelWriter(Destination_URL_NAYARA , engine = 'xlsxwriter')\n",
    "    Summary_NAYARA.to_excel(writer5 , sheet_name = 'NAYARA SUMMARY')\n",
    "    HP.to_excel(writer5 , sheet_name = 'HOTO PIVOT')\n",
    "    OM.to_excel(writer5 , sheet_name = 'O&M PIVOT')\n",
    "    Pivot.to_excel(writer5,sheet_name = 'SPARE PIVOT')\n",
    "    nayara.to_excel(writer5 , sheet_name = 'NAYARA DETAILS' , index = False)\n",
    "    writer5.save()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESSFULLY Built & Exported PAN_INDIA_NAYARA Report')\n",
    "\n",
    "\n",
    "\n",
    "    # Looping................\n",
    "\n",
    "    while incrementer < len(incrementer_lst):\n",
    "\n",
    "        print('\\033[1m' + '\\033[92m' + 'Building ' + incrementer_lst[incrementer] + ' HPCL , BPCL & NAYARA' + ' Reports...')\n",
    "\n",
    "        a = incrementer_lst[incrementer]\n",
    "\n",
    "\n",
    "        #....................................................HPCL.................................................................#\n",
    "\n",
    "\n",
    "        # Extracting Required Data_HPCL HPCL\n",
    "\n",
    "        df = pd.read_excel(URL1 + '\\HPCL_' + 'Pan_India_Report_'+ YD +'.xlsx')   # Pan_India_HPCl\n",
    "        ref = pd.read_excel(URL2 + '\\HPCL_' + 'NANO_HISTORY_' + TD + '.xlsx')  # Nano History last date\n",
    "        location = pd.read_excel(URL3 + '\\Zone_State_Region' + '.xlsx' , 'HPCL')   # Fixed location\n",
    "\n",
    "        # Cleaning ALL Above Data_HPCL\n",
    "\n",
    "        df = df.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "        location = location.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        location = location.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "\n",
    "        # Should be changed according to file\n",
    "\n",
    "        #df = df.drop(['Connectivity Status','Connectivity Vendor'],axis=1)\n",
    "\n",
    "        # Cleaning NANO History\n",
    "\n",
    "        NANO_HISTORY = ref.iloc[11:,:].dropna(how='all',axis=1)\n",
    "        NANO_HISTORY.columns = list(NANO_HISTORY.iloc[0])\n",
    "        NANO_HISTORY = NANO_HISTORY.rename(columns = {'Pumps Configured':'Today Pumps Configured' , 'Tanks Configured':'Tanks Configured Today'})\n",
    "\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop(columns='index').iloc[1:len(NANO_HISTORY)-1].reset_index().drop('index',axis=1)\n",
    "        NANO_HISTORY['Region'] = NANO_HISTORY['Region'].str.upper()\n",
    "        NANO_HISTORY = location[['Region','State','State Office']].merge(NANO_HISTORY , how = 'right' , on = ['Region'])\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop('index',axis=1)\n",
    "        df = df.drop_duplicates(subset='ROCode')\n",
    "        NANO_HISTORY = NANO_HISTORY.drop_duplicates(subset='ROCode')\n",
    "\n",
    "        # .......\n",
    "\n",
    "        df['Reason'] = df['Reason'].str.upper()\n",
    "        df['Remarks'] = df['Remarks'].str.upper()\n",
    "        df['Dependency'] = df['Dependency'].str.upper()\n",
    "        df['Region'] = df['Region'].str.upper()\n",
    "        df['State Office'] = df['State Office'].str.upper()\n",
    "\n",
    "        HPCL = df       # Making A Copy Of Yesterday's Pan_India_HPCL\n",
    "\n",
    "        df['Yesterday Tanks Configured'] = df['Tanks Configured Today']\n",
    "        df['Yesterday Pumps Configured'] = df['Today Pumps Configured']\n",
    "        lstnano = list(set(NANO_HISTORY.columns.tolist()) & set(df.columns.tolist()))\n",
    "        lstnano.remove('ROCode')\n",
    "        df1 = df.drop(lstnano,axis=1)\n",
    "        Data_HPCL = df1.reset_index().drop('index',axis=1)\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop('index',axis=1)\n",
    "        Data_HPCL = Data_HPCL.merge(NANO_HISTORY, how = 'outer' , on = ['ROCode'])\n",
    "        Data_HPCL = Data_HPCL.reset_index().drop('index',axis=1)\n",
    "        Data_HPCL = Data_HPCL[df.columns.tolist()]\n",
    "\n",
    "        Data_HPCL.loc[Data_HPCL['Status'] == 'Fully Communicated' , ['Reason','Remarks','Dependency']] = np.nan\n",
    "        Data_HPCL.loc[Data_HPCL['Status'] == 'Temporary Close' , ['Reason','Remarks','Dependency']] = np.nan\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Reason'].isnull()) , ['Reason']] = 'TBF'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Reason'].isnull()) , ['Reason']] = 'TBF'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Remarks'].isnull()) , ['Remarks']] ='TO BE FOUND'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Remarks'].isnull()) , ['Remarks']] ='TO BE FOUND'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Dependency'].isnull()) , ['Dependency']] = 'AGS'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Dependency'].isnull()) , ['Dependency']] = 'AGS'\n",
    "\n",
    "        Data_HPCL['Difference'] = Data_HPCL['Today Pumps Configured'].sub(Data_HPCL['Yesterday Pumps Configured'] , axis = 0)\n",
    "        Data_HPCL['Difference.1'] = Data_HPCL['Tanks Configured Today'].sub(Data_HPCL['Yesterday Tanks Configured'] , axis = 0)\n",
    "\n",
    "        Data_HPCL = Data_HPCL.astype(int , errors = 'ignore')\n",
    "        Data_HPCL = Data_HPCL.drop_duplicates()\n",
    "        Data_HPCL = location[['Region','State']].merge(Data_HPCL , how = 'right' , on = ['Region'])\n",
    "        HPCL_2 = Data_HPCL.drop('State',axis=1)  # Copy of pan india\n",
    "\n",
    "        # Summary\n",
    "\n",
    "        ds1 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Dependency'] , values = 'Remarks' , aggfunc = len ,fill_value=0)#,margins =True)\n",
    "        ds2 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Reason'] , values = 'Remarks' , aggfunc = len ,fill_value=0)\n",
    "        ds2 = ds2[ds2.columns.tolist()]\n",
    "        ds3 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Status'] , values = 'Remarks' , aggfunc = len ,fill_value=0)\n",
    "        ds3['Total'] = ds3['Fully Communicated'] + ds3['Not Communicated'] + ds3['Partially Communicated']\n",
    "        ds3['NANO %'] = (ds3['Fully Communicated']/ ds3[\"Total\"])*100\n",
    "        Summary = pd.concat([ds3[['NANO %']],ds2,ds1],keys=[' ','Reason for NANO Absence','Issue Classification'],axis=1)\n",
    "\n",
    "        Summary = Summary.T[a].T  # Filtering State wise\n",
    "\n",
    "        ts = Summary[['Reason for NANO Absence','Issue Classification']]\n",
    "        ts = ts.T\n",
    "        ts['Grand Total'] = ts.sum(axis = 1)\n",
    "        ts = ts.fillna(0)\n",
    "        ts = ts.T.astype(int)\n",
    "        tn = Summary[[' ']]\n",
    "        tn = tn.T\n",
    "        tn['Grand Total'] = tn.mean(axis=1)\n",
    "        tn = tn.T\n",
    "        tn = tn.round(2)\n",
    "        Summary = pd.concat([tn,ts],axis=1)\n",
    "        Summary = Summary.replace(0,' ')\n",
    "\n",
    "\n",
    "        # Building Main Data & Pivot_Tables\n",
    "\n",
    "        # 1\n",
    "        a1 = Data_HPCL[['State Office','Remarks']]\n",
    "        a2 = pd.get_dummies(Data_HPCL['Dependency'])\n",
    "        #a2.columns = ['AGS','DEALER','HPCL']\n",
    "        Data_HPCL_t = pd.concat([a1,a2],axis=1)\n",
    "        Data_HPCL_m = Data_HPCL_t[Data_HPCL_t['State Office'] == a]\n",
    "        Data_HPCLp1 = Data_HPCL_m.set_index('Remarks')\n",
    "        Pivot_1 = Data_HPCLp1.groupby('Remarks').sum()\n",
    "\n",
    "        Pivot_1.loc['Grand Total'] = Pivot_1.sum()  # for column \n",
    "        Pivot_1['Grand Total'] = Pivot_1.sum(axis=1) # for row\n",
    "        Pivot_1 = Pivot_1.replace(0 ,' ')\n",
    "        P_t1 = Pivot_1.iloc[:,0:3]\n",
    "        P_t2 = Pivot_1[['Grand Total']]\n",
    "        Pivot_1 = pd.concat([P_t1,P_t2] , keys = ['Dependency' , ' '] , axis = 1)\n",
    "\n",
    "\n",
    "        # 2\n",
    "        Data_HPCL = Data_HPCL[Data_HPCL['State Office'] == a]   # Breaking State Office wise\n",
    "        ttdf = Data_HPCL[Data_HPCL.columns.tolist()[31:]]\n",
    "        tdf = pd.concat([Data_HPCL.Region,ttdf],axis=1)\n",
    "        Pivot_2 = tdf.groupby('Region').count().T\n",
    "        Pivot_2['Grand Total'] = Pivot_2.sum(axis=1) # for row\n",
    "        Pivot_2 = Pivot_2.replace(0,np.nan)\n",
    "        Pivot_2 = Pivot_2.dropna(how = 'all',axis=0)\n",
    "        Pivot_2 = Pivot_2.fillna(0)\n",
    "        Pivot_2 = Pivot_2.astype(int)\n",
    "        Pivot_2 = Pivot_2.replace(0 , ' ')\n",
    "\n",
    "        # Finalizing Data\n",
    "\n",
    "        Data_HPCL = Data_HPCL.drop('State',axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #...................................................BPCL...........................................................#\n",
    "\n",
    "        #Extracting Required Data BPCL\n",
    "\n",
    "        prod1 = pd.read_excel(URL5 + '\\Prod1 ' + TD + '.xlsx')    # Production 1\n",
    "        prod2 = pd.read_excel(URL6 + '\\Prod2 ' + TD + '.xlsx')  # Production 2  \n",
    "        Pan_India = pd.read_excel(URL10 + '\\BPCL_Pan_India_Report_' + YD + '.xlsx')\n",
    "        location = pd.read_excel(URL3 + '\\Zone_State_Region' + '.xlsx','BPCL')      # Fixed location\n",
    "        HOS = pd.read_excel(URL7 + '\\BPCL_HOS_' + TD + '.xlsx')   # HOS Onboarding\n",
    "\n",
    "        # CLeaning ALL Above\n",
    "\n",
    "        Pan_India = Pan_India.drop_duplicates(subset = 'CC')\n",
    "\n",
    "        Pan_India = Pan_India.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        Pan_India = Pan_India.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        location = location.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        location = location.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "\n",
    "        # MAking a copy of Yesterday's Pan_India_BPCL\n",
    "\n",
    "        BPCL = Pan_India\n",
    "\n",
    "\n",
    "        # Building Pan_India_Data\n",
    "\n",
    "        HOS_lst = HOS.iloc[1,:].tolist()\n",
    "        HOS.columns = [HOS_lst]\n",
    "        HOS = HOS.iloc[2:,:]\n",
    "\n",
    "        Final_HOS = HOS[['RO SAPCC','Status']]\n",
    "        Final_HOS.columns = ['CC','Status']\n",
    "        Final_HOS = Final_HOS.drop_duplicates(subset = ['CC'])\n",
    "\n",
    "        Pan_lst = Pan_India.columns.tolist()\n",
    "        Pan_India['CC'] = Pan_India['CC'].astype(int)\n",
    "        Final_HOS['CC'] = Final_HOS['CC'].astype(int)\n",
    "\n",
    "        Final_HOS1 = Final_HOS[['CC']]\n",
    "        Final_HOS1['Onboarded- YES/NO'] = 'YES'\n",
    "\n",
    "        Final_HOS2 = Final_HOS\n",
    "        Final_HOS2['Onboarding Reflecting On Server'] = np.nan\n",
    "        Final_HOS2.loc[Final_HOS2['Status'] == 'Completed' , ['Onboarding Reflecting On Server']] = 'YES'\n",
    "        Final_HOS2.loc[Final_HOS2['Status'] == 'Initiated' , ['Onboarding Reflecting On Server']] = 'NO'\n",
    "        Final_HOS2 = Final_HOS2.drop('Status',axis=1)\n",
    "\n",
    "        prod1.columns = prod1.iloc[1,:]\n",
    "        prod2.columns = prod2.iloc[1,:]\n",
    "        prod1 = prod1.iloc[2:,:]\n",
    "        prod2 = prod2.iloc[2:,:]\n",
    "        prod1 = prod1.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        prod2 = prod2.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        prod1 = prod1.drop_duplicates(subset='RO SAP CC',keep='first')\n",
    "        prod2 = prod2.drop_duplicates(subset='RO SAP CC',keep='first')\n",
    "        Final_Prod = pd.DataFrame(list(set(list(set(list(prod1['RO SAP CC']) + list(prod2['RO SAP CC']))))))\n",
    "        Final_Prod.columns = ['CC']\n",
    "        Final_Prod['CC'] = Final_Prod['CC'].astype(int)\n",
    "\n",
    "        Final_Prod['Today Auto RSP'] = 'YES'\n",
    "\n",
    "        Pan_India['Previous Day Auto RSP'] = Pan_India['Today Auto RSP']\n",
    "\n",
    "\n",
    "        Pan_India = Pan_India.drop(columns = ['Today Auto RSP','Onboarded- YES/NO','Onboarding Reflecting On Server','Sr no'])\n",
    "\n",
    "\n",
    "        Pan_India = Final_Prod.merge(Pan_India , how = 'outer' , on = ['CC'])\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "        Final_HOS3 = Final_HOS1.merge(Final_HOS2 , how = 'outer' , on =['CC'])\n",
    "        Final_HOS3 = Final_HOS3.reset_index().drop('index',axis=1)\n",
    "        Pan_India = Final_HOS3.merge(Pan_India , how = 'outer' , on = ['CC'])\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "\n",
    "\n",
    "        Pan_India.loc[Pan_India['Today Auto RSP'] == 'YES' , ['Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence','Dependency for Auto-RSP Absence','Reasons for sites not upgraded','Remarks for sites not upgraded','Dependency for Sites not upgraded','Description']] = np.nan\n",
    "\n",
    "        Pan_India.loc[Pan_India['Today Auto RSP'].isnull(),['Today Auto RSP']] = 'NO'\n",
    "        Pan_India.loc[Pan_India['Onboarding Reflecting On Server'].isnull(),['Onboarding Reflecting On Server']] = 'NO'\n",
    "        Pan_India.loc[Pan_India['Onboarded- YES/NO'].isnull(),['Onboarded- YES/NO']] = 'NO'\n",
    "\n",
    "\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Reasons for Auto-RSP Absence'].isnull()) , ['Reasons for Auto-RSP Absence']] = 'TBF'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Remarks for AUTO-RSP absence'].isnull()), ['Remarks for AUTO-RSP absence' ]] = 'TO BE FOUND'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Dependency for Auto-RSP Absence'].isnull()),['Dependency for Auto-RSP Absence']] = 'AGS'\n",
    "\n",
    "\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Reasons for sites not upgraded'].isnull()),['Reasons for sites not upgraded']] = 'TBF'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Remarks for sites not upgraded'].isnull()),['Remarks for sites not upgraded']] = 'TO BE FOUND'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Dependency for Sites not upgraded'].isnull()),['Dependency for Sites not upgraded']] = 'AGS'\n",
    "\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "        Pan_India['Sr no'] = np.nan\n",
    "        Pan_India['Sr no'] = list(range(1,len(Pan_India)+1))\n",
    "        Pan_India = Pan_India[Pan_lst]\n",
    "\n",
    "\n",
    "\n",
    "        # Pivot_1 (P1) (Auto-RSP)\n",
    "\n",
    "        India = Pan_India.drop('Region', axis = 1)\n",
    "        India['Dependency for Sites not upgraded'] = India['Dependency for Sites not upgraded'].replace('BPCl','BPCL')\n",
    "        India = India.rename(columns = {'Territory':'Region'})\n",
    "        India['Region'] = India['Region'].str.upper()\n",
    "        India = India.merge(location[['State Office','Region']] , on = ['Region'])\n",
    "        India = India.drop_duplicates()\n",
    "        P1 = pd.get_dummies(India['Dependency for Auto-RSP Absence'])\n",
    "        #P1.columns = ['AGS','BPCL','DEALER']\n",
    "        P1 = pd.concat([P1,India[['State Office','Remarks for AUTO-RSP absence']]],axis = 1)\n",
    "        P1 = P1.loc[(P1['State Office'] == a) & (P1['Remarks for AUTO-RSP absence'] == P1['Remarks for AUTO-RSP absence']),['Remarks for AUTO-RSP absence','AGS','BPCL','DEALER','TBF']]\n",
    "        P1 = pd.concat([P1.groupby('Remarks for AUTO-RSP absence').sum()] , keys = ['Dependency for Auto-RSP Absence'] , axis = 1)\n",
    "        P1.loc['Grand Total'] = P1.sum()  # for column \n",
    "        P1['Grand Total'] = P1.sum(axis=1) # for row\n",
    "        P1 = P1.astype(int)\n",
    "        P1.replace(0, ' ', inplace = True)\n",
    "\n",
    "        # Pivot_2 (P2) ()\n",
    "\n",
    "        P2 = pd.get_dummies(India['Dependency for Sites not upgraded'])\n",
    "        #P2.columns = ['AGS','BPCL']\n",
    "        P2 = pd.concat([P2,India[['State Office','Remarks for sites not upgraded']]],axis = 1)\n",
    "        P2 = P2.loc[(P2['State Office'] == a) & (P2['Remarks for sites not upgraded'] == P2['Remarks for sites not upgraded']),['Remarks for sites not upgraded','AGS','BPCL']]\n",
    "        P2 = pd.concat([P2.groupby('Remarks for sites not upgraded').sum()] , keys = ['Dependency for Sites not upgraded'] , axis = 1)\n",
    "        P2.loc['Grand Total'] = P2.sum()  # for column \n",
    "        P2['Grand Total'] = P2.sum(axis=1) # for row\n",
    "        P2 = P2.astype(int)\n",
    "        P2.replace(0, ' ', inplace = True)\n",
    "\n",
    "        # Summary (S) \n",
    "\n",
    "        T_India = India[India['State Office'] == a]\n",
    "\n",
    "\n",
    "                                      # Changing names #\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'TBF' , ['Reasons for sites not upgraded']] ='TBF-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'RAP' , ['Reasons for sites not upgraded']] ='RAP-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'FVP' , ['Reasons for sites not upgraded']] ='FVP-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'II' , ['Reasons for sites not upgraded']] ='II-U'\n",
    "\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'AGS' , ['Dependency for Sites not upgraded']] ='AGS-U'\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'BPCL' , ['Dependency for Sites not upgraded']] ='BPCL-U'\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'DEALER' , ['Dependency for Sites not upgraded']] ='DEALER-U'\n",
    "\n",
    "\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'TBF' , ['Reasons for Auto-RSP Absence']] ='TBF-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'RAP' , ['Reasons for Auto-RSP Absence']] ='RAP-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'FVP' , ['Reasons for Auto-RSP Absence']] ='FVP-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'II' , ['Reasons for Auto-RSP Absence']] ='II-A'\n",
    "\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'AGS' , ['Dependency for Auto-RSP Absence']] ='AGS-A'\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'BPCL' , ['Dependency for Auto-RSP Absence']] ='BPCL-A'\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'DEALER' , ['Dependency for Auto-RSP Absence']] ='DEALER-A'\n",
    "\n",
    "\n",
    "\n",
    "        S1 = T_India.loc[India['Upgraded-Yes/No'] == 'YES' , ['Region','Upgraded-Yes/No']].groupby('Region').count()\n",
    "        S2 = T_India.loc[India['Onboarded- YES/NO'] == 'YES' , ['Region','Onboarded- YES/NO']].groupby('Region').count()\n",
    "        S3 = pd.DataFrame(T_India['Region'].value_counts())\n",
    "        S4 = T_India.loc[T_India['Onboarding Reflecting On Server'] == 'YES' , ['Region','Onboarding Reflecting On Server']].groupby('Region').count()\n",
    "        S5 = T_India.loc[T_India['Today Auto RSP'] == 'YES' , ['Region','Today Auto RSP']].groupby('Region').count()\n",
    "\n",
    "        S5['Auto RSP %'] = (S5['Today Auto RSP']/S1['Upgraded-Yes/No'])*100\n",
    "\n",
    "        S5 = S5.round(2)\n",
    "        S6 = pd.get_dummies(T_India['Reasons for sites not upgraded']).groupby(T_India['Region']).sum()\n",
    "        S7 = pd.get_dummies(T_India['Dependency for Sites not upgraded']).groupby(T_India['Region']).sum()\n",
    "        S8 = pd.get_dummies(T_India['Reasons for Auto-RSP Absence']).groupby(T_India['Region']).sum()\n",
    "        S9 = pd.get_dummies(T_India['Dependency for Auto-RSP Absence']).groupby(T_India['Region']).sum()\n",
    "\n",
    "        S = S1.join(S2).join(S3).join(S4).join(S5).join(S6).join(S7).join(S8).join(S9).fillna(0).astype(int)\n",
    "\n",
    "        s0 = S[['Upgraded-Yes/No','Onboarded- YES/NO','Region','Onboarding Reflecting On Server','Today Auto RSP','Auto RSP %']]\n",
    "        s0.columns = ['UPGRADED','ONBOARDED','GRAND TOTAL','ONBOARDING REFLECTING ON SERVER','AUTO RSP','AUTO RSP %']\n",
    "        s1 = S[S6.columns.tolist()]\n",
    "        s2 = S[S7.columns.tolist()]\n",
    "        s3 = S[S8.columns.tolist()]\n",
    "        s4 = S[S9.columns.tolist()]\n",
    "\n",
    "        Summary_b = pd.concat([s0.reset_index().drop('Region',axis=1),s1.reset_index().drop('Region',axis=1),s2.reset_index().drop('Region',axis=1),s3.reset_index().drop('Region',axis=1),s4.reset_index().drop('Region',axis=1)] , keys = [' ','Reasons for sites not upgraded','ISSUE CLASSIFICATION','Reasons for Auto-RSP Absence','ISSUE CLASSIFICATION_1'],axis=1)\n",
    "        Summary_b['Zone'] = a\n",
    "        Summary_b['Region'] = s0.reset_index()['Region']\n",
    "        Summary_b = Summary_b.groupby(['Zone','Region']).first()\n",
    "        Summary_b = Summary_b.T\n",
    "        Summary_b['Grand Total'] = Summary_b.sum(axis = 1) # for row\n",
    "        Summary_b = Summary_b.T\n",
    "        Summary_b = Summary_b.astype(int)\n",
    "\n",
    "        if len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) > 0:\n",
    "            Summary_b.iloc[-1,5] = sum(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) / len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1])\n",
    "        elif len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) == 0:\n",
    "            Summary_b.iloc[-1,5] = 0\n",
    "\n",
    "        Summary_b = Summary_b.astype(int)\n",
    "        Summary_b = Summary_b.replace(0,' ')\n",
    "\n",
    "        # Building State_Office_Wise_Data\n",
    "\n",
    "        Pan_India = Pan_India.merge(location[['State','State Office']] , how = 'left' , on = ['State'])\n",
    "\n",
    "\n",
    "        BPCL_2 = Pan_India    # Copy of pan india\n",
    "        BPCL_2 = BPCL_2.drop('State Office',axis=1)\n",
    "        BPCL_2 = BPCL_2.drop_duplicates(subset='CC')\n",
    "        BPCL_2['Sr no'] = list(range(1,len(BPCL_2['Sr no'])+1))\n",
    "\n",
    "        Pan_India = Pan_India[Pan_India['State Office'] == a]\n",
    "        Pan_India = Pan_India.drop('State Office',axis=1)\n",
    "        Pan_India = Pan_India.drop_duplicates(subset='CC')\n",
    "        Pan_India['Sr no'] = list(range(1,len(Pan_India['Sr no'])+1))\n",
    "\n",
    "        # Building Pivot 3\n",
    "\n",
    "        p3 = Pan_India\n",
    "\n",
    "        p3 =p3[['Territory','FCC(WIRED)', 'INTERFACE CARD', 'FCC(WIRELESS)', 'SLAVE',\n",
    "               'MONILITH SLAVE', 'MASTER', 'SMPS(5V)', 'SMPS(12V)', 'SLAVE SMPS',\n",
    "               'MONITOR', 'KEYBOARD', 'MOUSE', 'OTHERS']]\n",
    "\n",
    "        p3 = p3.replace(np.nan , 0)\n",
    "        p3 = p3.groupby('Territory').sum().T\n",
    "        p3.loc['GRAND TOTAL'] = p3.sum()\n",
    "        p3 = p3.astype(int)\n",
    "        p3 = p3.replace(0 , np.nan)\n",
    "        p3 = pd.concat([p3],keys = ['REGION'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        #.............................................NAYARA REPORTS...................................................#\n",
    "\n",
    "\n",
    "\n",
    "        nayara = pd.read_excel(URL24 + slash + a + '.xlsx', 'NAYARA DETAILS')\n",
    "        nayara.columns = cols_nayara\n",
    "\n",
    "        nayara = nayara.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "        nayara = nayara.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        nayara = nayara.drop_duplicates(subset = 'CMS Code')\n",
    "        nayara = nayara.reset_index().drop('index',axis=1)\n",
    "        nayara['Sr No.'] = list(range(1,len(nayara)+1))\n",
    "\n",
    "\n",
    "        # SUMMARY nayara state wise\n",
    "\n",
    "        s = nayara[['Zone', 'State','Division','CMS Code','I & C Status', 'HOTO Done','HOTO - Uploaded','O&M Call Status (Open/Closed)'\n",
    "                    ,'Spare Requirement','Delivery Status']]\n",
    "        s.loc[s['I & C Status'] == 'COMPLETED', ['I & C Status']] = 'I/C Completed'\n",
    "        s.loc[s['I & C Status'] == 'PENDING' , ['I & C Status']] = 'I/C Pending'\n",
    "\n",
    "        s.loc[s['HOTO Done'] == 'N',['HOTO Done']] = 'HOTO Pending'\n",
    "\n",
    "        s.loc[s['HOTO - Uploaded'] == 'Y' , ['HOTO - Uploaded']] = 'HOTO Uploaded'\n",
    "        s.loc[s['O&M Call Status (Open/Closed)'] == 'OPEN',['O&M Call Status (Open/Closed)']] = 'O&M Open calls'\n",
    "\n",
    "        s.loc[(s['I & C Status'] != 'I/C Completed') & (s['I & C Status'] != 'I/C Pending') , ['I & C Status']] = np.nan\n",
    "        s.loc[s['HOTO Done'] != 'HOTO Pending' ,['HOTO Done']] = np.nan\n",
    "        s.loc[s['HOTO - Uploaded'] != 'HOTO Uploaded' , ['HOTO - Uploaded']] = np.nan\n",
    "        s.loc[s['O&M Call Status (Open/Closed)'] != 'O&M Open calls' , ['O&M Call Status (Open/Closed)']] = np.nan\n",
    "\n",
    "\n",
    "        s1 = pd.get_dummies(s['I & C Status'])\n",
    "        s2 = pd.get_dummies(s['HOTO - Uploaded'])\n",
    "\n",
    "        if len(s.loc[s['HOTO - Uploaded'].isnull(),['HOTO - Uploaded']]) == len(s):\n",
    "            s2['HOTO Uploaded'] = 0\n",
    "\n",
    "        s3 = pd.get_dummies(s['HOTO Done'])\n",
    "\n",
    "        if len(s.loc[s['HOTO Done'].isnull(),['HOTO Done']]) == len(s):\n",
    "            s3['HOTO Pending'] = 0\n",
    "\n",
    "        s4 = pd.get_dummies(s['O&M Call Status (Open/Closed)'])\n",
    "        ro = s[['CMS Code']]\n",
    "        ro['CMS Code'] = 1\n",
    "        ro.columns = ['Total RO']\n",
    "\n",
    "        Summary_N = pd.concat([s[['Zone','State','Division']],ro,s1,s2,s3,s4],axis=1)\n",
    "\n",
    "        Summary_N = Summary_N.groupby(['Zone','State','Division']).sum()\n",
    "        Summary_N = Summary_N.T\n",
    "        Summary_N['GRAND TOTAL'] = Summary_N.sum(axis=1)\n",
    "        Summary_N = Summary_N.T\n",
    "        Summary_N['HOTO Pending'] = Summary_N['Total RO'] - Summary_N['HOTO Uploaded']\n",
    "        Summary_State_NAYARA = Summary_N.astype(int)\n",
    "        Summary1_State_NAYARA = Summary_State_NAYARA   # For Mails\n",
    "        Summary1_State_NAYARA = Summary1_State_NAYARA.replace(0,' ')\n",
    "\n",
    "\n",
    "\n",
    "        # HOTO PIVOT Nayara State wise\n",
    "        tHP = nayara[['HOTO Remarks']]\n",
    "        tHP.columns = ['Count Of Remarks']\n",
    "        HP = pd.concat([nayara[['HOTO Dependency','HOTO Remarks']],tHP],axis=1)\n",
    "        HP = HP.dropna()\n",
    "        HP = HP.groupby(['HOTO Dependency','HOTO Remarks']).count()\n",
    "        HP = HP.replace(0,' ')\n",
    "\n",
    "\n",
    "        # O & M PIVOT Nayara State Wise\n",
    "\n",
    "\n",
    "        tOM = nayara[['O & M Remarks']]\n",
    "        tOM.columns = ['Count Of Remarks']\n",
    "        OM = pd.concat([nayara[['O & M Dependency','O & M Remarks']],tOM],axis=1)\n",
    "        OM = OM.dropna()\n",
    "        OM = OM.groupby(['O & M Dependency','O & M Remarks']).count()\n",
    "        OM = OM.replace(0,' ')\n",
    "\n",
    "        # SPARE PIVOT NAyara State Wise\n",
    "\n",
    "        p=nayara[['State','BOS CARD', 'FCC CARD', '5 VOLT SMPS', 'INTERFACE CARD',\n",
    "               'FCC with Accessory', 'DOOR LOCK RFID', 'Barrier board', 'Glands',\n",
    "               '12 SMPS', 'Total ATG probe', '2M', '2.25 M', '2.50 M', '2.75 M',\n",
    "               '3 M', 'HSD Density Float Kit', 'MS Density Float Kit',\n",
    "               'PRODUCT FLOAT KIT', 'WATER FLOAT KIT', 'RFID TAG', 'RFID READER',\n",
    "               'Neck Ribbon', 'Slave', 'MASTER', 'COMM Cable (M)', 'Epoxy KIT',\n",
    "               'MONITOR', 'KEYBOARD', 'MOUSE', 'USB HUB', 'MONITOR POWER CABLE',\n",
    "               'VGA CABLE', 'MCB', 'SPD', 'ROUTER', 'ROUTER ADOPTER', 'PATCH CORD (M)']]\n",
    "        Pivot = p.groupby('State').sum().T\n",
    "        Pivot['GRAND TOTAL'] = Pivot.sum(axis=1)\n",
    "        Pivot = Pivot.astype(int).replace(0,' ')\n",
    "\n",
    "\n",
    "        # Maintaining Files\n",
    "\n",
    "        if len(HP) == 0:\n",
    "            HP = HP.reset_index()\n",
    "\n",
    "        if len(OM) == 0:\n",
    "            OM = OM.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "        print('\\033[0m' + 'Files Made Succesfully')\n",
    "        print('\\033[0m' + 'Styling & Exporting Files Please Wait...')\n",
    "\n",
    "        # Styling Getting the content to be centered \n",
    "\n",
    "        Data_HPCL_s = Data_HPCL.style.set_properties(**{'text-align':'center'})\n",
    "        Summary_s = Summary.style.set_properties(**{'text-align':'center'})\n",
    "        Pivot_1_s = Pivot_1.style.set_properties(**{'text-align':'center'})\n",
    "        Pivot_2_s = Pivot_2.style.set_properties(**{'text-align':'center'})\n",
    "        #UPDATED_PAN_HPCL_REMARKS_s = UPDATED_PAN_HPCL_REMARKS.style.set_properties(**{'text-align':'center'})\n",
    "\n",
    "        Final_Statewise_India_s = Pan_India.style.set_properties(**{'text-align':'center'})\n",
    "        P1_s = P1.style.set_properties(**{'text-align':'center'})\n",
    "        P2_s = P2.style.set_properties(**{'text-align':'center'})\n",
    "        P3_s = p3.style.set_properties(**{'text-align':'center'})\n",
    "        Summary_b_s = Summary_b.style.set_properties(**{'text-align':'center'})\n",
    "        #UPDATED_PAN_BPCL_REMARKS_s = UPDATED_PAN_BPCL_REMARKS.style.set_properties(**{'text-align':'center'})\n",
    "\n",
    "\n",
    "        # Exporting Neccessary Files  (HPCL)\n",
    "\n",
    "        Destination_URL = URL8 + '\\HPCL_' + a + '_' + TD +'.xlsx'\n",
    "\n",
    "        writer1 = pd.ExcelWriter(Destination_URL , engine = 'xlsxwriter')\n",
    "        #UPDATED_PAN_HPCL_REMARKS_s.to_excel(writer1 , sheet_name = 'UPDATED REMARKS HPCL',index=False)\n",
    "        Summary_s.to_excel(writer1 , sheet_name = 'Summary')\n",
    "        Pivot_1_s.to_excel(writer1 , sheet_name = 'Pivot_Remarks')\n",
    "        Pivot_2_s.to_excel(writer1 , sheet_name = 'Pivot_Spares')\n",
    "        Data_HPCL_s.to_excel(writer1 , sheet_name = 'Data' , index = False)\n",
    "        writer1.save()\n",
    "\n",
    "\n",
    "        # Exporting Neccessary Files  (BPCL)\n",
    "\n",
    "        Destination_URL_B = URL9 + '\\BPCL_' + a + '_' + TD +'.xlsx'\n",
    "\n",
    "        writer2 = pd.ExcelWriter(Destination_URL_B , engine = 'xlsxwriter')\n",
    "        #UPDATED_PAN_BPCL_REMARKS_s.to_excel(writer2 , sheet_name = 'UPDATED REMARKS BPCL',index=False)\n",
    "        Summary_b_s.to_excel(writer2 , sheet_name = 'Summary')\n",
    "        P1_s.to_excel(writer2 , sheet_name = 'Issue Analysis Auto RSP')\n",
    "        P2_s.to_excel(writer2 , sheet_name = 'Issue Analysis Pending Upgrades')\n",
    "        P3_s.to_excel(writer2 , sheet_name = 'Spare Required')\n",
    "        Final_Statewise_India_s.to_excel(writer2 , sheet_name = 'Data' , index = False)\n",
    "        writer2.save()\n",
    "\n",
    "        # EXPORTING FILES NAYARA STATE WISE\n",
    "\n",
    "        Destination_URL_STATE_NAYARA = URL23 + slash + 'NAYARA_' + a + '_' + TD + '.xlsx'\n",
    "\n",
    "        writer6 = pd.ExcelWriter(Destination_URL_STATE_NAYARA , engine = 'xlsxwriter')\n",
    "        Summary_State_NAYARA.to_excel(writer6 , sheet_name = 'NAYARA SUMMARY')\n",
    "        HP.to_excel(writer6 , sheet_name = 'HOTO PIVOT')\n",
    "        OM.to_excel(writer6 , sheet_name = 'O&M PIVOT')\n",
    "        Pivot.to_excel(writer6,sheet_name = 'SPARE PIVOT')\n",
    "        nayara.to_excel(writer6 , sheet_name = 'NAYARA DETAILS' , index = False)\n",
    "        writer6.save()\n",
    "\n",
    "\n",
    "        print('\\033[0m' + 'All Files Saved Succesfully')\n",
    "\n",
    "\n",
    "\n",
    "        incrementer += 1 \n",
    "\n",
    "        if incrementer < len(incrementer_lst):\n",
    "            print('\\033[0m' + 'Wait Next File, In Process...')\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'Extracting NEW SITES Records...')\n",
    "\n",
    "    # Getting New Sites Records\n",
    "\n",
    "    HPCL_2 = HPCL_2[HPCL_2['Region'].isnull()]\n",
    "    HPCL_2.to_excel(URL8 + slash + 'NEW_SITES_HPCL.xlsx')\n",
    "\n",
    "    BPCL_2 = BPCL_2[(BPCL_2['Region'].isnull()) | (BPCL_2['State'].isnull()) | (BPCL_2['Territory'].isnull())]\n",
    "    BPCL_2.to_excel(URL9 + slash + 'NEW_SITES_BPCL.xlsx')\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"STATE WISE OPERATION'S SUCCESSFUL\")\n",
    "\n",
    "    # Exporting PAN_INDIA HPCL & BPCL Reports\n",
    "\n",
    "    print('\\033[0m' + 'Exporting PAN_INDIA HPCL & BPCL Reports Wait...')\n",
    "\n",
    "    # HPCL\n",
    "    states_for_pan = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO','KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "    i = 0\n",
    "    Pan_India_HPCL =pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_HPCL = pd.read_excel(URL18 + slash + TD + slash +'HPCL_' + states_for_pan[i] + '_' + TD + '.xlsx', 'Data')\n",
    "        Pan_India_HPCL = pd.concat([Pan_India_HPCL,extract_State_HPCL])\n",
    "        i +=1\n",
    "    Pan_India_HPCL.to_excel(URL11 +'\\HPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "    Pan_India_HPCL.to_excel(URL11 + '\\Backup But Without Update' + '\\HPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "\n",
    "    print('\\033[0m' + 'SUCCESSFULLY File Saved As : ' + 'HPCL_Pan_India_Report_' + TD)\n",
    "\n",
    "    # BPCL\n",
    "    i = 0\n",
    "    Pan_India_BPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_BPCL = pd.read_excel(URL17 + slash + TD + slash +'BPCL_' + states_for_pan[i] + '_' + TD + '.xlsx', 'Data')\n",
    "        Pan_India_BPCL = pd.concat([Pan_India_BPCL,extract_State_BPCL])\n",
    "        i +=1\n",
    "\n",
    "    Pan_India_BPCL['Sr no'] = list(range(1,len(Pan_India_BPCL)+1))\n",
    "    Pan_India_BPCL = Pan_India_BPCL.reset_index().drop('index',axis=1)\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\BPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\Backup But Without Update' + '\\BPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "\n",
    "    print('SUCCESSFULLY File Saved As : ' + 'BPCL_Pan_India_Report_' + TD)\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"PAN_INDIA OPERATION'S SUCCESSFUL\")\n",
    "\n",
    "\n",
    "    #.............................................................................\n",
    "\n",
    "\n",
    "    HPCL = HPCL.rename({'State Office':'State'},axis=1)\n",
    "    Y_df = Y_df.rename({'State Office':'State'},axis=1)\n",
    "    BPCL = Pan_India\n",
    "\n",
    "    #......\n",
    "    print('\\033[0m' + 'Wait In Process...')\n",
    "    CH = HPCL.loc[(HPCL['Reason'] == 'TBF') | (HPCL['Remarks'] == 'TO BE FOUND') , ['State','ROCode','Dependency','Reason','Remarks']]\n",
    "    CB = BPCL.loc[(BPCL['Reasons for sites not upgraded'] == 'TBF') | (BPCL['Remarks for sites not upgraded'] == 'TO BE FOUND') | (BPCL['Reasons for Auto-RSP Absence'] == 'TBF') | (BPCL['Remarks for AUTO-RSP absence'] == 'TO BE FOUND'), ['State','CC','Reasons for sites not upgraded','Remarks for sites not upgraded','Dependency for Sites not upgraded','Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence','Dependency for Auto-RSP Absence']]\n",
    "\n",
    "    #......\n",
    "\n",
    "    hcr = pd.read_excel(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files\\Common Remarks For HPCL & BPCL.xlsx','HPCL')\n",
    "    bcr = pd.read_excel(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files\\Common Remarks For HPCL & BPCL.xlsx','BPCL')\n",
    "    hcr['Remarks for HPCL'] = hcr['Remarks for HPCL'].str.upper()  # Since Pan India HPCL Is In Upper\n",
    "    bcr['Remarks for BPCL'] = bcr['Remarks for BPCL'].str.upper()  # Since Pan India BPCL Is In Upper \n",
    "\n",
    "\n",
    "    ags_hcr = hcr.loc[hcr['Dependency'] == 'AGS']\n",
    "    dea_hcr = hcr.loc[hcr['Dependency'] == 'DEALER']\n",
    "    hpcl_hcr = hcr.loc[hcr['Dependency'] == 'HPCL']\n",
    "\n",
    "    ags_bcr = bcr.loc[bcr['Dependency'] == 'AGS']\n",
    "    dea_bcr = bcr.loc[bcr['Dependency'] == 'DEALER']\n",
    "    bpcl_bcr = bcr.loc[bcr['Dependency'] == 'BPCL']\n",
    "\n",
    "    # HPCL\n",
    "\n",
    "    HPCL['Remarks'] = HPCL['Remarks'].str.upper()\n",
    "\n",
    "    H1 = HPCL.loc[HPCL['Dependency'] == 'AGS' , CH.columns.tolist()]\n",
    "    H1_ags_chk = H1.loc[~(H1['Remarks'].isin(ags_hcr['Remarks for HPCL']))]\n",
    "\n",
    "    H2 = HPCL.loc[HPCL['Dependency'] == 'DEALER' , CH.columns.tolist()]\n",
    "    H2_dea_chk = H2.loc[~(H2['Remarks'].isin(dea_hcr['Remarks for HPCL']))]\n",
    "\n",
    "    H3 = HPCL.loc[HPCL['Dependency'] == 'HPCL' , CH.columns.tolist()]\n",
    "    H3_hpcl_chk = H3.loc[~(H3['Remarks'].isin(hpcl_hcr['Remarks for HPCL']))]\n",
    "\n",
    "    PAN_HPCL_CHK = pd.concat([H1_ags_chk,H2_dea_chk,H3_hpcl_chk])\n",
    "    PAN_HPCL_CHK = PAN_HPCL_CHK[PAN_HPCL_CHK['Remarks'] != 'TO BE FOUND']\n",
    "\n",
    "    # BPCL\n",
    "\n",
    "\n",
    "    B1 = BPCL.loc[BPCL['Dependency for Sites not upgraded'] == 'AGS' , ['State','CC','Dependency for Sites not upgraded','Reasons for sites not upgraded','Remarks for sites not upgraded']]\n",
    "    B1_ags_chk = B1.loc[~(B1['Remarks for sites not upgraded'].isin(ags_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    B2 = BPCL.loc[BPCL['Dependency for Sites not upgraded'] == 'DEALER' , ['State','CC','Dependency for Sites not upgraded','Reasons for sites not upgraded','Remarks for sites not upgraded']]\n",
    "    B2_dea_chk = B2.loc[~(B2['Remarks for sites not upgraded'].isin(dea_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    B3 = BPCL.loc[BPCL['Dependency for Sites not upgraded'] == 'BPCL' , ['State','CC','Dependency for Sites not upgraded','Reasons for sites not upgraded','Remarks for sites not upgraded']]\n",
    "    B3_bpcl_chk = B3.loc[~(B3['Remarks for sites not upgraded'].isin(bpcl_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    PAN_BPCL_CHK_1 = pd.concat([B1_ags_chk,B2_dea_chk,B3_bpcl_chk])\n",
    "    PAN_BPCL_CHK_1 = PAN_BPCL_CHK_1[PAN_BPCL_CHK_1['Remarks for sites not upgraded'] != 'TO BE FOUND']\n",
    "\n",
    "    B4 = BPCL.loc[BPCL['Dependency for Auto-RSP Absence'] == 'AGS' , ['State','CC','Dependency for Auto-RSP Absence','Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence']]\n",
    "    B4_ags_chk = B4.loc[~(B4['Remarks for AUTO-RSP absence'].isin(ags_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    B5 = BPCL.loc[BPCL['Dependency for Auto-RSP Absence'] == 'DEALER' , ['State','CC','Dependency for Auto-RSP Absence','Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence']]\n",
    "    B5_dea_chk = B5.loc[~(B5['Remarks for AUTO-RSP absence'].isin(dea_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    B6 = BPCL.loc[BPCL['Dependency for Auto-RSP Absence'] == 'BPCL' , ['State','CC','Dependency for Auto-RSP Absence','Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence']]\n",
    "    B6_bpcl_chk = B6.loc[~(B6['Remarks for AUTO-RSP absence'].isin(bpcl_bcr['Remarks for BPCL']))]\n",
    "\n",
    "    PAN_BPCL_CHK_2 = pd.concat([B4_ags_chk,B5_dea_chk,B6_bpcl_chk])\n",
    "    PAN_BPCL_CHK_2 = PAN_BPCL_CHK_2[PAN_BPCL_CHK_2['Remarks for AUTO-RSP absence'] != 'TO BE FOUND']\n",
    "\n",
    "    # .....\n",
    "\n",
    "    sir1 = CH.groupby('State').count()[['ROCode']].rename({'ROCode':'Not Updated ( Previous Evening )'},axis=1)\n",
    "    sir2 = PAN_HPCL_CHK.groupby('State').count()[['ROCode']].rename({'ROCode':'Wrongly Updated'},axis=1)\n",
    "    sir3 = CB.groupby('State').count()[['CC']].rename({'CC':'Not Updated ( Previous Evening )'},axis=1)\n",
    "    sir4 = PAN_BPCL_CHK_1.groupby('State').count()[['CC']].rename({'CC':'Wrongly Updated for Sites'},axis=1)\n",
    "    sir5 = PAN_BPCL_CHK_2.groupby('State').count()[['CC']].rename({'CC':'Wrongly Updated for Auto-RSP'},axis=1)\n",
    "    sir = sir1.merge(sir2, how = 'outer' , on = ['State']).merge(sir3, how='outer', on = ['State']).merge(sir4, how = 'outer' , on = ['State']).merge(sir5, how = 'outer' , on = ['State'])\n",
    "    sir = sir.fillna(0)\n",
    "    sir = sir.astype(int)\n",
    "    tsir1 = sir.iloc[:,:2]\n",
    "    tsir2 = sir.iloc[:,2:]\n",
    "\n",
    "    tsir2 = tsir2.drop_duplicates(keep = False)\n",
    "    tsir1 = tsir1.drop_duplicates(keep = False)\n",
    "\n",
    "\n",
    "    y_tdf_hpcl = Y_df.loc[Y_df['Reason'] == 'TBF' , ['State','Reason']].groupby('State').count().rename({'Reason':\"TBFs ( Previous Day )\"},axis=1)\n",
    "    y_tdf_bpcl = Y_Pan_India.loc[Y_Pan_India['Reasons for sites not upgraded'] == 'TBF' ,\n",
    "                                 ['State','Reasons for sites not upgraded']].groupby('State').count().rename({'Reasons for sites not upgraded':\"TBFs ( Previous Day )\"},axis=1)\n",
    "\n",
    "    sir_hpcl = y_tdf_hpcl.merge(tsir1 , how = 'outer' , on = ['State'])\n",
    "    sir_bpcl = y_tdf_bpcl.merge(tsir2 , how = 'outer' , on = ['State'])\n",
    "\n",
    "    sir_hpcl = pd.concat([sir_hpcl],keys=[\"HPCL ERROR'S\"],axis=1)\n",
    "    sir_bpcl = pd.concat([sir_bpcl],keys=[\"BPCL ERROR'S\"],axis=1)\n",
    "\n",
    "    sir_hpcl.loc['GRAND TOTAL'] = sir_hpcl.sum().astype(int)\n",
    "\n",
    "    sir_bpcl.loc['GRAND TOTAL'] = sir_bpcl.sum().astype(int)\n",
    "\n",
    "    sir_hpcl = sir_hpcl.fillna(0)\n",
    "    sir_hpcl = sir_hpcl.replace(0,' ')\n",
    "\n",
    "\n",
    "\n",
    "    sir_bpcl = sir_bpcl.fillna(0)\n",
    "    sir_bpcl = sir_bpcl.replace(0,' ')\n",
    "\n",
    "\n",
    "    # Gmail\n",
    "\n",
    "    email_user = 'monitoring-team@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']    #\n",
    "    bcc = 'idrisikasim@gmail.com'\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = \", \".join(email_send)\n",
    "    msg['Subject'] = 'Work Review ' + YD\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated Pan India work review of HPCL & BPCL:<br>\n",
    "\n",
    "               <br>HPCL PAN INDIA WORK ERROR'S SUMMARY:<br>\n",
    "               {0}\n",
    "               <br>BPCL PAN INDIA WORK ERROR'S SUMMARY:<br>\n",
    "               {1}\n",
    "               <br>HPCL Not Updated ( Previous Evening ):<br>\n",
    "               {2}\n",
    "               <br>HPCL Wrongly Updated:<br>\n",
    "               {3}\n",
    "               <br>BPCL Not Updated ( Previous Evening ):<br>\n",
    "               {4}\n",
    "               <br>BPCL Wrongly Updated for Sites:<br>\n",
    "               {5}\n",
    "               <br>BPCL Wrongly Updated for Auto-RSP:<br>\n",
    "               {6}\n",
    "\n",
    "\n",
    "               <br>Kindly let me know if you'd like me to follow up on additional details.<br>\n",
    "               <br>Regards,\n",
    "               <br>Mohd Kasim & Shweta Kedar,\n",
    "               <br>Data Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>(M):+91 - 8291244397 / +91 - 7507714623\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\".format(sir_hpcl.to_html(),sir_bpcl.to_html(), CH.to_html(), PAN_HPCL_CHK.to_html(), CB.to_html(), PAN_BPCL_CHK_1.to_html(), PAN_BPCL_CHK_2.to_html())\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [URL1 + '\\HPCL_Pan_India_Report_' + YD + '.xlsx' , URL10 + '\\BPCL_Pan_India_Report_' + YD + '.xlsx']\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,email_send + [bcc],text)\n",
    "    server.quit()\n",
    "\n",
    "\n",
    "    # Mail to AmSool Sir....HPCL\n",
    "\n",
    "    print('\\033[0m' + 'Sending HPCL PAN INDIA Report To Amar Sool...')\n",
    "\n",
    "    email_user = 'singh.jaspal@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = 'amar.sool@agsindia.com'    #\n",
    "    bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = email_send\n",
    "    msg['Subject'] = 'Operational Updates - HPCL'\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated Pan India work status of HPCL:<br>\n",
    "\n",
    "               <br>Regards,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [URL1 + '\\HPCL_Pan_India_Report_' + TD + '.xlsx']\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,[email_send] + bcc,text)\n",
    "    server.quit()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + 'HPCL PAN INDIA ' + '\\033[0m' + 'Report To ' + '\\033[1m' + '\\033[92m' + 'Amar Sool')\n",
    "\n",
    "\n",
    "    # Mail to Nitin Nikam Sir....BPCL\n",
    "\n",
    "    print('\\033[0m' +'Sending BPCL PAN INDIA Report To Nitin Nikam...')\n",
    "\n",
    "\n",
    "    email_user = 'abhijit.maity@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = 'nitin.nikam@agsindia.com'    #\n",
    "    bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = email_send\n",
    "    msg['Subject'] = 'Operational Updates - BPCL'\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated Pan India work status of BPCL:<br>\n",
    "\n",
    "               <br>Regards,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [URL12 + '\\BPCL_Pan_India_Report_' + TD + '.xlsx']\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,[email_send] + bcc,text)\n",
    "    server.quit()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + 'BPCL PAN INDIA ' + '\\033[0m' + 'Report To ' + '\\033[1m' + '\\033[92m' +'Nitin Nikam')\n",
    "\n",
    "\n",
    "\n",
    "    # Mail to Reshmi & Shah Jainam....NAYARA\n",
    "\n",
    "    print('\\033[0m' +'Sending NAYARA PAN INDIA Report To Reshmi...')\n",
    "\n",
    "\n",
    "    email_user = 'varun.kumar@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = 'reshmi.das@agsindia.com'    #\n",
    "\n",
    "    bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = email_send\n",
    "    msg['Subject'] = 'Operational Updates - NAYARA'\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Mam,\n",
    "\n",
    "               <br>Please find updated Pan India work status of NAYARA:<br>\n",
    "\n",
    "               <br>Regards,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [Destination_URL_NAYARA]\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,[email_send] + bcc,text)\n",
    "    server.quit()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + 'NAYARA PAN INDIA ' + '\\033[0m' + 'Report To ' + '\\033[1m' + '\\033[92m' +'Reshmi')\n",
    "\n",
    "\n",
    "\n",
    "    # Continuation.......\n",
    "\n",
    "    print('\\033[0m' +'Sending NAYARA PAN INDIA Report To Shah Jainam...')\n",
    "\n",
    "\n",
    "    email_user = 'varun.kumar@agsindia.com' #\n",
    "    email_password = '*****'             #\n",
    "    email_send = 'shah.jainam@agsindia.com'    #\n",
    "    bcc = ['kush.meshram@agsindia.com','chandra.sekhar@agsindia.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_user\n",
    "    msg['To'] = email_send\n",
    "    msg['Subject'] = 'Operational Updates - NAYARA'\n",
    "\n",
    "\n",
    "    body = \"\"\"        <html>\n",
    "          <head></head>\n",
    "          <body>\n",
    "            <p>Dear Sir,\n",
    "\n",
    "               <br>Please find updated Pan India work status of NAYARA:<br>\n",
    "\n",
    "               <br>Regards,\n",
    "               <br>Monitoring Team\n",
    "               <br>AGS Transact Technologies Ltd.\n",
    "               <br>\n",
    "            </p>\n",
    "          </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    msg.attach(MIMEText(body,'html'))\n",
    "\n",
    "    files = [Destination_URL_NAYARA]\n",
    "    for a_file in files:\n",
    "            attachment  = open(a_file,'rb')   #\n",
    "            file_name = os.path.basename(a_file)\n",
    "            part = MIMEBase('application','octet-stream')\n",
    "            part.set_payload((attachment).read())\n",
    "            encoders.encode_base64(part)    #\n",
    "            part.add_header('Content-Disposition',\"attachment; filename= \"+file_name)\n",
    "            msg.attach(part)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server = smtplib.SMTP('smtp.agsindia.com',587)\n",
    "    server.starttls()\n",
    "    server.login(email_user,email_password)\n",
    "    server.sendmail(email_user,[email_send] + bcc,text)\n",
    "    server.quit()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESFULLY ' + '\\033[0m' + 'Sent ' + '\\033[1m' + '\\033[92m' + 'NAYARA PAN INDIA ' + '\\033[0m' + 'Report To ' + '\\033[1m' + '\\033[92m' +'Shah Jainam')\n",
    "\n",
    "\n",
    "\n",
    "    print('Creating Backup...')\n",
    "\n",
    "    # copy subdirectory \n",
    "    os.mkdir(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\Backup\\HPCL & BPCL' + slash + TD)\n",
    "    fromDirectory = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL'\n",
    "    toDirectory = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\Backup\\HPCL & BPCL' + slash + TD\n",
    "\n",
    "    copy_tree(fromDirectory, toDirectory)\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESSFULLY Backup Created')\n",
    "\n",
    "    image = imread(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Script\\image-robot.jpg')\n",
    "    plt.imshow(image,print('\\033[1m' + 'ALL TASK COMPLETED'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def gap_consolidate():\n",
    "    \n",
    "    \n",
    "    # Importing Neccessary Libraries...\n",
    "\n",
    "    import warnings \n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    import pandas as pd , numpy as np , datetime, os\n",
    "    from distutils.dir_util import copy_tree\n",
    "\n",
    "    # Taking Input From User...\n",
    "\n",
    "    variable = input('\\033[1m' +'Enter Your System Name : ')\n",
    "    slash = input('\\033[1m' + 'Enter \\ : ')\n",
    "\n",
    "    # Good Morning Message...\n",
    "\n",
    "    image = imread(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Script\\goodmorning.jpg')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Datetime Manipulation \n",
    "\n",
    "    TD = datetime.datetime.now().strftime('%d-%m-%Y')\n",
    "    YD = datetime.date.today()-datetime.timedelta(1)\n",
    "    YD = YD.strftime('%d-%m-%Y')\n",
    "\n",
    "    # Initiliazing State Office\n",
    "\n",
    "    incrementer_lst = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO'\n",
    "                       ,'KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "\n",
    "    #incrementer_lst = ['NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO'\n",
    "    #                   ,'KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "\n",
    "    incrementer = 0\n",
    "    Pan_India_HPCL = pd.DataFrame()\n",
    "\n",
    "    # Connecting Files To One Drive\n",
    "\n",
    "    print('\\033[0m' + 'Wait In Process...')\n",
    "\n",
    "    URL1 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'  # Pan India HPCL Input\n",
    "    URL2 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input NANO History'             # NANO History Input\n",
    "    URL3 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files'              # Fixed Location Input\n",
    "    URL4 = URL3           # Fixed State Office Mail Details Input\n",
    "    URL5 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Prods ( 1 & 2 )'          # Production 1 BPCL Input\n",
    "    URL6 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Prods ( 1 & 2 )'          # Production 2 BPCL Input\n",
    "    URL7 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input HOS'              # HOS File Input\n",
    "    URL8 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL' + slash + TD    # HPCL State Wise Destination Output\n",
    "    URL9 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL' + slash + TD    # BPCL State Wise Destination Output\n",
    "    URL10 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL' # Pan India BPCL Input\n",
    "    URL11 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'  # Pan India HPCL Output\n",
    "    URL12 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL' # Pan India BPCL Output\n",
    "    URL13 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India HPCL'   # HPCL Pan Output\n",
    "    URL14 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Daily Remarks Updation\\HPCL'   # Daily Remarks Updation HPCL\n",
    "    URL15 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output & Input Pan India BPCL'   # BPCL Pan Output\n",
    "    URL16 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Daily Remarks Updation\\BPCL'   # Daily Remarks Updation BPCL\n",
    "    URL17 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL'   # State wise BPCL for remarks\n",
    "    URL18 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL'   # State wise HPCl for remarks\n",
    "    URL19 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL'\n",
    "    URL20 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL' # NAyara cols\n",
    "\n",
    "    URL21 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files\\Nayara Columns.xlsx'\n",
    "    URL22 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\Pan_India'        # Pan_India_nayara\n",
    "    URL23 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\State_files_Output' + slash + TD   #  Output State Wise Nayara\n",
    "    URL24 = r'C:\\Users\\Sony\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\NAYARA\\State_files_Input' # Input State wise nayara\n",
    "\n",
    "\n",
    "\n",
    "    # Auto Generation Today's Date Folders... \n",
    "\n",
    "    os.mkdir(URL8)   \n",
    "    os.mkdir(URL9)\n",
    "    os.mkdir(URL23)\n",
    "\n",
    "\n",
    "    # Copy Of Yesterday HPCL & BPCL Pan India... \n",
    "\n",
    "    Y_df = pd.read_excel(URL1 + '\\Backup But Without Update' + '\\HPCL_' + 'Pan_India_Report_'+ YD +'.xlsx')   # Pan_India_HPCL Yesterday\n",
    "    Y_Pan_India = pd.read_excel(URL10 + '\\Backup But Without Update' + '\\BPCL_Pan_India_Report_' + YD + '.xlsx')  # Pan_India_BPCL Yesterday\n",
    "\n",
    "    # Importing Required Columns Name to Overfit Format Of Files...\n",
    "\n",
    "    cols_hpcl = pd.read_excel(URL3 + '\\HPCL Columns.xlsx').columns.tolist()\n",
    "    cols_bpcl = pd.read_excel(URL3 + '\\BPCL Columns.xlsx').columns.tolist()\n",
    "    cols_nayara = pd.read_excel(URL21,'NAYARA DETAILS').columns.tolist()\n",
    "\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"Updating Yesterday's PAN INDIA Reports...\")\n",
    "\n",
    "    # HPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "\n",
    "    states_for_pan = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO','KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "    i = 0\n",
    "    Pan_India_HPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_HPCL = pd.read_excel(URL19 + slash + YD + slash + 'HPCL_' + states_for_pan[i] + '_' + YD + '.xlsx', 'Data')\n",
    "        extract_State_HPCL.columns = cols_hpcl\n",
    "        Pan_India_HPCL = pd.concat([Pan_India_HPCL,extract_State_HPCL])\n",
    "        i +=1\n",
    "    Pan_India_HPCL.to_excel(URL11 +'\\HPCL_Pan_India_Report_' + YD + '.xlsx',index = False)\n",
    "    print('\\033[0m' + 'SUCCESSFULLY File Saved As : ' + 'HPCL_Pan_India_Report_' + YD)\n",
    "\n",
    "    # BPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "\n",
    "    i = 0\n",
    "    Pan_India_BPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_BPCL = pd.read_excel(URL20 + slash + YD + slash + 'BPCL_' + states_for_pan[i] + '_' + YD + '.xlsx', 'Data')\n",
    "        extract_State_BPCL.columns = cols_bpcl\n",
    "        State_BPCL = extract_State_BPCL.drop('Sr no',axis = 1)\n",
    "        Pan_India_BPCL = pd.concat([Pan_India_BPCL,State_BPCL])\n",
    "        i +=1\n",
    "    Pan_India_BPCL['Sr no'] = list(range(1,len(Pan_India_BPCL)+1))\n",
    "    Pan_India_BPCL = Pan_India_BPCL.reset_index().drop('index',axis=1)\n",
    "    Pan_India_BPCL = Pan_India_BPCL[extract_State_BPCL.columns.tolist()]\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\BPCL_Pan_India_Report_' + YD + '.xlsx',index = False)\n",
    "    print('SUCCESSFULLY File Saved As : ' + 'BPCL_Pan_India_Report_' + YD)\n",
    "    print('\\033[1m' + '\\033[92m' + \"SUCCESSFULLY Updated Yesterday's PAN INDIA Reports\")\n",
    "\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'Building PAN INDIA NAYARA Reports...')\n",
    "\n",
    "    # NAYARA (Building PAN INDIA NAYARA Reports...)\n",
    "\n",
    "    f_N = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO'\n",
    "                  ,'KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "\n",
    "    i_N = 0\n",
    "    nayara = pd.DataFrame()\n",
    "\n",
    "\n",
    "    while i_N < len(f_N):\n",
    "        extract_nayara = pd.read_excel(URL24 + slash + f_N[i_N] + '.xlsx', 'NAYARA DETAILS')\n",
    "        extract_nayara.columns = cols_nayara\n",
    "        nayara = pd.concat([nayara,extract_nayara])\n",
    "        i_N += 1\n",
    "\n",
    "    nayara = nayara.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "    nayara = nayara.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "    nayara = nayara.drop_duplicates(subset = 'CMS Code')\n",
    "    nayara = nayara.reset_index().drop('index',axis=1)\n",
    "    nayara['Sr No.'] = list(range(1,len(nayara)+1))\n",
    "\n",
    "    # SUMMARY Pan_India_NAYARA\n",
    "\n",
    "    s = nayara[['Zone', 'State','Division','CMS Code','I & C Status', 'HOTO Done','HOTO - Uploaded','O&M Call Status (Open/Closed)'\n",
    "                ,'Spare Requirement','Delivery Status']]\n",
    "    s.loc[s['I & C Status'] == 'COMPLETED', ['I & C Status']] = 'I/C Completed'\n",
    "    s.loc[s['I & C Status'] == 'PENDING' , ['I & C Status']] = 'I/C Pending'\n",
    "\n",
    "    s.loc[s['HOTO Done'] == 'N',['HOTO Done']] = 'HOTO Pending'\n",
    "    s.loc[s['HOTO - Uploaded'] == 'Y' , ['HOTO - Uploaded']] = 'HOTO Uploaded'\n",
    "    s.loc[s['O&M Call Status (Open/Closed)'] == 'OPEN',['O&M Call Status (Open/Closed)']] = 'O&M Open calls'\n",
    "\n",
    "    s.loc[(s['I & C Status'] != 'I/C Completed') & (s['I & C Status'] != 'I/C Pending') , ['I & C Status']] = np.nan\n",
    "    s.loc[s['HOTO Done'] != 'HOTO Pending' ,['HOTO Done']] = np.nan\n",
    "    s.loc[s['HOTO - Uploaded'] != 'HOTO Uploaded' , ['HOTO - Uploaded']] = np.nan\n",
    "    s.loc[s['O&M Call Status (Open/Closed)'] != 'O&M Open calls' , ['O&M Call Status (Open/Closed)']] = np.nan\n",
    "\n",
    "\n",
    "    s1 = pd.get_dummies(s['I & C Status'])\n",
    "    s2 = pd.get_dummies(s['HOTO - Uploaded'])\n",
    "\n",
    "    if len(s.loc[s['HOTO - Uploaded'].isnull(),['HOTO - Uploaded']]) == len(s):\n",
    "        s2['HOTO - Uploaded'] = 0\n",
    "\n",
    "    s3 = pd.get_dummies(s['HOTO Done'])\n",
    "\n",
    "    if len(s.loc[s['HOTO Done'].isnull(),['HOTO Done']]) == len(s):\n",
    "        s3['HOTO Pending'] = 0\n",
    "\n",
    "    s4 = pd.get_dummies(s['O&M Call Status (Open/Closed)'])\n",
    "    ro = s[['CMS Code']]\n",
    "    ro['CMS Code'] = 1\n",
    "    ro.columns = ['Total RO']\n",
    "\n",
    "    Summary = pd.concat([s[['Zone','State','Division']],ro,s1,s2,s3,s4],axis=1)\n",
    "\n",
    "    Summary = Summary.groupby(['Zone','State','Division']).sum()\n",
    "    Summary = Summary.T\n",
    "    Summary['GRAND TOTAL'] = Summary.sum(axis=1)\n",
    "    Summary = Summary.T\n",
    "    Summary['HOTO Pending'] = Summary['Total RO'] - Summary['HOTO Uploaded']\n",
    "    Summary_NAYARA = Summary.astype(int)\n",
    "    Summary_NAYARA = Summary_NAYARA.replace(0,' ')\n",
    "\n",
    "    # HOTO PIVOT Pan_India_NAYARA\n",
    "\n",
    "    tHP = nayara[['HOTO Remarks']]\n",
    "    tHP.columns = ['Count Of Remarks']\n",
    "    HP = pd.concat([nayara[['HOTO Dependency','HOTO Remarks']],tHP],axis=1)\n",
    "    HP = HP.dropna()\n",
    "    HP = HP.groupby(['HOTO Dependency','HOTO Remarks']).count()\n",
    "    HP = HP.replace(0,' ')\n",
    "\n",
    "    # O & M PIVOT Pan_India_NAYARA\n",
    "\n",
    "    tOM = nayara[['O & M Remarks']]\n",
    "    tOM.columns = ['Count Of Remarks']\n",
    "    OM = pd.concat([nayara[['O & M Dependency','O & M Remarks']],tOM],axis=1)\n",
    "    OM = OM.dropna()\n",
    "    OM = OM.groupby(['O & M Dependency','O & M Remarks']).count()\n",
    "    OM = OM.replace(0,' ')\n",
    "\n",
    "    ## SPARE PIVOT\n",
    "\n",
    "    p=nayara[['State','BOS CARD', 'FCC CARD', '5 VOLT SMPS', 'INTERFACE CARD',\n",
    "           'FCC with Accessory', 'DOOR LOCK RFID', 'Barrier board', 'Glands',\n",
    "           '12 SMPS', 'Total ATG probe', '2M', '2.25 M', '2.50 M', '2.75 M',\n",
    "           '3 M', 'HSD Density Float Kit', 'MS Density Float Kit',\n",
    "           'PRODUCT FLOAT KIT', 'WATER FLOAT KIT', 'RFID TAG', 'RFID READER',\n",
    "           'Neck Ribbon', 'Slave', 'MASTER', 'COMM Cable (M)', 'Epoxy KIT',\n",
    "           'MONITOR', 'KEYBOARD', 'MOUSE', 'USB HUB', 'MONITOR POWER CABLE',\n",
    "           'VGA CABLE', 'MCB', 'SPD', 'ROUTER', 'ROUTER ADOPTER', 'PATCH CORD (M)']]\n",
    "    Pivot = p.groupby('State').sum().T\n",
    "    Pivot['GRAND TOTAL'] = Pivot.sum(axis=1)\n",
    "    Pivot = Pivot.astype(int).replace(0,' ')\n",
    "\n",
    "    # EXPORTING FILES  Pan_India_NAYARA\n",
    "\n",
    "    Destination_URL_NAYARA = URL22 + slash + 'Pan_India_NAYARA_' + TD + '.xlsx'\n",
    "\n",
    "    writer5 = pd.ExcelWriter(Destination_URL_NAYARA , engine = 'xlsxwriter')\n",
    "    Summary_NAYARA.to_excel(writer5 , sheet_name = 'NAYARA SUMMARY')\n",
    "    HP.to_excel(writer5 , sheet_name = 'HOTO PIVOT')\n",
    "    OM.to_excel(writer5 , sheet_name = 'O&M PIVOT')\n",
    "    Pivot.to_excel(writer5,sheet_name = 'SPARE PIVOT')\n",
    "    nayara.to_excel(writer5 , sheet_name = 'NAYARA DETAILS' , index = False)\n",
    "    writer5.save()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESSFULLY Built & Exported PAN_INDIA_NAYARA Report')\n",
    "\n",
    "\n",
    "\n",
    "    # Looping................\n",
    "\n",
    "    while incrementer < len(incrementer_lst):\n",
    "\n",
    "        print('\\033[1m' + '\\033[92m' + 'Building ' + incrementer_lst[incrementer] + ' HPCL , BPCL & NAYARA' + ' Reports...')\n",
    "\n",
    "        a = incrementer_lst[incrementer]\n",
    "\n",
    "\n",
    "        #....................................................HPCL.................................................................#\n",
    "\n",
    "\n",
    "        # Extracting Required Data_HPCL HPCL\n",
    "\n",
    "        df = pd.read_excel(URL1 + '\\HPCL_' + 'Pan_India_Report_'+ YD +'.xlsx')   # Pan_India_HPCl\n",
    "        ref = pd.read_excel(URL2 + '\\HPCL_' + 'NANO_HISTORY_' + TD + '.xlsx')  # Nano History last date\n",
    "        location = pd.read_excel(URL3 + '\\Zone_State_Region' + '.xlsx' , 'HPCL')   # Fixed location\n",
    "\n",
    "        # Cleaning ALL Above Data_HPCL\n",
    "\n",
    "        df = df.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "        location = location.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        location = location.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "\n",
    "        # Should be changed according to file\n",
    "\n",
    "        #df = df.drop(['Connectivity Status','Connectivity Vendor'],axis=1)\n",
    "\n",
    "        # Cleaning NANO History\n",
    "\n",
    "        NANO_HISTORY = ref.iloc[11:,:].dropna(how='all',axis=1)\n",
    "        NANO_HISTORY.columns = list(NANO_HISTORY.iloc[0])\n",
    "        NANO_HISTORY = NANO_HISTORY.rename(columns = {'Pumps Configured':'Today Pumps Configured' , 'Tanks Configured':'Tanks Configured Today'})\n",
    "\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop(columns='index').iloc[1:len(NANO_HISTORY)-1].reset_index().drop('index',axis=1)\n",
    "        NANO_HISTORY['Region'] = NANO_HISTORY['Region'].str.upper()\n",
    "        NANO_HISTORY = location[['Region','State','State Office']].merge(NANO_HISTORY , how = 'right' , on = ['Region'])\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop('index',axis=1)\n",
    "        df = df.drop_duplicates(subset='ROCode')\n",
    "        NANO_HISTORY = NANO_HISTORY.drop_duplicates(subset='ROCode')\n",
    "\n",
    "        # .......\n",
    "\n",
    "        df['Reason'] = df['Reason'].str.upper()\n",
    "        df['Remarks'] = df['Remarks'].str.upper()\n",
    "        df['Dependency'] = df['Dependency'].str.upper()\n",
    "        df['Region'] = df['Region'].str.upper()\n",
    "        df['State Office'] = df['State Office'].str.upper()\n",
    "\n",
    "        HPCL = df       # Making A Copy Of Yesterday's Pan_India_HPCL\n",
    "\n",
    "        df['Yesterday Tanks Configured'] = df['Tanks Configured Today']\n",
    "        df['Yesterday Pumps Configured'] = df['Today Pumps Configured']\n",
    "        lstnano = list(set(NANO_HISTORY.columns.tolist()) & set(df.columns.tolist()))\n",
    "        lstnano.remove('ROCode')\n",
    "        df1 = df.drop(lstnano,axis=1)\n",
    "        Data_HPCL = df1.reset_index().drop('index',axis=1)\n",
    "        NANO_HISTORY = NANO_HISTORY.reset_index().drop('index',axis=1)\n",
    "        Data_HPCL = Data_HPCL.merge(NANO_HISTORY, how = 'outer' , on = ['ROCode'])\n",
    "        Data_HPCL = Data_HPCL.reset_index().drop('index',axis=1)\n",
    "        Data_HPCL = Data_HPCL[df.columns.tolist()]\n",
    "\n",
    "        Data_HPCL.loc[Data_HPCL['Status'] == 'Fully Communicated' , ['Reason','Remarks','Dependency']] = np.nan\n",
    "        Data_HPCL.loc[Data_HPCL['Status'] == 'Temporary Close' , ['Reason','Remarks','Dependency']] = np.nan\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Reason'].isnull()) , ['Reason']] = 'TBF'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Reason'].isnull()) , ['Reason']] = 'TBF'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Remarks'].isnull()) , ['Remarks']] ='TO BE FOUND'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Remarks'].isnull()) , ['Remarks']] ='TO BE FOUND'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Not Communicated') & (Data_HPCL['Dependency'].isnull()) , ['Dependency']] = 'AGS'\n",
    "        Data_HPCL.loc[(Data_HPCL['Status'] == 'Partially Communicated') & (Data_HPCL['Dependency'].isnull()) , ['Dependency']] = 'AGS'\n",
    "\n",
    "        Data_HPCL['Difference'] = Data_HPCL['Today Pumps Configured'].sub(Data_HPCL['Yesterday Pumps Configured'] , axis = 0)\n",
    "        Data_HPCL['Difference.1'] = Data_HPCL['Tanks Configured Today'].sub(Data_HPCL['Yesterday Tanks Configured'] , axis = 0)\n",
    "\n",
    "        Data_HPCL = Data_HPCL.astype(int , errors = 'ignore')\n",
    "        Data_HPCL = Data_HPCL.drop_duplicates()\n",
    "        Data_HPCL = location[['Region','State']].merge(Data_HPCL , how = 'right' , on = ['Region'])\n",
    "        HPCL_2 = Data_HPCL.drop('State',axis=1)  # Copy of pan india\n",
    "\n",
    "        # Summary\n",
    "\n",
    "        ds1 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Dependency'] , values = 'Remarks' , aggfunc = len ,fill_value=0)#,margins =True)\n",
    "        ds2 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Reason'] , values = 'Remarks' , aggfunc = len ,fill_value=0)\n",
    "        ds2 = ds2[ds2.columns.tolist()]\n",
    "        ds3 =  Data_HPCL.pivot_table(index = ['State Office','State','Region'], columns = ['Status'] , values = 'Remarks' , aggfunc = len ,fill_value=0)\n",
    "        ds3['Total'] = ds3['Fully Communicated'] + ds3['Not Communicated'] + ds3['Partially Communicated']\n",
    "        ds3['NANO %'] = (ds3['Fully Communicated']/ ds3[\"Total\"])*100\n",
    "        Summary = pd.concat([ds3[['NANO %']],ds2,ds1],keys=[' ','Reason for NANO Absence','Issue Classification'],axis=1)\n",
    "\n",
    "        Summary = Summary.T[a].T  # Filtering State wise\n",
    "\n",
    "        ts = Summary[['Reason for NANO Absence','Issue Classification']]\n",
    "        ts = ts.T\n",
    "        ts['Grand Total'] = ts.sum(axis = 1)\n",
    "        ts = ts.fillna(0)\n",
    "        ts = ts.T.astype(int)\n",
    "        tn = Summary[[' ']]\n",
    "        tn = tn.T\n",
    "        tn['Grand Total'] = tn.mean(axis=1)\n",
    "        tn = tn.T\n",
    "        tn = tn.round(2)\n",
    "        Summary = pd.concat([tn,ts],axis=1)\n",
    "        Summary = Summary.replace(0,' ')\n",
    "\n",
    "\n",
    "        # Building Main Data & Pivot_Tables\n",
    "\n",
    "        # 1\n",
    "        a1 = Data_HPCL[['State Office','Remarks']]\n",
    "        a2 = pd.get_dummies(Data_HPCL['Dependency'])\n",
    "        #a2.columns = ['AGS','DEALER','HPCL']\n",
    "        Data_HPCL_t = pd.concat([a1,a2],axis=1)\n",
    "        Data_HPCL_m = Data_HPCL_t[Data_HPCL_t['State Office'] == a]\n",
    "        Data_HPCLp1 = Data_HPCL_m.set_index('Remarks')\n",
    "        Pivot_1 = Data_HPCLp1.groupby('Remarks').sum()\n",
    "\n",
    "        Pivot_1.loc['Grand Total'] = Pivot_1.sum()  # for column \n",
    "        Pivot_1['Grand Total'] = Pivot_1.sum(axis=1) # for row\n",
    "        Pivot_1 = Pivot_1.replace(0 ,' ')\n",
    "        P_t1 = Pivot_1.iloc[:,0:3]\n",
    "        P_t2 = Pivot_1[['Grand Total']]\n",
    "        Pivot_1 = pd.concat([P_t1,P_t2] , keys = ['Dependency' , ' '] , axis = 1)\n",
    "\n",
    "\n",
    "        # 2\n",
    "        Data_HPCL = Data_HPCL[Data_HPCL['State Office'] == a]   # Breaking State Office wise\n",
    "        ttdf = Data_HPCL[Data_HPCL.columns.tolist()[31:]]\n",
    "        tdf = pd.concat([Data_HPCL.Region,ttdf],axis=1)\n",
    "        Pivot_2 = tdf.groupby('Region').count().T\n",
    "        Pivot_2['Grand Total'] = Pivot_2.sum(axis=1) # for row\n",
    "        Pivot_2 = Pivot_2.replace(0,np.nan)\n",
    "        Pivot_2 = Pivot_2.dropna(how = 'all',axis=0)\n",
    "        Pivot_2 = Pivot_2.fillna(0)\n",
    "        Pivot_2 = Pivot_2.astype(int)\n",
    "        Pivot_2 = Pivot_2.replace(0 , ' ')\n",
    "\n",
    "        # Finalizing Data\n",
    "\n",
    "        Data_HPCL = Data_HPCL.drop('State',axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #...................................................BPCL...........................................................#\n",
    "\n",
    "        #Extracting Required Data BPCL\n",
    "\n",
    "        prod1 = pd.read_excel(URL5 + '\\Prod1 ' + TD + '.xlsx')    # Production 1\n",
    "        prod2 = pd.read_excel(URL6 + '\\Prod2 ' + TD + '.xlsx')  # Production 2  \n",
    "        Pan_India = pd.read_excel(URL10 + '\\BPCL_Pan_India_Report_' + YD + '.xlsx')\n",
    "        location = pd.read_excel(URL3 + '\\Zone_State_Region' + '.xlsx','BPCL')      # Fixed location\n",
    "        HOS = pd.read_excel(URL7 + '\\BPCL_HOS_' + TD + '.xlsx')   # HOS Onboarding\n",
    "\n",
    "        # CLeaning ALL Above\n",
    "\n",
    "        Pan_India = Pan_India.drop_duplicates(subset = 'CC')\n",
    "\n",
    "        Pan_India = Pan_India.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        Pan_India = Pan_India.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        location = location.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        location = location.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "\n",
    "        # MAking a copy of Yesterday's Pan_India_BPCL\n",
    "\n",
    "        BPCL = Pan_India\n",
    "\n",
    "\n",
    "        # Building Pan_India_Data\n",
    "\n",
    "        HOS_lst = HOS.iloc[1,:].tolist()\n",
    "        HOS.columns = [HOS_lst]\n",
    "        HOS = HOS.iloc[2:,:]\n",
    "\n",
    "        Final_HOS = HOS[['RO SAPCC','Status']]\n",
    "        Final_HOS.columns = ['CC','Status']\n",
    "        Final_HOS = Final_HOS.drop_duplicates(subset = ['CC'])\n",
    "\n",
    "        Pan_lst = Pan_India.columns.tolist()\n",
    "        Pan_India['CC'] = Pan_India['CC'].astype(int)\n",
    "        Final_HOS['CC'] = Final_HOS['CC'].astype(int)\n",
    "\n",
    "        Final_HOS1 = Final_HOS[['CC']]\n",
    "        Final_HOS1['Onboarded- YES/NO'] = 'YES'\n",
    "\n",
    "        Final_HOS2 = Final_HOS\n",
    "        Final_HOS2['Onboarding Reflecting On Server'] = np.nan\n",
    "        Final_HOS2.loc[Final_HOS2['Status'] == 'Completed' , ['Onboarding Reflecting On Server']] = 'YES'\n",
    "        Final_HOS2.loc[Final_HOS2['Status'] == 'Initiated' , ['Onboarding Reflecting On Server']] = 'NO'\n",
    "        Final_HOS2 = Final_HOS2.drop('Status',axis=1)\n",
    "\n",
    "        prod1.columns = prod1.iloc[1,:]\n",
    "        prod2.columns = prod2.iloc[1,:]\n",
    "        prod1 = prod1.iloc[2:,:]\n",
    "        prod2 = prod2.iloc[2:,:]\n",
    "        prod1 = prod1.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        prod2 = prod2.apply(lambda x:x.str.strip(' ') if x.dtype == 'str' else x)\n",
    "        prod1 = prod1.drop_duplicates(subset='RO SAP CC',keep='first')\n",
    "        prod2 = prod2.drop_duplicates(subset='RO SAP CC',keep='first')\n",
    "        Final_Prod = pd.DataFrame(list(set(list(set(list(prod1['RO SAP CC']) + list(prod2['RO SAP CC']))))))\n",
    "        Final_Prod.columns = ['CC']\n",
    "        Final_Prod['CC'] = Final_Prod['CC'].astype(int)\n",
    "\n",
    "        Final_Prod['Today Auto RSP'] = 'YES'\n",
    "\n",
    "        Pan_India['Previous Day Auto RSP'] = Pan_India['Today Auto RSP']\n",
    "\n",
    "\n",
    "        Pan_India = Pan_India.drop(columns = ['Today Auto RSP','Onboarded- YES/NO','Onboarding Reflecting On Server','Sr no'])\n",
    "\n",
    "\n",
    "        Pan_India = Final_Prod.merge(Pan_India , how = 'outer' , on = ['CC'])\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "        Final_HOS3 = Final_HOS1.merge(Final_HOS2 , how = 'outer' , on =['CC'])\n",
    "        Final_HOS3 = Final_HOS3.reset_index().drop('index',axis=1)\n",
    "        Pan_India = Final_HOS3.merge(Pan_India , how = 'outer' , on = ['CC'])\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "\n",
    "\n",
    "        Pan_India.loc[Pan_India['Today Auto RSP'] == 'YES' , ['Reasons for Auto-RSP Absence','Remarks for AUTO-RSP absence','Dependency for Auto-RSP Absence','Reasons for sites not upgraded','Remarks for sites not upgraded','Dependency for Sites not upgraded','Description']] = np.nan\n",
    "\n",
    "        Pan_India.loc[Pan_India['Today Auto RSP'].isnull(),['Today Auto RSP']] = 'NO'\n",
    "        Pan_India.loc[Pan_India['Onboarding Reflecting On Server'].isnull(),['Onboarding Reflecting On Server']] = 'NO'\n",
    "        Pan_India.loc[Pan_India['Onboarded- YES/NO'].isnull(),['Onboarded- YES/NO']] = 'NO'\n",
    "\n",
    "\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Reasons for Auto-RSP Absence'].isnull()) , ['Reasons for Auto-RSP Absence']] = 'TBF'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Remarks for AUTO-RSP absence'].isnull()), ['Remarks for AUTO-RSP absence' ]] = 'TO BE FOUND'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'YES') & (Pan_India['Today Auto RSP'] == 'NO') & (Pan_India['Dependency for Auto-RSP Absence'].isnull()),['Dependency for Auto-RSP Absence']] = 'AGS'\n",
    "\n",
    "\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Reasons for sites not upgraded'].isnull()),['Reasons for sites not upgraded']] = 'TBF'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Remarks for sites not upgraded'].isnull()),['Remarks for sites not upgraded']] = 'TO BE FOUND'\n",
    "        Pan_India.loc[(Pan_India['Upgraded-Yes/No'] == 'NO') & (Pan_India['Dependency for Sites not upgraded'].isnull()),['Dependency for Sites not upgraded']] = 'AGS'\n",
    "\n",
    "        Pan_India = Pan_India.reset_index().drop('index',axis=1)\n",
    "        Pan_India['Sr no'] = np.nan\n",
    "        Pan_India['Sr no'] = list(range(1,len(Pan_India)+1))\n",
    "        Pan_India = Pan_India[Pan_lst]\n",
    "\n",
    "\n",
    "\n",
    "        # Pivot_1 (P1) (Auto-RSP)\n",
    "\n",
    "        India = Pan_India.drop('Region', axis = 1)\n",
    "        India['Dependency for Sites not upgraded'] = India['Dependency for Sites not upgraded'].replace('BPCl','BPCL')\n",
    "        India = India.rename(columns = {'Territory':'Region'})\n",
    "        India['Region'] = India['Region'].str.upper()\n",
    "        India = India.merge(location[['State Office','Region']] , on = ['Region'])\n",
    "        India = India.drop_duplicates()\n",
    "        P1 = pd.get_dummies(India['Dependency for Auto-RSP Absence'])\n",
    "        #P1.columns = ['AGS','BPCL','DEALER']\n",
    "        P1 = pd.concat([P1,India[['State Office','Remarks for AUTO-RSP absence']]],axis = 1)\n",
    "        P1 = P1.loc[(P1['State Office'] == a) & (P1['Remarks for AUTO-RSP absence'] == P1['Remarks for AUTO-RSP absence']),['Remarks for AUTO-RSP absence','AGS','BPCL','DEALER','TBF']]\n",
    "        P1 = pd.concat([P1.groupby('Remarks for AUTO-RSP absence').sum()] , keys = ['Dependency for Auto-RSP Absence'] , axis = 1)\n",
    "        P1.loc['Grand Total'] = P1.sum()  # for column \n",
    "        P1['Grand Total'] = P1.sum(axis=1) # for row\n",
    "        P1 = P1.astype(int)\n",
    "        P1.replace(0, ' ', inplace = True)\n",
    "\n",
    "        # Pivot_2 (P2) ()\n",
    "\n",
    "        P2 = pd.get_dummies(India['Dependency for Sites not upgraded'])\n",
    "        #P2.columns = ['AGS','BPCL']\n",
    "        P2 = pd.concat([P2,India[['State Office','Remarks for sites not upgraded']]],axis = 1)\n",
    "        P2 = P2.loc[(P2['State Office'] == a) & (P2['Remarks for sites not upgraded'] == P2['Remarks for sites not upgraded']),['Remarks for sites not upgraded','AGS','BPCL']]\n",
    "        P2 = pd.concat([P2.groupby('Remarks for sites not upgraded').sum()] , keys = ['Dependency for Sites not upgraded'] , axis = 1)\n",
    "        P2.loc['Grand Total'] = P2.sum()  # for column \n",
    "        P2['Grand Total'] = P2.sum(axis=1) # for row\n",
    "        P2 = P2.astype(int)\n",
    "        P2.replace(0, ' ', inplace = True)\n",
    "\n",
    "        # Summary (S) \n",
    "\n",
    "        T_India = India[India['State Office'] == a]\n",
    "\n",
    "\n",
    "                                      # Changing names #\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'TBF' , ['Reasons for sites not upgraded']] ='TBF-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'RAP' , ['Reasons for sites not upgraded']] ='RAP-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'FVP' , ['Reasons for sites not upgraded']] ='FVP-U'\n",
    "        T_India.loc[T_India['Reasons for sites not upgraded'] == 'II' , ['Reasons for sites not upgraded']] ='II-U'\n",
    "\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'AGS' , ['Dependency for Sites not upgraded']] ='AGS-U'\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'BPCL' , ['Dependency for Sites not upgraded']] ='BPCL-U'\n",
    "        T_India.loc[T_India['Dependency for Sites not upgraded'] == 'DEALER' , ['Dependency for Sites not upgraded']] ='DEALER-U'\n",
    "\n",
    "\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'TBF' , ['Reasons for Auto-RSP Absence']] ='TBF-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'RAP' , ['Reasons for Auto-RSP Absence']] ='RAP-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'FVP' , ['Reasons for Auto-RSP Absence']] ='FVP-A'\n",
    "        T_India.loc[T_India['Reasons for Auto-RSP Absence'] == 'II' , ['Reasons for Auto-RSP Absence']] ='II-A'\n",
    "\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'AGS' , ['Dependency for Auto-RSP Absence']] ='AGS-A'\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'BPCL' , ['Dependency for Auto-RSP Absence']] ='BPCL-A'\n",
    "        T_India.loc[T_India['Dependency for Auto-RSP Absence'] == 'DEALER' , ['Dependency for Auto-RSP Absence']] ='DEALER-A'\n",
    "\n",
    "\n",
    "\n",
    "        S1 = T_India.loc[India['Upgraded-Yes/No'] == 'YES' , ['Region','Upgraded-Yes/No']].groupby('Region').count()\n",
    "        S2 = T_India.loc[India['Onboarded- YES/NO'] == 'YES' , ['Region','Onboarded- YES/NO']].groupby('Region').count()\n",
    "        S3 = pd.DataFrame(T_India['Region'].value_counts())\n",
    "        S4 = T_India.loc[T_India['Onboarding Reflecting On Server'] == 'YES' , ['Region','Onboarding Reflecting On Server']].groupby('Region').count()\n",
    "        S5 = T_India.loc[T_India['Today Auto RSP'] == 'YES' , ['Region','Today Auto RSP']].groupby('Region').count()\n",
    "\n",
    "        S5['Auto RSP %'] = (S5['Today Auto RSP']/S1['Upgraded-Yes/No'])*100\n",
    "\n",
    "        S5 = S5.round(2)\n",
    "        S6 = pd.get_dummies(T_India['Reasons for sites not upgraded']).groupby(T_India['Region']).sum()\n",
    "        S7 = pd.get_dummies(T_India['Dependency for Sites not upgraded']).groupby(T_India['Region']).sum()\n",
    "        S8 = pd.get_dummies(T_India['Reasons for Auto-RSP Absence']).groupby(T_India['Region']).sum()\n",
    "        S9 = pd.get_dummies(T_India['Dependency for Auto-RSP Absence']).groupby(T_India['Region']).sum()\n",
    "\n",
    "        S = S1.join(S2).join(S3).join(S4).join(S5).join(S6).join(S7).join(S8).join(S9).fillna(0).astype(int)\n",
    "\n",
    "        s0 = S[['Upgraded-Yes/No','Onboarded- YES/NO','Region','Onboarding Reflecting On Server','Today Auto RSP','Auto RSP %']]\n",
    "        s0.columns = ['UPGRADED','ONBOARDED','GRAND TOTAL','ONBOARDING REFLECTING ON SERVER','AUTO RSP','AUTO RSP %']\n",
    "        s1 = S[S6.columns.tolist()]\n",
    "        s2 = S[S7.columns.tolist()]\n",
    "        s3 = S[S8.columns.tolist()]\n",
    "        s4 = S[S9.columns.tolist()]\n",
    "\n",
    "        Summary_b = pd.concat([s0.reset_index().drop('Region',axis=1),s1.reset_index().drop('Region',axis=1),s2.reset_index().drop('Region',axis=1),s3.reset_index().drop('Region',axis=1),s4.reset_index().drop('Region',axis=1)] , keys = [' ','Reasons for sites not upgraded','ISSUE CLASSIFICATION','Reasons for Auto-RSP Absence','ISSUE CLASSIFICATION_1'],axis=1)\n",
    "        Summary_b['Zone'] = a\n",
    "        Summary_b['Region'] = s0.reset_index()['Region']\n",
    "        Summary_b = Summary_b.groupby(['Zone','Region']).first()\n",
    "        Summary_b = Summary_b.T\n",
    "        Summary_b['Grand Total'] = Summary_b.sum(axis = 1) # for row\n",
    "        Summary_b = Summary_b.T\n",
    "        Summary_b = Summary_b.astype(int)\n",
    "\n",
    "        if len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) > 0:\n",
    "            Summary_b.iloc[-1,5] = sum(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) / len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1])\n",
    "        elif len(Summary_b[' ']['AUTO RSP %'].tolist()[:-1]) == 0:\n",
    "            Summary_b.iloc[-1,5] = 0\n",
    "\n",
    "        Summary_b = Summary_b.astype(int)\n",
    "        Summary_b = Summary_b.replace(0,' ')\n",
    "\n",
    "        # Building State_Office_Wise_Data\n",
    "\n",
    "        Pan_India = Pan_India.merge(location[['State','State Office']] , how = 'left' , on = ['State'])\n",
    "\n",
    "\n",
    "        BPCL_2 = Pan_India    # Copy of pan india\n",
    "        BPCL_2 = BPCL_2.drop('State Office',axis=1)\n",
    "        BPCL_2 = BPCL_2.drop_duplicates(subset='CC')\n",
    "        BPCL_2['Sr no'] = list(range(1,len(BPCL_2['Sr no'])+1))\n",
    "\n",
    "        Pan_India = Pan_India[Pan_India['State Office'] == a]\n",
    "        Pan_India = Pan_India.drop('State Office',axis=1)\n",
    "        Pan_India = Pan_India.drop_duplicates(subset='CC')\n",
    "        Pan_India['Sr no'] = list(range(1,len(Pan_India['Sr no'])+1))\n",
    "\n",
    "        # Building Pivot 3\n",
    "\n",
    "        p3 = Pan_India\n",
    "\n",
    "        p3 =p3[['Territory','FCC(WIRED)', 'INTERFACE CARD', 'FCC(WIRELESS)', 'SLAVE',\n",
    "               'MONILITH SLAVE', 'MASTER', 'SMPS(5V)', 'SMPS(12V)', 'SLAVE SMPS',\n",
    "               'MONITOR', 'KEYBOARD', 'MOUSE', 'OTHERS']]\n",
    "\n",
    "        p3 = p3.replace(np.nan , 0)\n",
    "        p3 = p3.groupby('Territory').sum().T\n",
    "        p3.loc['GRAND TOTAL'] = p3.sum()\n",
    "        p3 = p3.astype(int)\n",
    "        p3 = p3.replace(0 , np.nan)\n",
    "        p3 = pd.concat([p3],keys = ['REGION'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        #.............................................NAYARA REPORTS...................................................#\n",
    "\n",
    "\n",
    "\n",
    "        nayara = pd.read_excel(URL24 + slash + a + '.xlsx', 'NAYARA DETAILS')\n",
    "        nayara.columns = cols_nayara\n",
    "\n",
    "        nayara = nayara.apply(lambda x:x.str.strip(' ') if x.dtype == 'object' else x)\n",
    "        nayara = nayara.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "        nayara = nayara.drop_duplicates(subset = 'CMS Code')\n",
    "        nayara = nayara.reset_index().drop('index',axis=1)\n",
    "        nayara['Sr No.'] = list(range(1,len(nayara)+1))\n",
    "\n",
    "\n",
    "        # SUMMARY nayara state wise\n",
    "\n",
    "        s = nayara[['Zone', 'State','Division','CMS Code','I & C Status', 'HOTO Done','HOTO - Uploaded','O&M Call Status (Open/Closed)'\n",
    "                    ,'Spare Requirement','Delivery Status']]\n",
    "        s.loc[s['I & C Status'] == 'COMPLETED', ['I & C Status']] = 'I/C Completed'\n",
    "        s.loc[s['I & C Status'] == 'PENDING' , ['I & C Status']] = 'I/C Pending'\n",
    "\n",
    "        s.loc[s['HOTO Done'] == 'N',['HOTO Done']] = 'HOTO Pending'\n",
    "\n",
    "        s.loc[s['HOTO - Uploaded'] == 'Y' , ['HOTO - Uploaded']] = 'HOTO Uploaded'\n",
    "        s.loc[s['O&M Call Status (Open/Closed)'] == 'OPEN',['O&M Call Status (Open/Closed)']] = 'O&M Open calls'\n",
    "\n",
    "        s.loc[(s['I & C Status'] != 'I/C Completed') & (s['I & C Status'] != 'I/C Pending') , ['I & C Status']] = np.nan\n",
    "        s.loc[s['HOTO Done'] != 'HOTO Pending' ,['HOTO Done']] = np.nan\n",
    "        s.loc[s['HOTO - Uploaded'] != 'HOTO Uploaded' , ['HOTO - Uploaded']] = np.nan\n",
    "        s.loc[s['O&M Call Status (Open/Closed)'] != 'O&M Open calls' , ['O&M Call Status (Open/Closed)']] = np.nan\n",
    "\n",
    "\n",
    "        s1 = pd.get_dummies(s['I & C Status'])\n",
    "        s2 = pd.get_dummies(s['HOTO - Uploaded'])\n",
    "\n",
    "        if len(s.loc[s['HOTO - Uploaded'].isnull(),['HOTO - Uploaded']]) == len(s):\n",
    "            s2['HOTO Uploaded'] = 0\n",
    "\n",
    "        s3 = pd.get_dummies(s['HOTO Done'])\n",
    "\n",
    "        if len(s.loc[s['HOTO Done'].isnull(),['HOTO Done']]) == len(s):\n",
    "            s3['HOTO Pending'] = 0\n",
    "\n",
    "        s4 = pd.get_dummies(s['O&M Call Status (Open/Closed)'])\n",
    "        ro = s[['CMS Code']]\n",
    "        ro['CMS Code'] = 1\n",
    "        ro.columns = ['Total RO']\n",
    "\n",
    "        Summary_N = pd.concat([s[['Zone','State','Division']],ro,s1,s2,s3,s4],axis=1)\n",
    "\n",
    "        Summary_N = Summary_N.groupby(['Zone','State','Division']).sum()\n",
    "        Summary_N = Summary_N.T\n",
    "        Summary_N['GRAND TOTAL'] = Summary_N.sum(axis=1)\n",
    "        Summary_N = Summary_N.T\n",
    "        Summary_N['HOTO Pending'] = Summary_N['Total RO'] - Summary_N['HOTO Uploaded']\n",
    "        Summary_State_NAYARA = Summary_N.astype(int)\n",
    "        Summary1_State_NAYARA = Summary_State_NAYARA   # For Mails\n",
    "        Summary1_State_NAYARA = Summary1_State_NAYARA.replace(0,' ')\n",
    "\n",
    "\n",
    "\n",
    "        # HOTO PIVOT Nayara State wise\n",
    "        tHP = nayara[['HOTO Remarks']]\n",
    "        tHP.columns = ['Count Of Remarks']\n",
    "        HP = pd.concat([nayara[['HOTO Dependency','HOTO Remarks']],tHP],axis=1)\n",
    "        HP = HP.dropna()\n",
    "        HP = HP.groupby(['HOTO Dependency','HOTO Remarks']).count()\n",
    "        HP = HP.replace(0,' ')\n",
    "\n",
    "\n",
    "        # O & M PIVOT Nayara State Wise\n",
    "\n",
    "\n",
    "        tOM = nayara[['O & M Remarks']]\n",
    "        tOM.columns = ['Count Of Remarks']\n",
    "        OM = pd.concat([nayara[['O & M Dependency','O & M Remarks']],tOM],axis=1)\n",
    "        OM = OM.dropna()\n",
    "        OM = OM.groupby(['O & M Dependency','O & M Remarks']).count()\n",
    "        OM = OM.replace(0,' ')\n",
    "\n",
    "        # SPARE PIVOT NAyara State Wise\n",
    "\n",
    "        p=nayara[['State','BOS CARD', 'FCC CARD', '5 VOLT SMPS', 'INTERFACE CARD',\n",
    "               'FCC with Accessory', 'DOOR LOCK RFID', 'Barrier board', 'Glands',\n",
    "               '12 SMPS', 'Total ATG probe', '2M', '2.25 M', '2.50 M', '2.75 M',\n",
    "               '3 M', 'HSD Density Float Kit', 'MS Density Float Kit',\n",
    "               'PRODUCT FLOAT KIT', 'WATER FLOAT KIT', 'RFID TAG', 'RFID READER',\n",
    "               'Neck Ribbon', 'Slave', 'MASTER', 'COMM Cable (M)', 'Epoxy KIT',\n",
    "               'MONITOR', 'KEYBOARD', 'MOUSE', 'USB HUB', 'MONITOR POWER CABLE',\n",
    "               'VGA CABLE', 'MCB', 'SPD', 'ROUTER', 'ROUTER ADOPTER', 'PATCH CORD (M)']]\n",
    "        Pivot = p.groupby('State').sum().T\n",
    "        Pivot['GRAND TOTAL'] = Pivot.sum(axis=1)\n",
    "        Pivot = Pivot.astype(int).replace(0,' ')\n",
    "\n",
    "\n",
    "        # Maintaining Files\n",
    "\n",
    "        if len(HP) == 0:\n",
    "            HP = HP.reset_index()\n",
    "\n",
    "        if len(OM) == 0:\n",
    "            OM = OM.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "        print('\\033[0m' + 'Files Made Succesfully')\n",
    "        print('\\033[0m' + 'Styling & Exporting Files Please Wait...')\n",
    "\n",
    "        # Styling Getting the content to be centered \n",
    "\n",
    "        Data_HPCL_s = Data_HPCL\n",
    "        Summary_s = Summary\n",
    "        Pivot_1_s = Pivot_1\n",
    "        Pivot_2_s = Pivot_2\n",
    "        #UPDATED_PAN_HPCL_REMARKS_s = UPDATED_PAN_HPCL_REMARKS.style.set_properties(**{'text-align':'center'})\n",
    "\n",
    "        Final_Statewise_India_s = Pan_India\n",
    "        P1_s = P1\n",
    "        P2_s = P2\n",
    "        P3_s = p3\n",
    "        Summary_b_s = Summary_b\n",
    "        #UPDATED_PAN_BPCL_REMARKS_s = UPDATED_PAN_BPCL_REMARKS.style.set_properties(**{'text-align':'center'})\n",
    "\n",
    "\n",
    "        # Exporting Neccessary Files  (HPCL)\n",
    "\n",
    "        Destination_URL = URL8 + '\\HPCL_' + a + '_' + TD +'.xlsx'\n",
    "\n",
    "        writer1 = pd.ExcelWriter(Destination_URL , engine = 'xlsxwriter')\n",
    "        #UPDATED_PAN_HPCL_REMARKS_s.to_excel(writer1 , sheet_name = 'UPDATED REMARKS HPCL',index=False)\n",
    "        Summary_s.to_excel(writer1 , sheet_name = 'Summary')\n",
    "        Pivot_1_s.to_excel(writer1 , sheet_name = 'Pivot_Remarks')\n",
    "        Pivot_2_s.to_excel(writer1 , sheet_name = 'Pivot_Spares')\n",
    "        Data_HPCL_s.to_excel(writer1 , sheet_name = 'Data' , index = False)\n",
    "        writer1.save()\n",
    "\n",
    "\n",
    "        # Exporting Neccessary Files  (BPCL)\n",
    "\n",
    "        Destination_URL_B = URL9 + '\\BPCL_' + a + '_' + TD +'.xlsx'\n",
    "\n",
    "        writer2 = pd.ExcelWriter(Destination_URL_B , engine = 'xlsxwriter')\n",
    "        #UPDATED_PAN_BPCL_REMARKS_s.to_excel(writer2 , sheet_name = 'UPDATED REMARKS BPCL',index=False)\n",
    "        Summary_b_s.to_excel(writer2 , sheet_name = 'Summary')\n",
    "        P1_s.to_excel(writer2 , sheet_name = 'Issue Analysis Auto RSP')\n",
    "        P2_s.to_excel(writer2 , sheet_name = 'Issue Analysis Pending Upgrades')\n",
    "        P3_s.to_excel(writer2 , sheet_name = 'Spare Required')\n",
    "        Final_Statewise_India_s.to_excel(writer2 , sheet_name = 'Data' , index = False)\n",
    "        writer2.save()\n",
    "\n",
    "        # EXPORTING FILES NAYARA STATE WISE\n",
    "\n",
    "        Destination_URL_STATE_NAYARA = URL23 + slash + 'NAYARA_' + a + '_' + TD + '.xlsx'\n",
    "\n",
    "        writer6 = pd.ExcelWriter(Destination_URL_STATE_NAYARA , engine = 'xlsxwriter')\n",
    "        Summary_State_NAYARA.to_excel(writer6 , sheet_name = 'NAYARA SUMMARY')\n",
    "        HP.to_excel(writer6 , sheet_name = 'HOTO PIVOT')\n",
    "        OM.to_excel(writer6 , sheet_name = 'O&M PIVOT')\n",
    "        Pivot.to_excel(writer6,sheet_name = 'SPARE PIVOT')\n",
    "        nayara.to_excel(writer6 , sheet_name = 'NAYARA DETAILS' , index = False)\n",
    "        writer6.save()\n",
    "\n",
    "\n",
    "        print('\\033[0m' + 'All Files Saved Succesfully')\n",
    "\n",
    "\n",
    "        incrementer += 1 \n",
    "\n",
    "        if incrementer < len(incrementer_lst):\n",
    "            print('\\033[0m' + 'Wait Next File, In Process...')\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + 'Extracting NEW SITES Records...')\n",
    "\n",
    "    # Getting New Sites Records\n",
    "\n",
    "    HPCL_2 = HPCL_2[HPCL_2['Region'].isnull()]\n",
    "    HPCL_2.to_excel(URL8 + slash + 'NEW_SITES_HPCL.xlsx')\n",
    "\n",
    "    BPCL_2 = BPCL_2[(BPCL_2['Region'].isnull()) | (BPCL_2['State'].isnull()) | (BPCL_2['Territory'].isnull())]\n",
    "    BPCL_2.to_excel(URL9 + slash + 'NEW_SITES_BPCL.xlsx')\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"STATE WISE OPERATION'S SUCCESSFUL\")\n",
    "\n",
    "    # Exporting PAN_INDIA HPCL & BPCL Reports\n",
    "\n",
    "    print('\\033[0m' + 'Exporting PAN_INDIA HPCL & BPCL Reports Wait...')\n",
    "\n",
    "    # HPCL\n",
    "    states_for_pan = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO','KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "    i = 0\n",
    "    Pan_India_HPCL =pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_HPCL = pd.read_excel(URL18 + slash + TD + slash +'HPCL_' + states_for_pan[i] + '_' + TD + '.xlsx', 'Data')\n",
    "        Pan_India_HPCL = pd.concat([Pan_India_HPCL,extract_State_HPCL])\n",
    "        i +=1\n",
    "    Pan_India_HPCL.to_excel(URL11 +'\\HPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "    Pan_India_HPCL.to_excel(URL11 + '\\Backup But Without Update' + '\\HPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "\n",
    "    print('\\033[0m' + 'SUCCESSFULLY File Saved As : ' + 'HPCL_Pan_India_Report_' + TD)\n",
    "\n",
    "    # BPCL\n",
    "    i = 0\n",
    "    Pan_India_BPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_BPCL = pd.read_excel(URL17 + slash + TD + slash +'BPCL_' + states_for_pan[i] + '_' + TD + '.xlsx', 'Data')\n",
    "        Pan_India_BPCL = pd.concat([Pan_India_BPCL,extract_State_BPCL])\n",
    "        i +=1\n",
    "\n",
    "    Pan_India_BPCL['Sr no'] = list(range(1,len(Pan_India_BPCL)+1))\n",
    "    Pan_India_BPCL = Pan_India_BPCL.reset_index().drop('index',axis=1)\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\BPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "    Pan_India_BPCL.to_excel(URL12 + '\\Backup But Without Update' + '\\BPCL_Pan_India_Report_' + TD + '.xlsx',index = False)\n",
    "\n",
    "    print('SUCCESSFULLY File Saved As : ' + 'BPCL_Pan_India_Report_' + TD)\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"PAN_INDIA OPERATION'S SUCCESSFUL\")\n",
    "\n",
    "    print('Creating Backup...')\n",
    "\n",
    "    # copy subdirectory \n",
    "    os.mkdir(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\Backup\\HPCL & BPCL' + slash + TD)\n",
    "    fromDirectory = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL'\n",
    "    toDirectory = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\Backup\\HPCL & BPCL' + slash + TD\n",
    "\n",
    "    copy_tree(fromDirectory, toDirectory)\n",
    "\n",
    "\n",
    "   \n",
    "    print('\\033[1m' + '\\033[92m' + 'SUCCESSFULLY Backup Created')\n",
    "\n",
    "    image = imread(r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Script\\image-robot.jpg')\n",
    "    plt.imshow(image,print('\\033[1m' + 'ALL TASK COMPLETED'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def chk_yesterday_files():\n",
    "    \n",
    "    # Importing Neccessary Libraries...\n",
    "    import warnings \n",
    "    warnings.filterwarnings('ignore')\n",
    "    import pandas as pd , numpy as np , datetime, os\n",
    "\n",
    "    # Taking Input From User...\n",
    "    variable = input('\\033[1m' +'Enter Your System Name : ')\n",
    "    slash = input('\\033[1m' + 'Enter \\ : ')\n",
    "\n",
    "    # Datetime Manipulation \n",
    "    TD = datetime.datetime.now().strftime('%d-%m-%Y')\n",
    "    YD = datetime.date.today()-datetime.timedelta(1)\n",
    "    YD = YD.strftime('%d-%m-%Y')\n",
    "\n",
    "    #URL's\n",
    "    URL3 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files'              # Fixed Location Input\n",
    "    URL19 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL'\n",
    "    URL20 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL'\n",
    "\n",
    "    # Importing Required Columns Name to Overfit Format Of Files...\n",
    "    cols_hpcl = pd.read_excel(URL3 + '\\HPCL Columns.xlsx').columns.tolist()\n",
    "    cols_bpcl = pd.read_excel(URL3 + '\\BPCL Columns.xlsx').columns.tolist()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"Wait Checking In Process...\")\n",
    "\n",
    "    # HPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "    states_for_pan = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO','KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "    i = 0\n",
    "    Pan_India_HPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_HPCL = pd.read_excel(URL19 + slash + YD + slash + 'HPCL_' + states_for_pan[i] + '_' + YD + '.xlsx', 'Data')\n",
    "        extract_State_HPCL.columns = cols_hpcl\n",
    "        Pan_India_HPCL = pd.concat([Pan_India_HPCL,extract_State_HPCL])\n",
    "        i +=1\n",
    "\n",
    "    # BPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "    i = 0\n",
    "    Pan_India_BPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_BPCL = pd.read_excel(URL20 + slash + YD + slash + 'BPCL_' + states_for_pan[i] + '_' + YD + '.xlsx', 'Data')\n",
    "        extract_State_BPCL.columns = cols_bpcl\n",
    "        State_BPCL = extract_State_BPCL.drop('Sr no',axis = 1)\n",
    "        Pan_India_BPCL = pd.concat([Pan_India_BPCL,State_BPCL])\n",
    "        i +=1\n",
    "    Pan_India_BPCL['Sr no'] = list(range(1,len(Pan_India_BPCL)+1))\n",
    "    Pan_India_BPCL = Pan_India_BPCL.reset_index().drop('index',axis=1)\n",
    "    Pan_India_BPCL = Pan_India_BPCL[extract_State_BPCL.columns.tolist()]\n",
    "\n",
    "\n",
    "    # Final Report Cards\n",
    "\n",
    "    print('Report Cards..!')\n",
    "\n",
    "    display(Pan_India_HPCL['ROCode'][Pan_India_HPCL['ROCode'].apply(type) == str])\n",
    "    display(Pan_India_BPCL['CC'][Pan_India_BPCL['CC'].apply(type) == str])\n",
    "\n",
    "\n",
    "    \n",
    "def chk_today_files():\n",
    "    \n",
    "    # Importing Neccessary Libraries...\n",
    "    import warnings \n",
    "    warnings.filterwarnings('ignore')\n",
    "    import pandas as pd , numpy as np , datetime, os\n",
    "\n",
    "    # Taking Input From User...\n",
    "    variable = input('\\033[1m' +'Enter Your System Name : ')\n",
    "    slash = input('\\033[1m' + 'Enter \\ : ')\n",
    "\n",
    "    # Datetime Manipulation \n",
    "    TD = datetime.datetime.now().strftime('%d-%m-%Y')\n",
    "    TD = datetime.date.today()-datetime.timedelta(1)\n",
    "    TD = TD.strftime('%d-%m-%Y')\n",
    "\n",
    "    #URL's\n",
    "    URL3 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Input Fixed Files'              # Fixed Location Input\n",
    "    URL19 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise HPCL'\n",
    "    URL20 = r'C:\\Users' + slash + variable + '\\OneDrive\\Work\\Daily Reports\\HPCL & BPCL\\Output State Wise BPCL'\n",
    "\n",
    "    # Importing Required Columns Name to Overfit Format Of Files...\n",
    "    cols_hpcl = pd.read_excel(URL3 + '\\HPCL Columns.xlsx').columns.tolist()\n",
    "    cols_bpcl = pd.read_excel(URL3 + '\\BPCL Columns.xlsx').columns.tolist()\n",
    "\n",
    "    print('\\033[1m' + '\\033[92m' + \"Wait Checking In Process...\")\n",
    "\n",
    "    # HPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "    states_for_pan = ['ODSO','WBSO','NESO','JSO','DSO','BSO','GSO','RSO','TNSO','KESO','KASO','TAPSO','MPSO','PBSO I','PBSO II','UPSO I','UPSO II','MHSO']\n",
    "    i = 0\n",
    "    Pan_India_HPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_HPCL = pd.read_excel(URL19 + slash + TD + slash + 'HPCL_' + states_for_pan[i] + '_' + TD + '.xlsx', 'Data')\n",
    "        extract_State_HPCL.columns = cols_hpcl\n",
    "        Pan_India_HPCL = pd.concat([Pan_India_HPCL,extract_State_HPCL])\n",
    "        i +=1\n",
    "\n",
    "    # BPCL (Updating Yesterday's PAN INDIA Reports...)\n",
    "    i = 0\n",
    "    Pan_India_BPCL = pd.DataFrame()\n",
    "    while i < len(states_for_pan):\n",
    "        extract_State_BPCL = pd.read_excel(URL20 + slash + TD + slash + 'BPCL_' + states_for_pan[i] + '_' + TD + '.xlsx', 'Data')\n",
    "        extract_State_BPCL.columns = cols_bpcl\n",
    "        State_BPCL = extract_State_BPCL.drop('Sr no',axis = 1)\n",
    "        Pan_India_BPCL = pd.concat([Pan_India_BPCL,State_BPCL])\n",
    "        i +=1\n",
    "    Pan_India_BPCL['Sr no'] = list(range(1,len(Pan_India_BPCL)+1))\n",
    "    Pan_India_BPCL = Pan_India_BPCL.reset_index().drop('index',axis=1)\n",
    "    Pan_India_BPCL = Pan_India_BPCL[extract_State_BPCL.columns.tolist()]\n",
    "\n",
    "\n",
    "    # Final Report Cards\n",
    "\n",
    "    print('Report Cards..!')\n",
    "\n",
    "    display(Pan_India_HPCL['ROCode'][Pan_India_HPCL['ROCode'].apply(type) == str])\n",
    "    display(Pan_India_BPCL['CC'][Pan_India_BPCL['CC'].apply(type) == str])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ...END..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
